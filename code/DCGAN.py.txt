import os
import matplotlib.pyplot as plt
import pickle
import imageio
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.cuda import is_available as cuda_available
import torch.nn.functional as F

# Constants and Configuration
CONFIG = {
    'batch_size': 256,
    'learning_rate': 2e-4,
    'epochs': 100,
    'latent_dim': 100,
    'image_size': 28,
    'channels': 1,  # MNIST is grayscale
    'results_dir': 'MNIST_DCGAN_results',
    'device': 'cuda:0' if cuda_available() else 'cpu'
}

class Generator(nn.Module):
    """Generator network using transposed convolutions"""
    def __init__(self, latent_dim=100, channels=1, feature_size=64):
        super().__init__()
        self.main = nn.Sequential(
            # Input: latent_dim x 1 x 1
            nn.ConvTranspose2d(latent_dim, feature_size * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(feature_size * 4),
            nn.ReLU(True),
            
            # State: (feature_size*4) x 4 x 4
            nn.ConvTranspose2d(feature_size * 4, feature_size * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_size * 2),
            nn.ReLU(True),
            
            # State: (feature_size*2) x 8 x 8
            nn.ConvTranspose2d(feature_size * 2, feature_size, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_size),
            nn.ReLU(True),
            
            # State: (feature_size) x 16 x 16
            nn.ConvTranspose2d(feature_size, channels, 4, 2, 1, bias=False),
            nn.Tanh()
            # Output: channels x 32 x 32
        )
    
    def forward(self, input):
        # Reshape latent vector to 4D tensor
        input = input.view(input.size(0), input.size(1), 1, 1)
        return self.main(input)

class Discriminator(nn.Module):
    """Discriminator network using convolutions"""
    def __init__(self, channels=1, feature_size=64):
        super().__init__()
        self.main = nn.Sequential(
            # Input: channels x 32 x 32
            nn.Conv2d(channels, feature_size, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            
            # State: (feature_size) x 16 x 16
            nn.Conv2d(feature_size, feature_size * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_size * 2),
            nn.LeakyReLU(0.2, inplace=True),
            
            # State: (feature_size*2) x 8 x 8
            nn.Conv2d(feature_size * 2, feature_size * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_size * 4),
            nn.LeakyReLU(0.2, inplace=True),
            
            # State: (feature_size*4) x 4 x 4
            nn.Conv2d(feature_size * 4, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
            # Output: 1 x 1 x 1
        )
    
    def forward(self, input):
        # Add padding to make input 32x32 if needed
        if input.size(2) == 28:
            input = F.pad(input, (2, 2, 2, 2), mode='reflect')
        out = self.main(input)
        return out.view(-1)

def prepare_directories():
    """Create necessary directories for saving results"""
    os.makedirs(CONFIG['results_dir'], exist_ok=True)
    os.makedirs(os.path.join(CONFIG['results_dir'], 'Random_results'), exist_ok=True)
    os.makedirs(os.path.join(CONFIG['results_dir'], 'Fixed_results'), exist_ok=True)

def get_data_loader():
    """Prepare MNIST data loader"""
    transform = transforms.Compose([
        transforms.Resize(32),  # Resize to 32x32 for DCGAN
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.5,), std=(0.5,))  # Single channel for MNIST
    ])
    dataset = datasets.MNIST(
        'data', train=True, download=True, transform=transform
    )
    return DataLoader(
        dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2
    )

def weights_init(m):
    """Initialize weights for DCGAN"""
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

def train_gan():
    """Main training loop for DCGAN"""
    # Initialize networks
    generator = Generator(CONFIG['latent_dim'], CONFIG['channels']).to(CONFIG['device'])
    discriminator = Discriminator(CONFIG['channels']).to(CONFIG['device'])
    
    # Apply weight initialization
    generator.apply(weights_init)
    discriminator.apply(weights_init)
    
    # Loss and optimizers
    criterion = nn.BCELoss()
    g_optimizer = optim.Adam(generator.parameters(), lr=CONFIG['learning_rate'], betas=(0.5, 0.999))
    d_optimizer = optim.Adam(discriminator.parameters(), lr=CONFIG['learning_rate'], betas=(0.5, 0.999))
    
    # Fixed noise for visualization
    fixed_z = torch.randn((25, CONFIG['latent_dim']), device=CONFIG['device'])
    
    # Training history
    history = {'D_losses': [], 'G_losses': []}
    
    # Get data loader
    train_loader = get_data_loader()    
    for epoch in range(CONFIG['epochs']):
        d_losses, g_losses = [], []
        
        for i, (real_images, _) in enumerate(train_loader):
            real_images = real_images.to(CONFIG['device'])
            batch_size = real_images.size(0)
            
            # Labels
            real_labels = torch.full((batch_size,), 1.0, device=CONFIG['device'])
            fake_labels = torch.full((batch_size,), 0.0, device=CONFIG['device'])

            # Train Discriminator
            discriminator.zero_grad()
            
            # Forward pass real images
            outputs = discriminator(real_images)
            d_loss_real = criterion(outputs, real_labels)
            
            # Forward pass fake images
            z = torch.randn(batch_size, CONFIG['latent_dim'], device=CONFIG['device'])
            fake_images = generator(z)
            outputs = discriminator(fake_images.detach())
            d_loss_fake = criterion(outputs, fake_labels)
            
            # Total discriminator loss
            d_loss = d_loss_real + d_loss_fake
            d_loss.backward()
            d_optimizer.step()
            
            # Train Generator
            generator.zero_grad()
            
            # Generate fake images and calculate loss
            fake_images = generator(z)
            outputs = discriminator(fake_images)
            g_loss = criterion(outputs, real_labels)
            g_loss.backward()
            g_optimizer.step()
            
            # Save losses
            d_losses.append(d_loss.item())
            g_losses.append(g_loss.item())
        
        # Record epoch losses
        avg_d_loss = sum(d_losses) / len(d_losses)
        avg_g_loss = sum(g_losses) / len(g_losses)
        history['D_losses'].append(avg_d_loss)
        history['G_losses'].append(avg_g_loss)
        print(f'Epoch-DCGAN [{epoch+1}/{CONFIG["epochs"]}] | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f}')
        
        # Save sample images
        save_samples(generator, epoch, fixed_z)
    
    # Save models and training history
    save_results(generator, discriminator, history)
    create_animation()

def save_samples(generator, epoch, fixed_z, num_samples=5):
    """Save generated samples for visualization"""
    with torch.no_grad():
        # Random samples
        random_z = torch.randn(num_samples**2, CONFIG['latent_dim'], device=CONFIG['device'])
        generated = generator(random_z)
        save_image(generated, os.path.join(
            CONFIG['results_dir'], 'Random_results', f'MNIST_DCGAN_{epoch+1}.png'
        ))
        
        # Fixed samples
        generated = generator(fixed_z)
        save_image(generated, os.path.join(
            CONFIG['results_dir'], 'Fixed_results', f'MNIST_DCGAN_{epoch+1}.png'
        ))

def save_image(tensor, path):
    """Helper function to save tensor as image"""
    from torchvision.utils import save_image
    save_image(tensor, path, nrow=5, normalize=True)

def save_results(generator, discriminator, history):
    """Save models and training history"""
    torch.save(generator.state_dict(), os.path.join(CONFIG['results_dir'], 'generator.pth'))
    torch.save(discriminator.state_dict(), os.path.join(CONFIG['results_dir'], 'discriminator.pth'))
    
    with open(os.path.join(CONFIG['results_dir'], 'train_history.pkl'), 'wb') as f:
        pickle.dump(history, f)
    
    # Plot training history
    plt.figure(figsize=(10, 5))
    plt.plot(history['D_losses'], label='Discriminator Loss')
    plt.plot(history['G_losses'], label='Generator Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(CONFIG['results_dir'], 'training_history.png'))
    plt.close()

def create_animation():
    """Create GIF animation of training progress"""
    images = []
    for e in range(CONFIG['epochs']):
        img_path = os.path.join(
            CONFIG['results_dir'], 'Fixed_results', f'MNIST_DCGAN_{e+1}.png'
        )
        images.append(imageio.v2.imread(img_path))
    imageio.mimsave(
        os.path.join(CONFIG['results_dir'], 'training_progress.gif'),
        images, fps=5
    )

if __name__ == '__main__':
    prepare_directories()
    train_gan()