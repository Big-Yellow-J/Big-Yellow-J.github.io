import torch
import clip
from PIL import Image

# åŠ è½½ CLIP æ¨¡å‹ï¼ˆViT-B/32 æ¨¡å‹ï¼Œé€Ÿåº¦å’Œæ•ˆæœé€‚ä¸­ï¼‰
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

def compute_clip_score(image_path: str, text: str) -> float:
    # åŠ è½½å›¾åƒå¹¶é¢„å¤„ç†
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
    # ç¼–ç æ–‡æœ¬
    text_tokens = clip.tokenize([text]).to(device)

    # è®¡ç®—ç‰¹å¾
    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text_tokens)

        # å½’ä¸€åŒ–
        image_features /= image_features.norm(dim=-1, keepdim=True)
        text_features /= text_features.norm(dim=-1, keepdim=True)

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCLIP scoreï¼‰
        similarity = (image_features @ text_features.T).item()

    return similarity

# ğŸ”§ ç¤ºä¾‹ç”¨æ³•
image_path = "./instance/car-97.png"
text = "a car with wheels and headlights"
score = compute_clip_score(image_path, text)
print(f"CLIP Score: {score:.4f}")
