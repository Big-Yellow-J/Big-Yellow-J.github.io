{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9519665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先启用代理\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63437d91",
   "metadata": {},
   "source": [
    "# torch.compile加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cache_dit\n",
    "from diffusers import ZImagePipeline, AutoModel, PyramidAttentionBroadcastConfig\n",
    "from diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig\n",
    "from transformers import BitsAndBytesConfig as TransformersBitsAndBytesConfig\n",
    "\n",
    "def load_model(model_name= 'Tongyi-MAI/Z-Image-Turbo', cache_dir='/root/autodl-tmp/Model'):\n",
    "    device = \"cuda\"\n",
    "    quantization_config = DiffusersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        llm_int8_skip_modules=[\"transformer_blocks.0.img_mod\"],\n",
    "    )\n",
    "    transformer = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"transformer\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    # transformer = transformer.to(\"cpu\")\n",
    "\n",
    "    quantization_config = TransformersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    text_encoder = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"text_encoder\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    # text_encoder = text_encoder.to(\"cpu\")\n",
    "\n",
    "    pipe = ZImagePipeline.from_pretrained(\n",
    "        model_name,\n",
    "        transformer=transformer,\n",
    "        text_encoder=text_encoder,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        mirror='https://hf-mirror.com',\n",
    "        device_map=device\n",
    "    )\n",
    "    # pipe.enable_model_cpu_offload(gpu_id=gpu_id)\n",
    "    return pipe\n",
    "\n",
    "def image_generate(pipeline, prompt, special_name, seed=10086):\n",
    "    s_time = time.time()\n",
    "    image = pipeline(\n",
    "        prompt=prompt,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        num_inference_steps=10,\n",
    "        guidance_scale=0.0,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(seed),\n",
    "    ).images[0]\n",
    "    e_time = time.time()\n",
    "    # image.save(f\"./{special_name}-{e_time- s_time:.2f}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image_pipeline = load_model()\n",
    "z_image_pipeline.transformer.compile()\n",
    "s_time = time.time()\n",
    "for i in range(5):\n",
    "    image_generate(z_image_pipeline,\n",
    "                   \"Realistic mid-aged male image\",\n",
    "                   None)\n",
    "print(f\"Used Time: {time.time()- s_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26387d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image_pipeline = load_model()\n",
    "s_time = time.time()\n",
    "for i in range(10):\n",
    "    image_generate(z_image_pipeline,\n",
    "                   \"Realistic mid-aged male image\",\n",
    "                   None)\n",
    "print(f\"Used Time: {time.time()- s_time:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64213dbc",
   "metadata": {},
   "source": [
    "# CacheDit使用  \n",
    "## 基础使用方式\n",
    "```python\n",
    "cache_dit.enable_cache(dit_pipeline)\n",
    "```\n",
    "直接运行上面代码就可以启动cache_dit。\n",
    "## BlockAdapter使用方式  \n",
    "这个参数主要是为了结局在自定义的模型中使用了自定义的模型层，而这个模型层不在cache-dit中存在，比如说假设z-image里面模型有新定义的层/修改了他某些层。\n",
    "```python\n",
    "...\n",
    "(noise_refiner): ModuleList(\n",
    "    (0-1): 2 x ZImageTransformerBlock(\n",
    "      (attention): Attention(\n",
    "        (norm_q): RMSNorm()\n",
    "        (norm_k): RMSNorm()\n",
    "        (to_q): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "        (to_k): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "        (to_v): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "        (to_out): ModuleList(\n",
    "          (0): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "          (1): Dropout(p=0.0, inplace=False)\n",
    "        )\n",
    "      )\n",
    "...\n",
    "```\n",
    "比如说`all_final_layer`就是修改的，那么可以直接这么使用BlockAdapter 可以帮助您快速将各种缓存加速功能应用于自定义的Diffusion Pipelines和Transformers。那么可以直接使用\n",
    "```python\n",
    "from cache_dit import ForwardPattern, BlockAdapter\n",
    "cache_dit.enable_cache(\n",
    "    BlockAdapter(\n",
    "        pipe= z_image_pipeline,\n",
    "        transformer=z_image_pipeline.transformer,\n",
    "        blocks=[\n",
    "            z_image_pipeline.transformer.noise_refiner,\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75727718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cache_dit\n",
    "from diffusers import ZImagePipeline, AutoModel, PyramidAttentionBroadcastConfig\n",
    "from diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig\n",
    "from transformers import BitsAndBytesConfig as TransformersBitsAndBytesConfig\n",
    "\n",
    "def load_model(model_name= 'Tongyi-MAI/Z-Image-Turbo', cache_dir='/root/autodl-tmp/Model'):\n",
    "    device = \"cuda\"\n",
    "    quantization_config = DiffusersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        llm_int8_skip_modules=[\"transformer_blocks.0.img_mod\"],\n",
    "    )\n",
    "    transformer = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"transformer\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    # transformer = transformer.to(\"cpu\")\n",
    "\n",
    "    quantization_config = TransformersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    text_encoder = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"text_encoder\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    # text_encoder = text_encoder.to(\"cpu\")\n",
    "\n",
    "    pipe = ZImagePipeline.from_pretrained(\n",
    "        model_name,\n",
    "        transformer=transformer,\n",
    "        text_encoder=text_encoder,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        mirror='https://hf-mirror.com',\n",
    "        device_map=device\n",
    "    )\n",
    "    # pipe.enable_model_cpu_offload(gpu_id=gpu_id)\n",
    "    return pipe\n",
    "\n",
    "def image_generate(pipeline, prompt, special_name, seed=10086):\n",
    "    s_time = time.time()\n",
    "    image = pipeline(\n",
    "        prompt=prompt,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        num_inference_steps=10,\n",
    "        guidance_scale=0.0,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(seed),\n",
    "    ).images[0]\n",
    "    e_time = time.time()\n",
    "    image.save(f\"./{special_name}-{e_time- s_time:.2f}.png\")\n",
    "\n",
    "z_image_pipeline = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_image_pipeline.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5333bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BlockAdapter使用方式\n",
    "from cache_dit import ForwardPattern, BlockAdapter\n",
    "cache_dit.enable_cache(\n",
    "    BlockAdapter(\n",
    "        pipe= z_image_pipeline,\n",
    "        transformer=z_image_pipeline.transformer,\n",
    "        blocks=[\n",
    "            z_image_pipeline.transformer.noise_refiner,\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "image_generate(z_image_pipeline,\n",
    "               \"Realistic mid-aged male image\",\n",
    "               \"BlockAdapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9571d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "z-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
