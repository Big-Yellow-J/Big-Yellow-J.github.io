{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9519665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/miniconda3/envs/z-image/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 3 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 32017.59it/s]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.22s/it]\n",
      "Attention backends are an experimental feature and the API may be subject to change.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]\n",
      "Keyword arguments {'mirror': 'https://hf-mirror.com'} are not expected by ZImagePipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 19.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import cache_dit\n",
    "import subprocess\n",
    "from diffusers import ZImagePipeline, AutoModel, PyramidAttentionBroadcastConfig\n",
    "from diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig\n",
    "from transformers import BitsAndBytesConfig as TransformersBitsAndBytesConfig\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "\n",
    "def load_model(model_name= 'Tongyi-MAI/Z-Image-Turbo', cache_dir='/root/autodl-tmp/Model'):\n",
    "    device = \"cuda\"\n",
    "    quantization_config = DiffusersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        llm_int8_skip_modules=[\"transformer_blocks.0.img_mod\"],\n",
    "    )\n",
    "    transformer = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"transformer\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    transformer.set_attention_backend('flash')\n",
    "    transformer.to(memory_format=torch.channels_last)\n",
    "    # transformer = transformer.to(\"cpu\")\n",
    "\n",
    "    quantization_config = TransformersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    text_encoder = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"text_encoder\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    # text_encoder = text_encoder.to(\"cpu\")\n",
    "\n",
    "    pipe = ZImagePipeline.from_pretrained(\n",
    "        model_name,\n",
    "        transformer=transformer,\n",
    "        text_encoder=text_encoder,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        mirror='https://hf-mirror.com',\n",
    "        device_map=device\n",
    "    )\n",
    "    # pipe.enable_model_cpu_offload(gpu_id=gpu_id)\n",
    "    return pipe\n",
    "\n",
    "def image_generate(pipeline, prompt, special_name, num_inference_steps, seed=10086):\n",
    "    s_time = time.time()\n",
    "    image = pipeline(\n",
    "        prompt=prompt,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=0.0,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(seed),\n",
    "    ).images[0]\n",
    "    e_time = time.time()\n",
    "    if special_name:\n",
    "        image.save(f\"./tmp/{special_name}-{e_time- s_time:.2f}.png\")\n",
    "    print(f\"Used Time: {e_time- s_time:.2f}\")\n",
    "prompt = \"è¶…å†™å®äºšæ´²ä¸­å¹´ç”·æ€§ï¼Œå¹´é¾„çº¦45-55å²ã€‚é¢å®¹åšæ¯…ã€æ†”æ‚´ï¼Œå¸¦æœ‰ç”Ÿæ´»é˜…å†çš„ç—•è¿¹ï¼ˆå¦‚çœ¼è§’çš„ç»†çº¹ï¼‰ã€‚ä»–ç©¿ç€è´¨æ„ŸæŸ”è½¯çš„æ·±ç°è‰²é«˜é¢†æ¯›è¡£ï¼Œå¤–æ­ä¸€ä»¶ç»å…¸çš„å¡å…¶è‰²é£è¡£ï¼Œç«™åœ¨å¯’é£ä¸­å‘¨å›´æ˜¯é«˜æ¥¼å¤§å¦\"\n",
    "z_image_pipeline = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63437d91",
   "metadata": {},
   "source": [
    "# torch.compileåŠ é€Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image_pipeline = load_model()\n",
    "z_image_pipeline.transformer.compile()\n",
    "s_time = time.time()\n",
    "for i in range(5):\n",
    "    image_generate(z_image_pipeline,\n",
    "                   \"Realistic mid-aged male image\",\n",
    "                   None)\n",
    "print(f\"Used Time: {time.time()- s_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26387d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image_pipeline = load_model()\n",
    "s_time = time.time()\n",
    "for i in range(10):\n",
    "    image_generate(z_image_pipeline,\n",
    "                   \"Realistic mid-aged male image\",\n",
    "                   None)\n",
    "print(f\"Used Time: {time.time()- s_time:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64213dbc",
   "metadata": {},
   "source": [
    "# CacheDitä½¿ç”¨  \n",
    "å¯¹äºé‡åŒ–ã€attentionåç«¯é€‰æ‹©ç­‰å¯ä»¥ç›´æ¥çœ‹æ–‡æ¡£ï¼š[https://cache-dit.readthedocs.io/en/latest/user_guide/ATTENTION/#available-backend](https://cache-dit.readthedocs.io/en/latest/user_guide/ATTENTION/#available-backend)\n",
    "## åŸºç¡€ä½¿ç”¨æ–¹å¼\n",
    "```python\n",
    "cache_dit.enable_cache(dit_pipeline)\n",
    "cache_dit.disable_cache(dit_pipeline)\n",
    "```\n",
    "ç›´æ¥è¿è¡Œä¸Šé¢ä»£ç å°±å¯ä»¥å¯åŠ¨cache_ditï¼Œé™¤æ­¤ä¹‹å¤–å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š\n",
    "```python\n",
    "stats = cache_dit.summary(pipe)\n",
    "....\n",
    "ğŸ¤—Context Options: ZImageTransformerBlock\n",
    "\n",
    "{'cache_config': DBCacheConfig(cache_type=<CacheType.DBCache: 'DBCache'>, Fn_compute_blocks=8, Bn_compute_blocks=8, residual_diff_threshold=0.12, max_accumulated_residual_diff_threshold=None, max_warmup_steps=2, warmup_interval=1, max_cached_steps=-1, max_continuous_cached_steps=-1, enable_separate_cfg=False, cfg_compute_first=False, cfg_diff_compute_separate=True, num_inference_steps=None, steps_computation_mask=None, steps_computation_policy='dynamic'), 'name': 'layers_139918048080288'}\n",
    "WARNING 01-14 22:27:20 [summary.py:288] Can't find Parallelism Config for: ZImageTransformerBlock\n",
    "\n",
    "âš¡ï¸Cache Steps and Residual Diffs Statistics: ZImageTransformerBlock\n",
    "\n",
    "| Cache Steps | Diffs P00 | Diffs P25 | Diffs P50 | Diffs P75 | Diffs P95 | Diffs Min | Diffs Max |\n",
    "|-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "| 0           | 0.205     | 0.242     | 0.273     | 0.377     | 0.711     | 0.205     | 0.852     |\n",
    "\n",
    "WARNING 01-14 22:27:20 [summary.py:276] Can't find Context Options for: ZImageTransformerBlock\n",
    "WARNING 01-14 22:27:20 [summary.py:288] Can't find Parallelism Config for: ZImageTransformerBlock\n",
    "\n",
    "ğŸ¤—Context Options: ZImageTransformer2DModel\n",
    "\n",
    "{'cache_config': DBCacheConfig(cache_type=<CacheType.DBCache: 'DBCache'>, Fn_compute_blocks=8, Bn_compute_blocks=8, residual_diff_threshold=0.12, max_accumulated_residual_diff_threshold=None, max_warmup_steps=2, warmup_interval=1, max_cached_steps=-1, max_continuous_cached_steps=-1, enable_separate_cfg=False, cfg_compute_first=False, cfg_diff_compute_separate=True, num_inference_steps=None, steps_computation_mask=None, steps_computation_policy='dynamic'), 'name': 'layers_139918048080288'}\n",
    "WARNING 01-14 22:27:20 [summary.py:288] Can't find Parallelism Config for: ZImageTransformer2DModel\n",
    "\n",
    "âš¡ï¸Cache Steps and Residual Diffs Statistics: ZImageTransformer2DModel\n",
    "\n",
    "| Cache Steps | Diffs P00 | Diffs P25 | Diffs P50 | Diffs P75 | Diffs P95 | Diffs Min | Diffs Max |\n",
    "|-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "| 0           | 0.205     | 0.242     | 0.273     | 0.377     | 0.711     | 0.205     | 0.852     |\n",
    "....\n",
    "\n",
    "```\n",
    "å»åˆ†æç‰¹å¾ä¹‹é—´çš„æ®‹å·®åˆ†å¸ƒæƒ…å†µï¼ˆå¿…é¡»å…ˆè¿›è¡Œæ¨ç†ä¹‹åæ‰èƒ½è¿›è¡Œï¼‰è€Œåå»ç¡®å®šå‚æ•°`residual_diff_threshold`æ¯”å¦‚è¯´ï¼š\n",
    "```python\n",
    "fn, bn = 8, 8\n",
    "warmup_ratio, threshold = 0.2, 0.12\n",
    "num_inference_steps = 10\n",
    "cache_dit.enable_cache(\n",
    "    z_image_pipeline,\n",
    "    cache_config=DBCacheConfig(\n",
    "        max_warmup_steps=int(num_inference_steps* warmup_ratio), # å¤šå°‘æ­¥ä¸å»cacheç¼“å­˜\n",
    "        max_cached_steps=-1,\n",
    "        Fn_compute_blocks= fn,                                   # fnå±‚è®¡ç®—ç»“æœå¹¶ä¸”åˆ¤æ–­æ˜¯å¦ç¼“å­˜\n",
    "        Bn_compute_blocks= bn,                                   # bnå±‚ç›´æ¥è®¡ç®—\n",
    "        residual_diff_threshold= threshold,                      # å·®å¼‚é˜ˆå€¼\n",
    "    ),\n",
    ")\n",
    "```\n",
    "## BlockAdapterä½¿ç”¨æ–¹å¼  \n",
    "è¿™ä¸ªå‚æ•°ä¸»è¦æ˜¯ä¸ºäº†ç»“å±€åœ¨è‡ªå®šä¹‰çš„æ¨¡å‹ä¸­ä½¿ç”¨äº†è‡ªå®šä¹‰çš„æ¨¡å‹å±‚ï¼Œè€Œè¿™ä¸ªæ¨¡å‹å±‚ä¸åœ¨cache-ditä¸­å­˜åœ¨ï¼Œæ¯”å¦‚è¯´å‡è®¾z-imageé‡Œé¢æ¨¡å‹æœ‰æ–°å®šä¹‰çš„å±‚/ä¿®æ”¹äº†ä»–æŸäº›å±‚ã€‚\n",
    "```python\n",
    "...\n",
    "(noise_refiner): ModuleList(\n",
    "    (0-1): 2 x ZImageTransformerBlock(\n",
    "      (attention): Attention(\n",
    "        (norm_q): RMSNorm()\n",
    "        (norm_k): RMSNorm()\n",
    "        (to_q): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "        (to_k): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "        (to_v): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "        (to_out): ModuleList(\n",
    "          (0): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
    "          (1): Dropout(p=0.0, inplace=False)\n",
    "        )\n",
    "      )\n",
    "...\n",
    "```\n",
    "æ¯”å¦‚è¯´`all_final_layer`å°±æ˜¯ä¿®æ”¹çš„ï¼Œé‚£ä¹ˆå¯ä»¥ç›´æ¥è¿™ä¹ˆä½¿ç”¨BlockAdapter å¯ä»¥å¸®åŠ©æ‚¨å¿«é€Ÿå°†å„ç§ç¼“å­˜åŠ é€ŸåŠŸèƒ½åº”ç”¨äºè‡ªå®šä¹‰çš„Diffusion Pipelineså’ŒTransformersã€‚é‚£ä¹ˆå¯ä»¥ç›´æ¥ä½¿ç”¨\n",
    "```python\n",
    "from cache_dit import ForwardPattern, BlockAdapter\n",
    "cache_dit.enable_cache(\n",
    "    BlockAdapter(\n",
    "        pipe= z_image_pipeline,\n",
    "        transformer=z_image_pipeline.transformer,\n",
    "        blocks=[\n",
    "            z_image_pipeline.transformer.noise_refiner,\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75727718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 20327.81it/s]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.90s/it]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.49s/it]\n",
      "Fetching 8 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:14<00:00,  1.84s/it]\n",
      "Keyword arguments {'mirror': 'https://hf-mirror.com'} are not expected by ZImagePipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZImageTransformer2DModel(\n",
      "  (all_x_embedder): ModuleDict(\n",
      "    (2-1): Linear4bit(in_features=64, out_features=3840, bias=True)\n",
      "  )\n",
      "  (all_final_layer): ModuleDict(\n",
      "    (2-1): FinalLayer(\n",
      "      (norm_final): LayerNorm((3840,), eps=1e-06, elementwise_affine=False)\n",
      "      (linear): Linear4bit(in_features=3840, out_features=64, bias=True)\n",
      "      (adaLN_modulation): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear4bit(in_features=256, out_features=3840, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (noise_refiner): ModuleList(\n",
      "    (0-1): 2 x ZImageTransformerBlock(\n",
      "      (attention): Attention(\n",
      "        (norm_q): RMSNorm()\n",
      "        (norm_k): RMSNorm()\n",
      "        (to_q): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_k): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_v): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_out): ModuleList(\n",
      "          (0): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (w1): Linear4bit(in_features=3840, out_features=10240, bias=False)\n",
      "        (w2): Linear4bit(in_features=10240, out_features=3840, bias=False)\n",
      "        (w3): Linear4bit(in_features=3840, out_features=10240, bias=False)\n",
      "      )\n",
      "      (attention_norm1): RMSNorm()\n",
      "      (ffn_norm1): RMSNorm()\n",
      "      (attention_norm2): RMSNorm()\n",
      "      (ffn_norm2): RMSNorm()\n",
      "      (adaLN_modulation): Sequential(\n",
      "        (0): Linear4bit(in_features=256, out_features=15360, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (context_refiner): ModuleList(\n",
      "    (0-1): 2 x ZImageTransformerBlock(\n",
      "      (attention): Attention(\n",
      "        (norm_q): RMSNorm()\n",
      "        (norm_k): RMSNorm()\n",
      "        (to_q): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_k): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_v): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_out): ModuleList(\n",
      "          (0): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (w1): Linear4bit(in_features=3840, out_features=10240, bias=False)\n",
      "        (w2): Linear4bit(in_features=10240, out_features=3840, bias=False)\n",
      "        (w3): Linear4bit(in_features=3840, out_features=10240, bias=False)\n",
      "      )\n",
      "      (attention_norm1): RMSNorm()\n",
      "      (ffn_norm1): RMSNorm()\n",
      "      (attention_norm2): RMSNorm()\n",
      "      (ffn_norm2): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (t_embedder): TimestepEmbedder(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear4bit(in_features=256, out_features=1024, bias=True)\n",
      "      (1): SiLU()\n",
      "      (2): Linear4bit(in_features=1024, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cap_embedder): Sequential(\n",
      "    (0): RMSNorm()\n",
      "    (1): Linear4bit(in_features=2560, out_features=3840, bias=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-29): 30 x ZImageTransformerBlock(\n",
      "      (attention): Attention(\n",
      "        (norm_q): RMSNorm()\n",
      "        (norm_k): RMSNorm()\n",
      "        (to_q): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_k): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_v): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "        (to_out): ModuleList(\n",
      "          (0): Linear4bit(in_features=3840, out_features=3840, bias=False)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (w1): Linear4bit(in_features=3840, out_features=10240, bias=False)\n",
      "        (w2): Linear4bit(in_features=10240, out_features=3840, bias=False)\n",
      "        (w3): Linear4bit(in_features=3840, out_features=10240, bias=False)\n",
      "      )\n",
      "      (attention_norm1): RMSNorm()\n",
      "      (ffn_norm1): RMSNorm()\n",
      "      (attention_norm2): RMSNorm()\n",
      "      (ffn_norm2): RMSNorm()\n",
      "      (adaLN_modulation): Sequential(\n",
      "        (0): Linear4bit(in_features=256, out_features=15360, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(z_image_pipeline.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5333bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BlockAdapterä½¿ç”¨æ–¹å¼\n",
    "from cache_dit import ForwardPattern, BlockAdapter\n",
    "cache_dit.enable_cache(\n",
    "    BlockAdapter(\n",
    "        pipe= z_image_pipeline,\n",
    "        transformer=z_image_pipeline.transformer,\n",
    "        blocks=[\n",
    "            z_image_pipeline.transformer.noise_refiner,\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "image_generate(z_image_pipeline,\n",
    "               \"Realistic mid-aged male image\",\n",
    "               \"BlockAdapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fc8ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-14 22:27:13 [cache_adapter.py:57] ZImagePipeline is officially supported by cache-dit. Use it's pre-defined BlockAdapter directly!\n",
      "INFO 01-14 22:27:13 [block_adapters.py:220] Auto fill blocks_name: layers.\n",
      "WARNING 01-14 22:27:13 [block_adapters.py:479] Skipped Forward Pattern Check: ForwardPattern.Pattern_3\n",
      "INFO 01-14 22:27:13 [cache_adapter.py:150] Use default 'enable_separate_cfg' from block adapter register: False, Pipeline: ZImagePipeline.\n",
      "INFO 01-14 22:27:13 [cache_adapter.py:341] Collected Context Config: DBCache_F8B8_W2I1M0MC0_R0.12_CFG0, Calibrator Config: None\n",
      "WARNING 01-14 22:27:13 [pattern_base.py:78] Skipped Forward Pattern Check: ForwardPattern.Pattern_3\n",
      "INFO 01-14 22:27:13 [pattern_base.py:70] Match Blocks: CachedBlocks_Pattern_3_4_5, for layers, cache_context: layers_139918048080288, context_manager: ZImagePipeline_139918049240816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Time: 5.96\n",
      "WARNING 01-14 22:27:20 [summary.py:276] Can't find Context Options for: ZImageTransformerBlock\n",
      "WARNING 01-14 22:27:20 [summary.py:288] Can't find Parallelism Config for: ZImageTransformerBlock\n",
      "\n",
      "ğŸ¤—Context Options: ZImageTransformerBlock\n",
      "\n",
      "{'cache_config': DBCacheConfig(cache_type=<CacheType.DBCache: 'DBCache'>, Fn_compute_blocks=8, Bn_compute_blocks=8, residual_diff_threshold=0.12, max_accumulated_residual_diff_threshold=None, max_warmup_steps=2, warmup_interval=1, max_cached_steps=-1, max_continuous_cached_steps=-1, enable_separate_cfg=False, cfg_compute_first=False, cfg_diff_compute_separate=True, num_inference_steps=None, steps_computation_mask=None, steps_computation_policy='dynamic'), 'name': 'layers_139918048080288'}\n",
      "WARNING 01-14 22:27:20 [summary.py:288] Can't find Parallelism Config for: ZImageTransformerBlock\n",
      "\n",
      "âš¡ï¸Cache Steps and Residual Diffs Statistics: ZImageTransformerBlock\n",
      "\n",
      "| Cache Steps | Diffs P00 | Diffs P25 | Diffs P50 | Diffs P75 | Diffs P95 | Diffs Min | Diffs Max |\n",
      "|-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "| 0           | 0.205     | 0.242     | 0.273     | 0.377     | 0.711     | 0.205     | 0.852     |\n",
      "\n",
      "WARNING 01-14 22:27:20 [summary.py:276] Can't find Context Options for: ZImageTransformerBlock\n",
      "WARNING 01-14 22:27:20 [summary.py:288] Can't find Parallelism Config for: ZImageTransformerBlock\n",
      "\n",
      "ğŸ¤—Context Options: ZImageTransformer2DModel\n",
      "\n",
      "{'cache_config': DBCacheConfig(cache_type=<CacheType.DBCache: 'DBCache'>, Fn_compute_blocks=8, Bn_compute_blocks=8, residual_diff_threshold=0.12, max_accumulated_residual_diff_threshold=None, max_warmup_steps=2, warmup_interval=1, max_cached_steps=-1, max_continuous_cached_steps=-1, enable_separate_cfg=False, cfg_compute_first=False, cfg_diff_compute_separate=True, num_inference_steps=None, steps_computation_mask=None, steps_computation_policy='dynamic'), 'name': 'layers_139918048080288'}\n",
      "WARNING 01-14 22:27:20 [summary.py:288] Can't find Parallelism Config for: ZImageTransformer2DModel\n",
      "\n",
      "âš¡ï¸Cache Steps and Residual Diffs Statistics: ZImageTransformer2DModel\n",
      "\n",
      "| Cache Steps | Diffs P00 | Diffs P25 | Diffs P50 | Diffs P75 | Diffs P95 | Diffs Min | Diffs Max |\n",
      "|-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "| 0           | 0.205     | 0.242     | 0.273     | 0.377     | 0.711     | 0.205     | 0.852     |\n",
      "\n",
      "[CacheStats(cache_options={'cache_config': DBCacheConfig(cache_type=<CacheType.DBCache: 'DBCache'>, Fn_compute_blocks=8, Bn_compute_blocks=8, residual_diff_threshold=0.12, max_accumulated_residual_diff_threshold=None, max_warmup_steps=2, warmup_interval=1, max_cached_steps=-1, max_continuous_cached_steps=-1, enable_separate_cfg=False, cfg_compute_first=False, cfg_diff_compute_separate=True, num_inference_steps=None, steps_computation_mask=None, steps_computation_policy='dynamic'), 'name': 'layers_139918048080288'}, cached_steps=[], residual_diffs={'2': 0.353515625, '3': 0.25390625, '4': 0.2080078125, '5': 0.205078125, '6': 0.25390625, '7': 0.29296875, '8': 0.44921875, '9': 0.8515625}, cfg_cached_steps=[], cfg_residual_diffs={}, pruned_steps=[], pruned_blocks=[], actual_blocks=[], pruned_ratio=None, cfg_pruned_steps=[], cfg_pruned_blocks=[], cfg_actual_blocks=[], cfg_pruned_ratio=None, parallelism_config=None), CacheStats(cache_options={'cache_config': DBCacheConfig(cache_type=<CacheType.DBCache: 'DBCache'>, Fn_compute_blocks=8, Bn_compute_blocks=8, residual_diff_threshold=0.12, max_accumulated_residual_diff_threshold=None, max_warmup_steps=2, warmup_interval=1, max_cached_steps=-1, max_continuous_cached_steps=-1, enable_separate_cfg=False, cfg_compute_first=False, cfg_diff_compute_separate=True, num_inference_steps=None, steps_computation_mask=None, steps_computation_policy='dynamic'), 'name': 'layers_139918048080288'}, cached_steps=[], residual_diffs={'2': 0.353515625, '3': 0.25390625, '4': 0.2080078125, '5': 0.205078125, '6': 0.25390625, '7': 0.29296875, '8': 0.44921875, '9': 0.8515625}, cfg_cached_steps=[], cfg_residual_diffs={}, pruned_steps=[], pruned_blocks=[], actual_blocks=[], pruned_ratio=None, cfg_pruned_steps=[], cfg_pruned_blocks=[], cfg_actual_blocks=[], cfg_pruned_ratio=None, parallelism_config=None)]\n"
     ]
    }
   ],
   "source": [
    "# Fn Bnä½¿ç”¨\n",
    "from cache_dit import DBCacheConfig\n",
    "\n",
    "fn, bn = 8, 8\n",
    "warmup_ratio, threshold = 0.2, 0.12\n",
    "num_inference_steps = 10\n",
    "cache_dit.enable_cache(\n",
    "    z_image_pipeline,\n",
    "    cache_config=DBCacheConfig(\n",
    "        max_warmup_steps=int(num_inference_steps* warmup_ratio),\n",
    "        max_cached_steps=-1,\n",
    "        Fn_compute_blocks= fn,\n",
    "        Bn_compute_blocks= bn, \n",
    "        residual_diff_threshold= threshold,\n",
    "    ),\n",
    ")\n",
    "image_generate(z_image_pipeline, \n",
    "               prompt,\n",
    "               f\"{fn}-{bn}-{len(prompt)}-{threshold}\", \n",
    "               num_inference_steps)\n",
    "stats = cache_dit.summary(z_image_pipeline)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbaab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Time: 5.67\n"
     ]
    }
   ],
   "source": [
    "# ä¸ä½¿ç”¨cachedit\n",
    "image_generate(z_image_pipeline, \n",
    "               prompt,\n",
    "               f\"Normal-{len(prompt)}\", \n",
    "               10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨compile\n",
    "z_image_pipeline.transformer = torch.compile(z_image_pipeline.transformer)\n",
    "image_generate(z_image_pipeline, \n",
    "               prompt,\n",
    "               f\"Compile-{len(prompt)}\", \n",
    "               10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f661f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-14 22:51:00 [cache_interface.py:200] cache_config is None, using default DBCacheConfig\n",
      "INFO 01-14 22:51:00 [cache_adapter.py:57] ZImagePipeline is officially supported by cache-dit. Use it's pre-defined BlockAdapter directly!\n",
      "INFO 01-14 22:51:00 [block_adapters.py:220] Auto fill blocks_name: layers.\n",
      "WARNING 01-14 22:51:00 [block_adapters.py:479] Skipped Forward Pattern Check: ForwardPattern.Pattern_3\n",
      "INFO 01-14 22:51:00 [cache_adapter.py:150] Use default 'enable_separate_cfg' from block adapter register: False, Pipeline: ZImagePipeline.\n",
      "INFO 01-14 22:51:00 [cache_adapter.py:341] Collected Context Config: DBCache_F8B0_W8I1M0MC0_R0.08_CFG0, Calibrator Config: None\n",
      "WARNING 01-14 22:51:00 [pattern_base.py:78] Skipped Forward Pattern Check: ForwardPattern.Pattern_3\n",
      "INFO 01-14 22:51:00 [pattern_base.py:70] Match Blocks: CachedBlocks_Pattern_3_4_5, for layers, cache_context: layers_140602253406288, context_manager: ZImagePipeline_140602228024352.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Time: 5.48\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨cachedit+ complie\n",
    "cache_dit.enable_cache(z_image_pipeline)\n",
    "image_generate(z_image_pipeline, \n",
    "               prompt,\n",
    "               f\"CacheDit-{len(prompt)}\", \n",
    "               10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea662062",
   "metadata": {},
   "source": [
    "# å„ç±»åŠ é€Ÿtrickç»¼åˆæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cache_dit\n",
    "from diffusers import ZImagePipeline, AutoModel, PyramidAttentionBroadcastConfig\n",
    "from diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig\n",
    "from transformers import BitsAndBytesConfig as TransformersBitsAndBytesConfig\n",
    "\n",
    "def load_model(model_name= 'Tongyi-MAI/Z-Image-Turbo', cache_dir='/root/autodl-tmp/Model'):\n",
    "    device = \"cuda\"\n",
    "    quantization_config = DiffusersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        llm_int8_skip_modules=[\"transformer_blocks.0.img_mod\"],\n",
    "    )\n",
    "    transformer = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"transformer\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    # transformer = transformer.to(\"cpu\")\n",
    "\n",
    "    quantization_config = TransformersBitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    text_encoder = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=cache_dir,\n",
    "        subfolder=\"text_encoder\",\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        mirror='https://hf-mirror.com'\n",
    "    )\n",
    "    # text_encoder = text_encoder.to(\"cpu\")\n",
    "\n",
    "    pipe = ZImagePipeline.from_pretrained(\n",
    "        model_name,\n",
    "        transformer=transformer,\n",
    "        text_encoder=text_encoder,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        mirror='https://hf-mirror.com',\n",
    "        device_map=device\n",
    "    )\n",
    "    # pipe.enable_model_cpu_offload(gpu_id=gpu_id)\n",
    "    return pipe\n",
    "\n",
    "def image_generate(pipeline, prompt, special_name, seed=10086):\n",
    "    s_time = time.time()\n",
    "    image = pipeline(\n",
    "        prompt=prompt,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        num_inference_steps=10,\n",
    "        guidance_scale=0.0,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(seed),\n",
    "    ).images[0]\n",
    "    e_time = time.time()\n",
    "    image.save(f\"./{special_name}-{e_time- s_time:.2f}.png\")\n",
    "\n",
    "z_image_pipeline = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e623e",
   "metadata": {},
   "source": [
    "# é‡åŒ–æ“ä½œ\n",
    "æœ¬æœºå‚æ•°å¦‚ä¸‹ï¼š`Linux version 5.4.0-153-generic (buildd@bos03-amd64-008) (gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1)) 4090 CUDA Version: 12.6,`\n",
    "## é‡åŒ–å·¥å…·â€”â€”llama.cppå®‰è£…\n",
    "> å®˜æ–¹é¡¹ç›®ï¼š[https://github.com/ggml-org/llama.cpp](https://github.com/ggml-org/llama.cpp)\n",
    "\n",
    "å‚è€ƒ[é¡¹ç›®](https://qwen.readthedocs.io/zh-cn/latest/run_locally/llama.cpp.html#getting-the-program)ä¸­çš„å®‰è£…æ–¹å¼ï¼ˆæœ¬åœ°ç¼–è¯‘æ–¹å¼ï¼‰ï¼Œé¦–å…ˆæ£€æŸ¥C++ç¯å¢ƒï¼š`cc --version`æˆ–è€…ç›´æ¥ä½¿ç”¨ `cmake --version`ã€‚llama.cppå®‰è£…å¼€å§‹ï¼š\n",
    "```bash\n",
    "git clone https://github.com/ggml-org/llama.cpp\n",
    "cd llama.cpp\n",
    "cmake -B build # å°†æ£€æŸ¥æœ¬åœ°ç¯å¢ƒå¹¶ç¡®å®šéœ€è¦åŒ…å«çš„æ¨ç†åç«¯ä¸ç‰¹æ€§\n",
    "cmake --build build --config Release -j 8 # 8ä¸ªå¹¶è¡Œå‘½ä»¤è¿›è¡Œç¼–è¯‘\n",
    "```\n",
    "\n",
    "https://grok.com/share/c2hhcmQtMi1jb3B5_31abfa5d-8124-4595-8745-5c52c63c77f1\n",
    "## å¤§æ¨¡å‹çš„é‡åŒ–æ“ä½œ\n",
    "[é‡åŒ–å¤§è¯­è¨€æ¨¡å‹](https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelCode/DF_acceralate/quant_LLM.ipynb)\n",
    "\n",
    "https://qwen.readthedocs.io/zh-cn/latest/quantization/llama.cpp.html\n",
    "## å¤šæ¨¡æ€æ¨¡å‹çš„é‡åŒ–æ“ä½œ\n",
    "[é‡åŒ–å¤šæ¨¡æ€æ¨¡å‹](https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelCode/DF_acceralate/quant_MultiModal.ipynb)\n",
    "\n",
    "## æ‰©æ•£æ¨¡å‹é‡åŒ–æ“ä½œ\n",
    "[é‡åŒ–æ‰©æ•£æ¨¡å‹](https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelCode/DF_acceralate/quant_DFModel.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "z-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
