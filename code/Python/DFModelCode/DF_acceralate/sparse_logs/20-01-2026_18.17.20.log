2026-01-20 18:17:20.984 | INFO     | llmcompressor.metrics.logger:_create_default_logger:356 - Logging all LLM Compressor modifier-level logs to sparse_logs/20-01-2026_18.17.20.log
2026-01-20 18:17:20.985 | DEBUG    | llmcompressor.core.lifecycle:initialize:92 - Initializing compression lifecycle
2026-01-20 18:17:20.985 | INFO     | llmcompressor.recipe.recipe:from_modifiers:68 - Creating recipe from modifiers
2026-01-20 18:17:20.985 | INFO     | llmcompressor.modifiers.smoothquant.base:_infer_mappings_from_model:188 - No SmoothQuantModifier.mappings provided, inferring from model...
2026-01-20 18:17:21.821 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:17:21.849 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:17:21.849 | INFO     | llmcompressor.core.lifecycle:initialize:110 - Compression lifecycle initialized for 2 modifiers
2026-01-20 18:17:21.849 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `SmoothQuantModifier`
2026-01-20 18:17:22.146 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:17:22.146 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2026-01-20 18:17:22.146 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:17:22.146 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:17:22.146 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2026-01-20 18:17:22.146 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:17:22.147 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:17:22.147 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache()
    return (past_key_values,)
2026-01-20 18:17:22.147 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:17:22.147 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:17:22.147 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2026-01-20 18:17:22.147 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:17:22.148 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:17:22.148 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2026-01-20 18:17:22.148 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:17:22.148 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:17:22.148 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids, *, causal_mask_mapping=None, mask_kwargs=None):
    if not isinstance((causal_mask_mapping := attention_mask), dict):
        mask_kwargs = {'config': self.config, 'input_embeds': inputs_embeds, 'attention_mask': attention_mask, 'cache_position': cache_position, 'past_key_values': past_key_values, 'position_ids': position_ids}
        causal_mask_mapping = {'full_attention': create_causal_mask(**mask_kwargs)}
        if self.has_sliding_layers:
            causal_mask_mapping['sliding_attention'] = create_sliding_window_causal_mask(**mask_kwargs)
    return (causal_mask_mapping, mask_kwargs)
2026-01-20 18:17:22.149 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:17:22.152 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:17:22.152 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2026-01-20 18:17:22.152 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:17:22.215 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2026-01-20 18:17:22.215 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b3ff80>
2026-01-20 18:17:22.215 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c170>
2026-01-20 18:17:22.215 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c230>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c2c0>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c350>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c410>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c4d0>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c590>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c620>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c6b0>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c770>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c830>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f851b553230>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c950>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6c9e0>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f852aa02bd0>
2026-01-20 18:17:22.216 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6cb30>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6cbf0>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f851b532750>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6cce0>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6cd70>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6ce30>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6cec0>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6cf80>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f85521c1bb0>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d0d0>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d190>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d280>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d340>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d400>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d4f0>
2026-01-20 18:17:22.217 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d5e0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d6d0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d7c0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d8b0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6d940>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6da00>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6dac0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6dbb0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6dca0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6dd60>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6de50>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6df10>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e000>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e0c0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e1b0>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e270>
2026-01-20 18:17:22.218 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e360>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e450>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e540>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e630>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e720>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e810>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e900>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6e9f0>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8518b6eae0>
2026-01-20 18:17:22.219 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:17:26.174 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:17:26.174 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.0.input_layernorm
2026-01-20 18:17:26.184 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.0.post_attention_layernorm
2026-01-20 18:17:26.184 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:17:55.323 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:17:55.324 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.1.input_layernorm
2026-01-20 18:17:55.325 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.1.post_attention_layernorm
2026-01-20 18:17:55.325 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:17:59.457 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:17:59.457 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.2.input_layernorm
2026-01-20 18:17:59.458 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.2.post_attention_layernorm
2026-01-20 18:17:59.459 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:03.123 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:03.123 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.3.input_layernorm
2026-01-20 18:18:03.124 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.3.post_attention_layernorm
2026-01-20 18:18:03.125 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:06.799 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:06.799 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.4.input_layernorm
2026-01-20 18:18:06.800 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.4.post_attention_layernorm
2026-01-20 18:18:06.801 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:10.424 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:10.424 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.5.input_layernorm
2026-01-20 18:18:10.425 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.5.post_attention_layernorm
2026-01-20 18:18:10.426 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:14.079 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:14.079 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.6.input_layernorm
2026-01-20 18:18:14.080 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.6.post_attention_layernorm
2026-01-20 18:18:14.081 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:17.747 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:17.747 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.7.input_layernorm
2026-01-20 18:18:17.748 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.7.post_attention_layernorm
2026-01-20 18:18:17.749 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:21.348 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:21.348 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.8.input_layernorm
2026-01-20 18:18:21.349 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.8.post_attention_layernorm
2026-01-20 18:18:21.350 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:24.917 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:24.917 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.9.input_layernorm
2026-01-20 18:18:24.918 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.9.post_attention_layernorm
2026-01-20 18:18:24.919 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:28.516 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:28.516 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.10.input_layernorm
2026-01-20 18:18:28.517 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.10.post_attention_layernorm
2026-01-20 18:18:28.518 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:32.119 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:32.119 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.11.input_layernorm
2026-01-20 18:18:32.121 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.11.post_attention_layernorm
2026-01-20 18:18:32.121 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:35.746 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:35.746 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.12.input_layernorm
2026-01-20 18:18:35.747 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.12.post_attention_layernorm
2026-01-20 18:18:35.748 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:39.385 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:39.386 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.13.input_layernorm
2026-01-20 18:18:39.387 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.13.post_attention_layernorm
2026-01-20 18:18:39.388 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:43.008 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:43.008 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.14.input_layernorm
2026-01-20 18:18:43.009 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.14.post_attention_layernorm
2026-01-20 18:18:43.010 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:46.637 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:46.638 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.15.input_layernorm
2026-01-20 18:18:46.639 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.15.post_attention_layernorm
2026-01-20 18:18:46.639 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:50.254 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:50.255 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.16.input_layernorm
2026-01-20 18:18:50.256 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.16.post_attention_layernorm
2026-01-20 18:18:50.257 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:53.905 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:53.905 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.17.input_layernorm
2026-01-20 18:18:53.906 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.17.post_attention_layernorm
2026-01-20 18:18:53.907 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:18:57.539 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:18:57.539 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.18.input_layernorm
2026-01-20 18:18:57.540 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.18.post_attention_layernorm
2026-01-20 18:18:57.541 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:01.180 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:01.181 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.19.input_layernorm
2026-01-20 18:19:01.182 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.19.post_attention_layernorm
2026-01-20 18:19:01.183 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:04.784 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:04.784 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.20.input_layernorm
2026-01-20 18:19:04.785 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.20.post_attention_layernorm
2026-01-20 18:19:04.786 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:08.335 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:08.335 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.21.input_layernorm
2026-01-20 18:19:08.337 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.21.post_attention_layernorm
2026-01-20 18:19:08.337 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:11.924 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:11.924 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.22.input_layernorm
2026-01-20 18:19:11.925 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.22.post_attention_layernorm
2026-01-20 18:19:11.926 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:15.559 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:15.559 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.23.input_layernorm
2026-01-20 18:19:15.560 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.23.post_attention_layernorm
2026-01-20 18:19:15.561 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:19.188 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:19.188 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.24.input_layernorm
2026-01-20 18:19:19.189 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.24.post_attention_layernorm
2026-01-20 18:19:19.190 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:22.754 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:22.754 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.25.input_layernorm
2026-01-20 18:19:22.755 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.25.post_attention_layernorm
2026-01-20 18:19:22.756 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:26.331 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:26.331 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.26.input_layernorm
2026-01-20 18:19:26.333 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.26.post_attention_layernorm
2026-01-20 18:19:26.333 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:29.899 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:29.900 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.27.input_layernorm
2026-01-20 18:19:29.901 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.27.post_attention_layernorm
2026-01-20 18:19:29.902 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:36.698 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:36.699 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:41.881 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2026-01-20 18:19:41.881 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:19:41.885 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `GPTQModifier`
2026-01-20 18:19:42.000 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:19:42.001 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2026-01-20 18:19:42.001 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:19:42.001 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:19:42.001 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2026-01-20 18:19:42.001 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:19:42.001 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:19:42.002 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache()
    return (past_key_values,)
2026-01-20 18:19:42.002 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:19:42.002 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:19:42.002 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2026-01-20 18:19:42.002 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:19:42.002 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:19:42.003 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2026-01-20 18:19:42.003 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:19:42.003 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:19:42.003 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids, *, causal_mask_mapping=None, mask_kwargs=None):
    if not isinstance((causal_mask_mapping := attention_mask), dict):
        mask_kwargs = {'config': self.config, 'input_embeds': inputs_embeds, 'attention_mask': attention_mask, 'cache_position': cache_position, 'past_key_values': past_key_values, 'position_ids': position_ids}
        causal_mask_mapping = {'full_attention': create_causal_mask(**mask_kwargs)}
        if self.has_sliding_layers:
            causal_mask_mapping['sliding_attention'] = create_sliding_window_causal_mask(**mask_kwargs)
    return (causal_mask_mapping, mask_kwargs)
2026-01-20 18:19:42.003 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:19:42.007 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:19:42.007 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2026-01-20 18:19:42.008 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:19:42.065 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2026-01-20 18:19:42.070 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851b552e40>
2026-01-20 18:19:42.070 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bab9b80>
2026-01-20 18:19:42.070 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba1c4d0>
2026-01-20 18:19:42.070 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851babbfe0>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba1c350>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba1fd10>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bab8bf0>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba1da60>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba1d6d0>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba1d190>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b16420>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b17410>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b15d90>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b14d10>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b15df0>
2026-01-20 18:19:42.071 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b15070>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b15370>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b17ef0>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b147a0>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b147d0>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b15010>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b14b00>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b145c0>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b14da0>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b17b00>
2026-01-20 18:19:42.072 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92810>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93320>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b919d0>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92570>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90aa0>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92db0>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92d80>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93710>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93a40>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b922a0>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b902c0>
2026-01-20 18:19:42.073 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91f70>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93fb0>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90b00>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92270>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90a70>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91ac0>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92f00>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93110>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92b10>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92480>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93890>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91310>
2026-01-20 18:19:42.074 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b924b0>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b908c0>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92a50>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93d40>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93ce0>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93c20>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93b60>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b938c0>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93860>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93440>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93410>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b932f0>
2026-01-20 18:19:42.075 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b931d0>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b93050>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90bc0>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92630>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b928a0>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92900>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92660>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b921e0>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91fd0>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91df0>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91f40>
2026-01-20 18:19:42.076 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91d60>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b918e0>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91880>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b917f0>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91670>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91610>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91490>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b912e0>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b930e0>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90f80>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90830>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91a00>
2026-01-20 18:19:42.077 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92b40>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90c80>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b905c0>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90620>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b904d0>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90440>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90200>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90110>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90050>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92390>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b90a40>
2026-01-20 18:19:42.078 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91b80>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b92ae0>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91400>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b914c0>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8518b91940>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43b60>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba41df0>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba41f70>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba42240>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba430b0>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43290>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43f80>
2026-01-20 18:19:42.079 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43410>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43200>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba423f0>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43bc0>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba42540>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43650>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43f50>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43d10>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43c80>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba439b0>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43890>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba40d40>
2026-01-20 18:19:42.080 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba41940>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba427b0>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba42510>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43e30>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba434a0>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba40290>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba42c00>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba426f0>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba434d0>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba42660>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43080>
2026-01-20 18:19:42.081 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba401d0>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba41220>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba42ea0>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba27770>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba27710>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba26660>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba24470>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba24650>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba27680>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba240b0>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba27e90>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba269c0>
2026-01-20 18:19:42.082 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba25a30>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba24140>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba262a0>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba26f30>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba25fd0>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba262d0>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba24680>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba27fe0>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba275f0>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba25340>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba27260>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba269f0>
2026-01-20 18:19:42.083 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a3f0>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6b8f0>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6b620>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6b650>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6b0b0>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6b230>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6ade0>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851ba43500>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6ae10>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bab9b20>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a510>
2026-01-20 18:19:42.084 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a240>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a2d0>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a4e0>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68440>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a2a0>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68590>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68a10>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd696d0>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd69820>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd691f0>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd69cd0>
2026-01-20 18:19:42.085 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd69070>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd690a0>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd69040>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68b30>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6b530>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a8d0>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd686b0>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68740>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68920>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a060>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68bf0>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd69910>
2026-01-20 18:19:42.086 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a3c0>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6abd0>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68ef0>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6aba0>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6a1e0>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd6b5c0>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd68d70>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd69490>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f851bd69c70>
2026-01-20 18:19:42.087 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:19:50.718 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:19:50.719 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.q_proj using 512 samples
2026-01-20 18:19:51.370 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.65s
2026-01-20 18:19:51.370 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 527.96
2026-01-20 18:19:51.370 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:19:51.371 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:19:51.371 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.k_proj using 512 samples
2026-01-20 18:19:51.936 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:19:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 4.20
2026-01-20 18:19:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:19:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:19:51.937 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.v_proj using 512 samples
2026-01-20 18:19:52.495 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:19:52.495 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.69
2026-01-20 18:19:52.495 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:19:52.496 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:19:52.496 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.o_proj using 512 samples
2026-01-20 18:19:53.055 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:19:53.056 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 2.97
2026-01-20 18:19:53.056 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:19:53.056 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:19:53.056 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.gate_proj using 512 samples
2026-01-20 18:19:53.620 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:19:53.621 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 58.34
2026-01-20 18:19:53.621 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:19:53.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:19:53.621 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.up_proj using 512 samples
2026-01-20 18:19:54.180 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:19:54.181 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 35.69
2026-01-20 18:19:54.181 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:19:54.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:19:54.181 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.down_proj using 512 samples
2026-01-20 18:19:57.521 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.34s
2026-01-20 18:19:57.522 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.30
2026-01-20 18:19:57.523 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.35% | total memory: 25 GB
2026-01-20 18:19:57.523 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:19:57.523 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:20:12.000 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:20:12.000 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.q_proj using 512 samples
2026-01-20 18:20:12.573 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:20:12.573 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 47.27
2026-01-20 18:20:12.574 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:20:12.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:20:12.574 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.k_proj using 512 samples
2026-01-20 18:20:13.122 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:20:13.122 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 12.47
2026-01-20 18:20:13.122 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:20:13.122 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:13.123 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.v_proj using 512 samples
2026-01-20 18:20:13.674 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:20:13.674 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.46
2026-01-20 18:20:13.674 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:20:13.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:13.675 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.o_proj using 512 samples
2026-01-20 18:20:14.234 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:20:14.235 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.09
2026-01-20 18:20:14.235 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:20:14.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:20:14.235 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.gate_proj using 512 samples
2026-01-20 18:20:14.812 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:20:14.812 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1679.24
2026-01-20 18:20:14.813 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:20:14.813 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:20:14.813 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.up_proj using 512 samples
2026-01-20 18:20:15.403 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:20:15.403 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 750.53
2026-01-20 18:20:15.403 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:20:15.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:20:15.404 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.down_proj using 512 samples
2026-01-20 18:20:15.538 | WARNING  | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:165 - Failed to invert hessian due to numerical instability. Consider increasing GPTQModifier.dampening_frac, increasing the number of calibration samples, or shuffling the calibration dataset. Falling back to round-to-nearest for this module.
2026-01-20 18:20:18.676 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.27s
2026-01-20 18:20:18.676 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.72
2026-01-20 18:20:18.676 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.55% | total memory: 25 GB
2026-01-20 18:20:18.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:20:18.677 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:20:27.179 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:20:27.179 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.q_proj using 512 samples
2026-01-20 18:20:27.707 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:20:27.708 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 132.68
2026-01-20 18:20:27.708 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:20:27.708 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:20:27.708 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.k_proj using 512 samples
2026-01-20 18:20:28.221 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:20:28.222 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 21.38
2026-01-20 18:20:28.222 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:20:28.222 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:28.222 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.v_proj using 512 samples
2026-01-20 18:20:28.760 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:20:28.760 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.48
2026-01-20 18:20:28.760 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:20:28.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:28.761 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.o_proj using 512 samples
2026-01-20 18:20:29.279 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:20:29.280 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.84
2026-01-20 18:20:29.280 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:29.280 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:20:29.280 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.gate_proj using 512 samples
2026-01-20 18:20:29.839 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:20:29.840 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6259.15
2026-01-20 18:20:29.840 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:29.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:20:29.840 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.up_proj using 512 samples
2026-01-20 18:20:30.428 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:20:30.428 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 724.60
2026-01-20 18:20:30.429 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:30.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:20:30.429 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.down_proj using 512 samples
2026-01-20 18:20:33.816 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.39s
2026-01-20 18:20:33.818 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 207.08
2026-01-20 18:20:33.818 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:33.818 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:20:33.819 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:20:42.305 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:20:42.305 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.q_proj using 512 samples
2026-01-20 18:20:42.839 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:20:42.840 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 121.39
2026-01-20 18:20:42.840 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:42.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:20:42.840 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.k_proj using 512 samples
2026-01-20 18:20:43.375 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:20:43.376 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 22.46
2026-01-20 18:20:43.376 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:43.376 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:43.376 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.v_proj using 512 samples
2026-01-20 18:20:43.897 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:20:43.897 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 4.19
2026-01-20 18:20:43.897 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:43.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:43.897 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.o_proj using 512 samples
2026-01-20 18:20:44.409 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:20:44.409 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.29
2026-01-20 18:20:44.409 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:44.409 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:20:44.410 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.mlp.gate_proj using 512 samples
2026-01-20 18:20:44.973 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:20:44.973 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 4182.29
2026-01-20 18:20:44.974 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:44.974 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:20:44.974 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.mlp.up_proj using 512 samples
2026-01-20 18:20:45.556 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:20:45.556 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 259.26
2026-01-20 18:20:45.557 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:45.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:20:45.557 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.mlp.down_proj using 512 samples
2026-01-20 18:20:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.30s
2026-01-20 18:20:48.856 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 23.82
2026-01-20 18:20:48.856 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:48.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:20:48.857 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:20:57.310 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:20:57.310 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.q_proj using 512 samples
2026-01-20 18:20:57.896 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:20:57.896 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 97.79
2026-01-20 18:20:57.896 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:20:57.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:20:57.897 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.k_proj using 512 samples
2026-01-20 18:20:58.429 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:20:58.430 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 16.04
2026-01-20 18:20:58.430 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:20:58.430 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:58.430 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.v_proj using 512 samples
2026-01-20 18:20:58.943 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:20:58.943 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.39
2026-01-20 18:20:58.943 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:20:58.943 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:20:58.944 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.o_proj using 512 samples
2026-01-20 18:20:59.491 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:20:59.491 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 2.82
2026-01-20 18:20:59.491 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:20:59.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:20:59.492 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.mlp.gate_proj using 512 samples
2026-01-20 18:21:00.057 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:21:00.057 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1957.55
2026-01-20 18:21:00.059 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:00.059 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:00.059 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.mlp.up_proj using 512 samples
2026-01-20 18:21:00.643 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:21:00.644 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 132.53
2026-01-20 18:21:00.644 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:00.644 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:00.644 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.mlp.down_proj using 512 samples
2026-01-20 18:21:03.819 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.17s
2026-01-20 18:21:03.821 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 13.76
2026-01-20 18:21:03.821 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:03.821 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:21:03.821 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:21:12.260 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:21:12.261 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.q_proj using 512 samples
2026-01-20 18:21:12.836 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:21:12.836 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 100.99
2026-01-20 18:21:12.837 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:12.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:21:12.837 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.k_proj using 512 samples
2026-01-20 18:21:13.396 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:21:13.397 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 17.53
2026-01-20 18:21:13.397 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:13.397 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:13.397 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.v_proj using 512 samples
2026-01-20 18:21:13.941 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:21:13.941 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.17
2026-01-20 18:21:13.941 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:13.941 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:13.942 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.o_proj using 512 samples
2026-01-20 18:21:14.504 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:21:14.504 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.56
2026-01-20 18:21:14.505 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:14.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:21:14.505 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.mlp.gate_proj using 512 samples
2026-01-20 18:21:15.086 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:21:15.087 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3833.09
2026-01-20 18:21:15.096 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:15.097 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:15.097 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.mlp.up_proj using 512 samples
2026-01-20 18:21:15.703 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.61s
2026-01-20 18:21:15.703 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 299.20
2026-01-20 18:21:15.703 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:15.704 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:15.704 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.mlp.down_proj using 512 samples
2026-01-20 18:21:18.969 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.27s
2026-01-20 18:21:18.971 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 21.16
2026-01-20 18:21:18.971 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:18.971 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:21:18.972 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:21:27.428 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:21:27.428 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.q_proj using 512 samples
2026-01-20 18:21:27.982 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:21:27.982 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 150.72
2026-01-20 18:21:27.982 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:27.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:21:27.983 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.k_proj using 512 samples
2026-01-20 18:21:28.513 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:21:28.514 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 22.64
2026-01-20 18:21:28.514 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:28.514 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:28.514 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.v_proj using 512 samples
2026-01-20 18:21:29.029 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:21:29.030 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.74
2026-01-20 18:21:29.030 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:29.030 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:29.030 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.o_proj using 512 samples
2026-01-20 18:21:29.550 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:21:29.550 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.88
2026-01-20 18:21:29.550 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:29.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:21:29.551 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.mlp.gate_proj using 512 samples
2026-01-20 18:21:30.157 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.61s
2026-01-20 18:21:30.158 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 490.75
2026-01-20 18:21:30.158 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:30.158 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:30.158 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.mlp.up_proj using 512 samples
2026-01-20 18:21:30.766 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.61s
2026-01-20 18:21:30.767 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 122.35
2026-01-20 18:21:30.767 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:30.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:30.767 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.mlp.down_proj using 512 samples
2026-01-20 18:21:34.286 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.52s
2026-01-20 18:21:34.289 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 20.41
2026-01-20 18:21:34.289 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:34.289 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:21:34.289 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:21:42.743 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:21:42.743 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.q_proj using 512 samples
2026-01-20 18:21:43.271 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:21:43.271 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 103.89
2026-01-20 18:21:43.272 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:21:43.272 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:21:43.272 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.k_proj using 512 samples
2026-01-20 18:21:43.789 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:21:43.790 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 13.12
2026-01-20 18:21:43.790 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:21:43.790 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:43.790 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.v_proj using 512 samples
2026-01-20 18:21:44.323 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:21:44.324 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.64
2026-01-20 18:21:44.324 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:21:44.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:44.324 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.o_proj using 512 samples
2026-01-20 18:21:44.873 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:21:44.873 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.48
2026-01-20 18:21:44.873 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:44.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:21:44.874 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.mlp.gate_proj using 512 samples
2026-01-20 18:21:45.448 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:21:45.448 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 306.23
2026-01-20 18:21:45.448 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:45.449 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:45.449 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.mlp.up_proj using 512 samples
2026-01-20 18:21:46.010 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:21:46.011 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 123.49
2026-01-20 18:21:46.011 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:21:46.011 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:21:46.011 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.mlp.down_proj using 512 samples
2026-01-20 18:21:49.225 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.21s
2026-01-20 18:21:49.227 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 24.64
2026-01-20 18:21:49.227 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:49.227 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:21:49.227 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:21:57.687 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:21:57.687 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.q_proj using 512 samples
2026-01-20 18:21:58.228 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:21:58.228 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 187.62
2026-01-20 18:21:58.228 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:58.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:21:58.229 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.k_proj using 512 samples
2026-01-20 18:21:58.774 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:21:58.774 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 25.44
2026-01-20 18:21:58.775 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:58.775 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:58.775 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.v_proj using 512 samples
2026-01-20 18:21:59.309 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:21:59.310 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.06
2026-01-20 18:21:59.310 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:59.310 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:21:59.310 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.o_proj using 512 samples
2026-01-20 18:21:59.853 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:21:59.854 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.76
2026-01-20 18:21:59.854 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:21:59.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:21:59.854 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.mlp.gate_proj using 512 samples
2026-01-20 18:22:00.430 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:22:00.431 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 387.44
2026-01-20 18:22:00.431 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:00.431 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:00.431 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.mlp.up_proj using 512 samples
2026-01-20 18:22:01.022 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:22:01.022 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 139.74
2026-01-20 18:22:01.022 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:01.023 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:01.023 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.mlp.down_proj using 512 samples
2026-01-20 18:22:04.320 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.30s
2026-01-20 18:22:04.322 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 25.73
2026-01-20 18:22:04.323 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:04.323 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:22:04.323 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:22:12.785 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:22:12.785 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.q_proj using 512 samples
2026-01-20 18:22:13.347 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:22:13.348 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 159.46
2026-01-20 18:22:13.348 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:13.348 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:22:13.348 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.k_proj using 512 samples
2026-01-20 18:22:13.911 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:22:13.911 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 19.38
2026-01-20 18:22:13.912 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:13.912 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:13.912 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.v_proj using 512 samples
2026-01-20 18:22:14.460 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:22:14.460 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.51
2026-01-20 18:22:14.460 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:14.461 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:14.461 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.o_proj using 512 samples
2026-01-20 18:22:15.025 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:22:15.025 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.10
2026-01-20 18:22:15.026 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:15.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:22:15.026 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.mlp.gate_proj using 512 samples
2026-01-20 18:22:15.613 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:22:15.614 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 334.66
2026-01-20 18:22:15.614 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:15.614 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:15.614 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.mlp.up_proj using 512 samples
2026-01-20 18:22:16.209 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:22:16.209 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 153.79
2026-01-20 18:22:16.210 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:16.210 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:16.210 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.mlp.down_proj using 512 samples
2026-01-20 18:22:19.618 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.41s
2026-01-20 18:22:19.620 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 31.35
2026-01-20 18:22:19.620 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:19.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:22:19.621 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:22:28.067 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:22:28.067 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.q_proj using 512 samples
2026-01-20 18:22:28.614 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:22:28.615 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 197.37
2026-01-20 18:22:28.615 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:22:28.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:22:28.616 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.k_proj using 512 samples
2026-01-20 18:22:29.169 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:22:29.170 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.68
2026-01-20 18:22:29.170 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:22:29.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:29.170 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.v_proj using 512 samples
2026-01-20 18:22:29.735 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:22:29.736 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 7.52
2026-01-20 18:22:29.736 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:22:29.736 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:29.736 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.o_proj using 512 samples
2026-01-20 18:22:30.303 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:22:30.304 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.37
2026-01-20 18:22:30.304 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:30.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:22:30.305 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.mlp.gate_proj using 512 samples
2026-01-20 18:22:30.898 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:22:30.898 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 355.17
2026-01-20 18:22:30.899 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:30.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:30.899 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.mlp.up_proj using 512 samples
2026-01-20 18:22:31.494 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:22:31.494 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 154.76
2026-01-20 18:22:31.494 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:31.495 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:31.495 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.mlp.down_proj using 512 samples
2026-01-20 18:22:34.835 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.34s
2026-01-20 18:22:34.838 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.36
2026-01-20 18:22:34.838 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:34.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:22:34.838 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:22:43.310 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:22:43.310 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.q_proj using 512 samples
2026-01-20 18:22:43.860 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:22:43.861 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 167.97
2026-01-20 18:22:43.861 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:43.861 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:22:43.861 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.k_proj using 512 samples
2026-01-20 18:22:44.387 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:22:44.388 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 23.81
2026-01-20 18:22:44.388 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:44.388 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:44.388 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.v_proj using 512 samples
2026-01-20 18:22:44.912 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:22:44.912 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.26
2026-01-20 18:22:44.913 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:44.913 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:44.913 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.o_proj using 512 samples
2026-01-20 18:22:45.466 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:22:45.467 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.57
2026-01-20 18:22:45.467 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:45.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:22:45.468 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.mlp.gate_proj using 512 samples
2026-01-20 18:22:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:22:46.040 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 461.81
2026-01-20 18:22:46.040 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:46.040 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:46.041 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.mlp.up_proj using 512 samples
2026-01-20 18:22:46.605 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:22:46.606 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 168.99
2026-01-20 18:22:46.606 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:46.606 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:22:46.606 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.mlp.down_proj using 512 samples
2026-01-20 18:22:49.898 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.29s
2026-01-20 18:22:49.901 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 24.55
2026-01-20 18:22:49.901 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:22:49.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:22:49.902 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:22:58.369 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:22:58.370 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.q_proj using 512 samples
2026-01-20 18:22:58.898 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:22:58.899 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 188.37
2026-01-20 18:22:58.899 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:58.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:22:58.899 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.k_proj using 512 samples
2026-01-20 18:22:59.412 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:22:59.412 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.36
2026-01-20 18:22:59.412 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:59.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:59.412 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.v_proj using 512 samples
2026-01-20 18:22:59.933 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:22:59.933 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 9.08
2026-01-20 18:22:59.933 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:22:59.933 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:22:59.934 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.o_proj using 512 samples
2026-01-20 18:23:00.484 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:23:00.484 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.01
2026-01-20 18:23:00.484 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:23:00.485 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:23:00.485 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.mlp.gate_proj using 512 samples
2026-01-20 18:23:01.028 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:23:01.028 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 324.96
2026-01-20 18:23:01.029 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:23:01.029 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:01.029 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.mlp.up_proj using 512 samples
2026-01-20 18:23:01.594 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:23:01.595 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 165.58
2026-01-20 18:23:01.595 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:23:01.595 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:01.595 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.mlp.down_proj using 512 samples
2026-01-20 18:23:04.748 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.15s
2026-01-20 18:23:04.750 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 27.18
2026-01-20 18:23:04.751 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:04.751 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:23:04.751 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:23:13.196 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:23:13.196 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.q_proj using 512 samples
2026-01-20 18:23:13.752 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:23:13.752 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 133.72
2026-01-20 18:23:13.752 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:23:13.753 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:23:13.753 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.k_proj using 512 samples
2026-01-20 18:23:14.313 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:23:14.313 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 22.12
2026-01-20 18:23:14.313 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:23:14.314 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:23:14.314 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.v_proj using 512 samples
2026-01-20 18:23:14.874 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:23:14.874 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 7.44
2026-01-20 18:23:14.874 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:23:14.875 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:23:14.875 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.o_proj using 512 samples
2026-01-20 18:23:15.435 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:23:15.436 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.82
2026-01-20 18:23:15.436 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:23:15.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:23:15.436 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.mlp.gate_proj using 512 samples
2026-01-20 18:23:16.019 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:23:16.019 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 280.54
2026-01-20 18:23:16.019 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:23:16.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:16.020 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.mlp.up_proj using 512 samples
2026-01-20 18:23:16.592 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:23:16.592 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 165.85
2026-01-20 18:23:16.593 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:23:16.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:16.593 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.mlp.down_proj using 512 samples
2026-01-20 18:23:19.832 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.24s
2026-01-20 18:23:19.834 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 22.02
2026-01-20 18:23:19.834 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:19.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:23:19.835 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:23:28.271 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:23:28.271 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.q_proj using 512 samples
2026-01-20 18:23:28.848 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:23:28.848 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 252.39
2026-01-20 18:23:28.848 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:28.849 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:23:28.849 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.k_proj using 512 samples
2026-01-20 18:23:29.417 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:23:29.418 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 34.13
2026-01-20 18:23:29.418 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:29.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:23:29.419 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.v_proj using 512 samples
2026-01-20 18:23:29.978 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:23:29.978 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 14.19
2026-01-20 18:23:29.978 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:29.979 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:23:29.979 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.o_proj using 512 samples
2026-01-20 18:23:30.582 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:23:30.583 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.56
2026-01-20 18:23:30.583 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:30.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:23:30.584 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.mlp.gate_proj using 512 samples
2026-01-20 18:23:31.208 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.62s
2026-01-20 18:23:31.209 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 318.52
2026-01-20 18:23:31.209 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:31.209 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:31.209 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.mlp.up_proj using 512 samples
2026-01-20 18:23:31.791 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:23:31.792 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 181.84
2026-01-20 18:23:31.793 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:31.793 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:31.793 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.mlp.down_proj using 512 samples
2026-01-20 18:23:35.136 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.34s
2026-01-20 18:23:35.139 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 36.35
2026-01-20 18:23:35.139 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:35.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:23:35.140 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:23:43.634 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:23:43.635 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.q_proj using 512 samples
2026-01-20 18:23:44.166 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:23:44.166 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 576.04
2026-01-20 18:23:44.166 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:44.166 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:23:44.167 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.k_proj using 512 samples
2026-01-20 18:23:44.711 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:23:44.711 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 23.92
2026-01-20 18:23:44.711 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:44.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:23:44.712 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.v_proj using 512 samples
2026-01-20 18:23:45.255 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:23:45.256 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 10.92
2026-01-20 18:23:45.256 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:45.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:23:45.256 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.o_proj using 512 samples
2026-01-20 18:23:45.794 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:23:45.794 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 9.95
2026-01-20 18:23:45.795 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:45.795 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:23:45.795 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.mlp.gate_proj using 512 samples
2026-01-20 18:23:46.364 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:23:46.365 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 353.67
2026-01-20 18:23:46.365 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:46.365 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:46.365 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.mlp.up_proj using 512 samples
2026-01-20 18:23:46.934 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:23:46.935 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 187.18
2026-01-20 18:23:46.935 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:46.935 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:23:46.935 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.mlp.down_proj using 512 samples
2026-01-20 18:23:50.364 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.43s
2026-01-20 18:23:50.368 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 40.02
2026-01-20 18:23:50.368 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:23:50.368 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:23:50.369 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:23:58.837 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:23:58.837 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.q_proj using 512 samples
2026-01-20 18:23:59.406 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:23:59.407 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 213.73
2026-01-20 18:23:59.408 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:23:59.408 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:23:59.408 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.k_proj using 512 samples
2026-01-20 18:23:59.950 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:23:59.951 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 42.33
2026-01-20 18:23:59.951 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:23:59.951 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:23:59.951 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.v_proj using 512 samples
2026-01-20 18:24:00.494 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:24:00.494 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 12.68
2026-01-20 18:24:00.494 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:24:00.495 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:24:00.495 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.o_proj using 512 samples
2026-01-20 18:24:01.030 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:24:01.031 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.42
2026-01-20 18:24:01.031 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:01.031 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:24:01.032 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.mlp.gate_proj using 512 samples
2026-01-20 18:24:01.593 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:24:01.594 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 356.04
2026-01-20 18:24:01.594 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:01.594 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:01.594 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.mlp.up_proj using 512 samples
2026-01-20 18:24:02.136 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:24:02.136 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 215.65
2026-01-20 18:24:02.136 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:02.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:02.137 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.mlp.down_proj using 512 samples
2026-01-20 18:24:05.351 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.21s
2026-01-20 18:24:05.354 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 36.83
2026-01-20 18:24:05.354 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:05.354 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:24:05.355 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:24:13.775 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:24:13.776 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.q_proj using 512 samples
2026-01-20 18:24:14.354 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:24:14.354 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 191.39
2026-01-20 18:24:14.355 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:14.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:24:14.355 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.k_proj using 512 samples
2026-01-20 18:24:14.918 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:24:14.919 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 28.77
2026-01-20 18:24:14.919 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:14.919 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:24:14.920 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.v_proj using 512 samples
2026-01-20 18:24:15.483 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:24:15.484 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 15.32
2026-01-20 18:24:15.484 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:15.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:24:15.485 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.o_proj using 512 samples
2026-01-20 18:24:16.043 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:24:16.044 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.75
2026-01-20 18:24:16.044 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:16.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:24:16.044 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.mlp.gate_proj using 512 samples
2026-01-20 18:24:16.597 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:24:16.598 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 401.65
2026-01-20 18:24:16.598 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:16.598 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:16.598 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.mlp.up_proj using 512 samples
2026-01-20 18:24:17.147 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:24:17.147 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 214.84
2026-01-20 18:24:17.147 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:17.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:17.148 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.mlp.down_proj using 512 samples
2026-01-20 18:24:20.396 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.25s
2026-01-20 18:24:20.399 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 35.23
2026-01-20 18:24:20.399 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:20.399 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:24:20.400 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:24:28.852 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:24:28.852 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.q_proj using 512 samples
2026-01-20 18:24:29.424 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:24:29.425 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 173.99
2026-01-20 18:24:29.426 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:29.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:24:29.426 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.k_proj using 512 samples
2026-01-20 18:24:29.999 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:24:30.000 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 33.03
2026-01-20 18:24:30.000 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:30.000 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:24:30.000 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.v_proj using 512 samples
2026-01-20 18:24:30.569 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:24:30.570 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 16.12
2026-01-20 18:24:30.570 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:30.570 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:24:30.571 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.o_proj using 512 samples
2026-01-20 18:24:31.138 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:24:31.138 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 9.17
2026-01-20 18:24:31.139 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:31.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:24:31.139 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.mlp.gate_proj using 512 samples
2026-01-20 18:24:31.694 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:24:31.695 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 421.26
2026-01-20 18:24:31.695 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:31.695 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:31.696 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.mlp.up_proj using 512 samples
2026-01-20 18:24:32.294 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:24:32.295 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 241.66
2026-01-20 18:24:32.295 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:32.295 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:32.295 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.mlp.down_proj using 512 samples
2026-01-20 18:24:35.655 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.36s
2026-01-20 18:24:35.659 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 49.43
2026-01-20 18:24:35.659 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:35.659 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:24:35.659 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:24:44.097 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:24:44.097 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.q_proj using 512 samples
2026-01-20 18:24:44.653 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:24:44.654 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 191.46
2026-01-20 18:24:44.654 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:24:44.654 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:24:44.654 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.k_proj using 512 samples
2026-01-20 18:24:45.200 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:24:45.201 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 42.17
2026-01-20 18:24:45.201 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:24:45.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:24:45.201 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.v_proj using 512 samples
2026-01-20 18:24:45.751 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:24:45.751 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 19.71
2026-01-20 18:24:45.751 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:24:45.751 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:24:45.751 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.o_proj using 512 samples
2026-01-20 18:24:46.279 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:24:46.280 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 11.11
2026-01-20 18:24:46.280 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:46.280 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:24:46.280 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.mlp.gate_proj using 512 samples
2026-01-20 18:24:46.801 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:24:46.802 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 547.84
2026-01-20 18:24:46.802 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:46.802 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:46.802 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.mlp.up_proj using 512 samples
2026-01-20 18:24:47.344 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:24:47.344 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 313.37
2026-01-20 18:24:47.344 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:24:47.345 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:24:47.345 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.mlp.down_proj using 512 samples
2026-01-20 18:24:50.704 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.36s
2026-01-20 18:24:50.708 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 85.34
2026-01-20 18:24:50.708 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:50.708 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:24:50.709 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:24:59.178 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:24:59.178 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.q_proj using 512 samples
2026-01-20 18:24:59.716 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:24:59.716 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 289.54
2026-01-20 18:24:59.716 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:24:59.717 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:24:59.717 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.k_proj using 512 samples
2026-01-20 18:25:00.252 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:25:00.252 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 63.16
2026-01-20 18:25:00.252 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:00.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:00.253 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.v_proj using 512 samples
2026-01-20 18:25:00.792 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:25:00.793 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 29.15
2026-01-20 18:25:00.793 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:00.793 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:00.793 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.o_proj using 512 samples
2026-01-20 18:25:01.343 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:25:01.344 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 17.04
2026-01-20 18:25:01.344 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:01.344 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:25:01.345 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.mlp.gate_proj using 512 samples
2026-01-20 18:25:01.891 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:25:01.891 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 646.11
2026-01-20 18:25:01.891 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:01.892 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:01.892 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.mlp.up_proj using 512 samples
2026-01-20 18:25:02.427 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:25:02.427 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 326.08
2026-01-20 18:25:02.427 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:02.428 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:02.428 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.mlp.down_proj using 512 samples
2026-01-20 18:25:05.686 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.26s
2026-01-20 18:25:05.689 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 71.92
2026-01-20 18:25:05.689 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:05.689 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:25:05.689 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:25:14.159 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:25:14.159 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.q_proj using 512 samples
2026-01-20 18:25:14.729 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:25:14.730 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 349.51
2026-01-20 18:25:14.730 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:14.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:25:14.731 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.k_proj using 512 samples
2026-01-20 18:25:15.287 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:25:15.288 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 56.47
2026-01-20 18:25:15.288 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:15.288 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:15.288 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.v_proj using 512 samples
2026-01-20 18:25:15.818 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:25:15.819 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 30.08
2026-01-20 18:25:15.819 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:15.819 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:15.819 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.o_proj using 512 samples
2026-01-20 18:25:16.352 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:25:16.353 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.59
2026-01-20 18:25:16.353 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:16.353 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:25:16.353 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.mlp.gate_proj using 512 samples
2026-01-20 18:25:16.896 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:25:16.896 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 830.12
2026-01-20 18:25:16.896 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:16.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:16.897 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.mlp.up_proj using 512 samples
2026-01-20 18:25:17.454 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:25:17.455 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 442.62
2026-01-20 18:25:17.455 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:17.455 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:17.456 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.mlp.down_proj using 512 samples
2026-01-20 18:25:20.640 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.18s
2026-01-20 18:25:20.642 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 112.54
2026-01-20 18:25:20.643 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:20.643 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:25:20.643 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:25:29.080 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:25:29.081 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.q_proj using 512 samples
2026-01-20 18:25:29.673 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:25:29.673 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 298.62
2026-01-20 18:25:29.674 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:25:29.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:25:29.674 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.k_proj using 512 samples
2026-01-20 18:25:30.252 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:25:30.253 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 54.65
2026-01-20 18:25:30.253 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:25:30.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:30.253 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.v_proj using 512 samples
2026-01-20 18:25:30.807 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:25:30.807 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 49.84
2026-01-20 18:25:30.808 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:25:30.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:30.808 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.o_proj using 512 samples
2026-01-20 18:25:31.358 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:25:31.359 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 16.26
2026-01-20 18:25:31.359 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:31.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:25:31.360 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.mlp.gate_proj using 512 samples
2026-01-20 18:25:31.907 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:25:31.908 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1010.14
2026-01-20 18:25:31.908 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:31.908 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:31.908 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.mlp.up_proj using 512 samples
2026-01-20 18:25:32.480 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:25:32.481 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 538.61
2026-01-20 18:25:32.481 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:32.481 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:32.481 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.mlp.down_proj using 512 samples
2026-01-20 18:25:35.764 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.28s
2026-01-20 18:25:35.767 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 145.65
2026-01-20 18:25:35.767 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:35.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:25:35.768 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:25:44.234 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:25:44.234 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.q_proj using 512 samples
2026-01-20 18:25:44.784 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:25:44.785 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 399.06
2026-01-20 18:25:44.785 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:25:44.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:25:44.785 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.k_proj using 512 samples
2026-01-20 18:25:45.330 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:25:45.331 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 82.51
2026-01-20 18:25:45.331 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:25:45.331 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:45.331 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.v_proj using 512 samples
2026-01-20 18:25:45.857 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:25:45.857 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 67.60
2026-01-20 18:25:45.857 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:25:45.857 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:25:45.858 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.o_proj using 512 samples
2026-01-20 18:25:46.389 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:25:46.390 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.05
2026-01-20 18:25:46.390 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:25:46.390 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:25:46.390 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.mlp.gate_proj using 512 samples
2026-01-20 18:25:46.954 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:25:46.955 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 932.74
2026-01-20 18:25:46.955 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:25:46.956 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:46.956 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.mlp.up_proj using 512 samples
2026-01-20 18:25:47.517 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:25:47.518 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 520.13
2026-01-20 18:25:47.518 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:25:47.518 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:25:47.519 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.mlp.down_proj using 512 samples
2026-01-20 18:25:50.897 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.38s
2026-01-20 18:25:50.901 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 169.30
2026-01-20 18:25:50.902 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:25:50.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:25:50.902 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:25:59.403 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:25:59.403 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.q_proj using 512 samples
2026-01-20 18:25:59.945 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:25:59.945 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 351.15
2026-01-20 18:25:59.945 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:25:59.946 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:25:59.946 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.k_proj using 512 samples
2026-01-20 18:26:00.473 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:26:00.473 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 50.84
2026-01-20 18:26:00.473 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:00.474 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:00.474 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.v_proj using 512 samples
2026-01-20 18:26:00.976 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.50s
2026-01-20 18:26:00.976 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 133.72
2026-01-20 18:26:00.977 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:00.977 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:00.977 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.o_proj using 512 samples
2026-01-20 18:26:01.530 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:26:01.531 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 36.39
2026-01-20 18:26:01.531 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:01.531 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:26:01.531 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.mlp.gate_proj using 512 samples
2026-01-20 18:26:02.068 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:26:02.069 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 885.35
2026-01-20 18:26:02.069 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:02.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:02.070 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.mlp.up_proj using 512 samples
2026-01-20 18:26:02.595 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:26:02.595 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 509.21
2026-01-20 18:26:02.596 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:02.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:02.596 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.mlp.down_proj using 512 samples
2026-01-20 18:26:05.732 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.14s
2026-01-20 18:26:05.735 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 167.80
2026-01-20 18:26:05.735 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:05.735 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:26:05.736 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:26:14.224 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:26:14.225 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.q_proj using 512 samples
2026-01-20 18:26:14.780 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:26:14.781 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 237.04
2026-01-20 18:26:14.781 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:26:14.781 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:26:14.781 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.k_proj using 512 samples
2026-01-20 18:26:15.341 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:26:15.342 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 53.43
2026-01-20 18:26:15.342 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:26:15.342 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:15.342 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.v_proj using 512 samples
2026-01-20 18:26:15.885 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:26:15.886 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 239.33
2026-01-20 18:26:15.886 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:26:15.886 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:15.886 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.o_proj using 512 samples
2026-01-20 18:26:16.444 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:26:16.444 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 61.09
2026-01-20 18:26:16.445 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:16.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:26:16.445 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.mlp.gate_proj using 512 samples
2026-01-20 18:26:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:26:16.973 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 959.50
2026-01-20 18:26:16.973 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:16.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:16.974 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.mlp.up_proj using 512 samples
2026-01-20 18:26:17.496 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:26:17.496 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 606.10
2026-01-20 18:26:17.496 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:26:17.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:17.497 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.mlp.down_proj using 512 samples
2026-01-20 18:26:20.649 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.15s
2026-01-20 18:26:20.652 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 236.71
2026-01-20 18:26:20.652 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:20.652 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:26:20.652 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:26:29.111 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:26:29.111 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.q_proj using 512 samples
2026-01-20 18:26:29.679 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:26:29.679 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 458.68
2026-01-20 18:26:29.680 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:29.680 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:26:29.680 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.k_proj using 512 samples
2026-01-20 18:26:30.235 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:26:30.236 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 73.55
2026-01-20 18:26:30.236 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:30.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:30.236 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.v_proj using 512 samples
2026-01-20 18:26:30.786 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:26:30.787 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 296.66
2026-01-20 18:26:30.787 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:30.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:30.787 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.o_proj using 512 samples
2026-01-20 18:26:31.336 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:26:31.337 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 48.82
2026-01-20 18:26:31.337 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:31.337 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:26:31.337 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.mlp.gate_proj using 512 samples
2026-01-20 18:26:31.896 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:26:31.897 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1136.09
2026-01-20 18:26:31.897 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:31.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:31.897 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.mlp.up_proj using 512 samples
2026-01-20 18:26:32.460 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:26:32.461 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 755.06
2026-01-20 18:26:32.461 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:32.461 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:32.461 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.mlp.down_proj using 512 samples
2026-01-20 18:26:35.678 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.22s
2026-01-20 18:26:35.680 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 387.80
2026-01-20 18:26:35.681 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:35.681 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:26:35.681 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:26:44.144 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:26:44.144 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.q_proj using 512 samples
2026-01-20 18:26:44.665 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:26:44.665 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 494.11
2026-01-20 18:26:44.666 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:44.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:26:44.666 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.k_proj using 512 samples
2026-01-20 18:26:45.201 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:26:45.201 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 75.66
2026-01-20 18:26:45.201 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:45.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:45.202 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.v_proj using 512 samples
2026-01-20 18:26:45.721 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:26:45.722 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 336.46
2026-01-20 18:26:45.722 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:45.722 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:26:45.722 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.o_proj using 512 samples
2026-01-20 18:26:46.276 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:26:46.277 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 133.21
2026-01-20 18:26:46.277 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:46.277 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:26:46.278 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.mlp.gate_proj using 512 samples
2026-01-20 18:26:46.840 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:26:46.840 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1256.57
2026-01-20 18:26:46.841 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:46.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:46.841 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.mlp.up_proj using 512 samples
2026-01-20 18:26:47.402 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:26:47.403 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 2610.19
2026-01-20 18:26:47.403 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:47.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:26:47.404 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.mlp.down_proj using 512 samples
2026-01-20 18:26:50.824 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.42s
2026-01-20 18:26:50.827 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 832.99
2026-01-20 18:26:50.827 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:26:50.827 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:26:50.828 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:26:57.647 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:26:57.647 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
