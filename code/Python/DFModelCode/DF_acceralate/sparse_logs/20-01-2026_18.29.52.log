2026-01-20 18:29:52.007 | INFO     | llmcompressor.metrics.logger:_create_default_logger:356 - Logging all LLM Compressor modifier-level logs to sparse_logs/20-01-2026_18.29.52.log
2026-01-20 18:29:52.008 | DEBUG    | llmcompressor.core.lifecycle:initialize:92 - Initializing compression lifecycle
2026-01-20 18:29:52.008 | INFO     | llmcompressor.recipe.recipe:from_modifiers:68 - Creating recipe from modifiers
2026-01-20 18:29:52.008 | INFO     | llmcompressor.modifiers.smoothquant.base:_infer_mappings_from_model:188 - No SmoothQuantModifier.mappings provided, inferring from model...
2026-01-20 18:29:52.840 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:29:52.867 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:29:52.867 | INFO     | llmcompressor.core.lifecycle:initialize:110 - Compression lifecycle initialized for 2 modifiers
2026-01-20 18:29:52.867 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `SmoothQuantModifier`
2026-01-20 18:29:53.160 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:29:53.160 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2026-01-20 18:29:53.160 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:29:53.160 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:29:53.160 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2026-01-20 18:29:53.160 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:29:53.161 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:29:53.161 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache()
    return (past_key_values,)
2026-01-20 18:29:53.161 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:29:53.161 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:29:53.162 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2026-01-20 18:29:53.162 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:29:53.162 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:29:53.162 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2026-01-20 18:29:53.162 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:29:53.162 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:29:53.163 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids, *, causal_mask_mapping=None, mask_kwargs=None):
    if not isinstance((causal_mask_mapping := attention_mask), dict):
        mask_kwargs = {'config': self.config, 'input_embeds': inputs_embeds, 'attention_mask': attention_mask, 'cache_position': cache_position, 'past_key_values': past_key_values, 'position_ids': position_ids}
        causal_mask_mapping = {'full_attention': create_causal_mask(**mask_kwargs)}
        if self.has_sliding_layers:
            causal_mask_mapping['sliding_attention'] = create_sliding_window_causal_mask(**mask_kwargs)
    return (causal_mask_mapping, mask_kwargs)
2026-01-20 18:29:53.163 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:29:53.167 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:29:53.167 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2026-01-20 18:29:53.167 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:29:53.230 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2026-01-20 18:29:53.230 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750230>
2026-01-20 18:29:53.230 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750380>
2026-01-20 18:29:53.230 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750410>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447504d0>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750590>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750650>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750710>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447507d0>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750890>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750920>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447509b0>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750a40>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750b00>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750b90>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750c20>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750ce0>
2026-01-20 18:29:53.231 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750da0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750e60>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750f20>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244750fe0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447510a0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751160>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447511f0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447512b0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751370>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751430>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447514f0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447515b0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447516a0>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751790>
2026-01-20 18:29:53.232 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751850>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751940>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751a00>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751af0>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751be0>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751cd0>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751dc0>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751eb0>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244751fa0>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752090>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752150>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752210>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447522d0>
2026-01-20 18:29:53.233 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752390>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752450>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752540>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752630>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752720>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752810>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752900>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe2447529f0>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752ae0>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752ba0>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752c90>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752d80>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7fe244752e70>
2026-01-20 18:29:53.234 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:29:57.221 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:29:57.221 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.0.input_layernorm
2026-01-20 18:29:57.230 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.0.post_attention_layernorm
2026-01-20 18:29:57.231 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:24.376 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:24.376 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.1.input_layernorm
2026-01-20 18:30:24.377 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.1.post_attention_layernorm
2026-01-20 18:30:24.378 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:28.160 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:28.160 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.2.input_layernorm
2026-01-20 18:30:28.161 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.2.post_attention_layernorm
2026-01-20 18:30:28.162 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:31.822 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:31.823 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.3.input_layernorm
2026-01-20 18:30:31.824 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.3.post_attention_layernorm
2026-01-20 18:30:31.824 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:35.397 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:35.397 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.4.input_layernorm
2026-01-20 18:30:35.398 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.4.post_attention_layernorm
2026-01-20 18:30:35.399 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:38.960 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:38.960 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.5.input_layernorm
2026-01-20 18:30:38.961 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.5.post_attention_layernorm
2026-01-20 18:30:38.962 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:42.534 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:42.534 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.6.input_layernorm
2026-01-20 18:30:42.535 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.6.post_attention_layernorm
2026-01-20 18:30:42.536 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:46.138 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:46.138 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.7.input_layernorm
2026-01-20 18:30:46.140 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.7.post_attention_layernorm
2026-01-20 18:30:46.140 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:49.724 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:49.724 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.8.input_layernorm
2026-01-20 18:30:49.725 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.8.post_attention_layernorm
2026-01-20 18:30:49.726 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:53.297 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:53.297 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.9.input_layernorm
2026-01-20 18:30:53.298 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.9.post_attention_layernorm
2026-01-20 18:30:53.299 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:30:56.831 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:30:56.831 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.10.input_layernorm
2026-01-20 18:30:56.832 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.10.post_attention_layernorm
2026-01-20 18:30:56.833 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:00.365 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:00.365 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.11.input_layernorm
2026-01-20 18:31:00.366 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.11.post_attention_layernorm
2026-01-20 18:31:00.367 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:03.899 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:03.899 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.12.input_layernorm
2026-01-20 18:31:03.900 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.12.post_attention_layernorm
2026-01-20 18:31:03.901 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:07.511 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:07.511 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.13.input_layernorm
2026-01-20 18:31:07.512 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.13.post_attention_layernorm
2026-01-20 18:31:07.513 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:11.112 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:11.112 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.14.input_layernorm
2026-01-20 18:31:11.113 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.14.post_attention_layernorm
2026-01-20 18:31:11.114 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:14.645 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:14.645 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.15.input_layernorm
2026-01-20 18:31:14.646 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.15.post_attention_layernorm
2026-01-20 18:31:14.647 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:18.201 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:18.201 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.16.input_layernorm
2026-01-20 18:31:18.202 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.16.post_attention_layernorm
2026-01-20 18:31:18.203 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:21.835 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:21.835 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.17.input_layernorm
2026-01-20 18:31:21.836 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.17.post_attention_layernorm
2026-01-20 18:31:21.837 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:25.426 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:25.426 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.18.input_layernorm
2026-01-20 18:31:25.427 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.18.post_attention_layernorm
2026-01-20 18:31:25.428 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:29.045 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:29.045 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.19.input_layernorm
2026-01-20 18:31:29.047 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.19.post_attention_layernorm
2026-01-20 18:31:29.047 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:32.650 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:32.650 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.20.input_layernorm
2026-01-20 18:31:32.651 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.20.post_attention_layernorm
2026-01-20 18:31:32.652 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:36.218 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:36.218 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.21.input_layernorm
2026-01-20 18:31:36.220 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.21.post_attention_layernorm
2026-01-20 18:31:36.220 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:39.776 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:39.776 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.22.input_layernorm
2026-01-20 18:31:39.778 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.22.post_attention_layernorm
2026-01-20 18:31:39.778 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:43.340 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:43.340 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.23.input_layernorm
2026-01-20 18:31:43.342 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.23.post_attention_layernorm
2026-01-20 18:31:43.342 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:46.974 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:46.974 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.24.input_layernorm
2026-01-20 18:31:46.975 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.24.post_attention_layernorm
2026-01-20 18:31:46.976 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:50.596 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:50.597 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.25.input_layernorm
2026-01-20 18:31:50.598 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.25.post_attention_layernorm
2026-01-20 18:31:50.598 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:54.157 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:54.157 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.26.input_layernorm
2026-01-20 18:31:54.158 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.26.post_attention_layernorm
2026-01-20 18:31:54.159 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:31:57.721 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:31:57.721 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.27.input_layernorm
2026-01-20 18:31:57.722 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.27.post_attention_layernorm
2026-01-20 18:31:57.723 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:32:04.491 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:32:04.491 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:32:09.713 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2026-01-20 18:32:09.713 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:32:09.717 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `GPTQModifier`
2026-01-20 18:32:09.843 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:32:09.844 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2026-01-20 18:32:09.844 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:32:09.844 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:32:09.844 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2026-01-20 18:32:09.844 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:32:09.844 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:32:09.844 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache()
    return (past_key_values,)
2026-01-20 18:32:09.845 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:32:09.845 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:32:09.845 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2026-01-20 18:32:09.845 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:32:09.845 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:32:09.845 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2026-01-20 18:32:09.846 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:32:09.846 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:32:09.846 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids, *, causal_mask_mapping=None, mask_kwargs=None):
    if not isinstance((causal_mask_mapping := attention_mask), dict):
        mask_kwargs = {'config': self.config, 'input_embeds': inputs_embeds, 'attention_mask': attention_mask, 'cache_position': cache_position, 'past_key_values': past_key_values, 'position_ids': position_ids}
        causal_mask_mapping = {'full_attention': create_causal_mask(**mask_kwargs)}
        if self.has_sliding_layers:
            causal_mask_mapping['sliding_attention'] = create_sliding_window_causal_mask(**mask_kwargs)
    return (causal_mask_mapping, mask_kwargs)
2026-01-20 18:32:09.846 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:32:09.850 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 18:32:09.850 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2026-01-20 18:32:09.850 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 18:32:09.907 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440a2d0>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440ad20>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24442a1e0>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24c3f9490>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24c3f92b0>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20f80>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23e60>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20260>
2026-01-20 18:32:09.913 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20350>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20200>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f208f0>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20170>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21400>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20ec0>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f205f0>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23c20>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23860>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21070>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f205c0>
2026-01-20 18:32:09.914 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23050>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23bf0>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23200>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23290>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f223f0>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20110>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f211c0>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23d10>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23b90>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22e10>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23770>
2026-01-20 18:32:09.915 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f235c0>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23500>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23590>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22f00>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22990>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22780>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22600>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23560>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f225a0>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f200b0>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22180>
2026-01-20 18:32:09.916 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20bc0>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20530>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21130>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21fa0>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21880>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21670>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21a60>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20b00>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f210d0>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21190>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22900>
2026-01-20 18:32:09.917 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f222d0>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f21490>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20470>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f206e0>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23ad0>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f201a0>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20c20>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20650>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f20ad0>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22a20>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22660>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22c30>
2026-01-20 18:32:09.918 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f202f0>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22b10>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f23e00>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f228a0>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe224f22ed0>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fa40>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e840>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c500>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fcb0>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c620>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d9a0>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fe90>
2026-01-20 18:32:09.919 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c920>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679daf0>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679dcd0>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679cd40>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fe30>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e660>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679ca10>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d790>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c740>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d7f0>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e030>
2026-01-20 18:32:09.920 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c260>
2026-01-20 18:32:09.921 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d970>
2026-01-20 18:32:09.921 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f7a0>
2026-01-20 18:32:09.921 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679dd00>
2026-01-20 18:32:09.921 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c560>
2026-01-20 18:32:09.921 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679db20>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244715490>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244714a10>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244715b80>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244716a80>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244717650>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244716ea0>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244714dd0>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244715820>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244429940>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f5f40>
2026-01-20 18:32:09.923 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f65a0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f67e0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6690>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6480>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6bd0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f68d0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f72c0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6ab0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6f60>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24c3fb800>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f63c0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f62d0>
2026-01-20 18:32:09.924 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6000>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f7020>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f7b90>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f71d0>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f7920>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f5d30>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6510>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f6e40>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f68a0>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2443f67b0>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2444080b0>
2026-01-20 18:32:09.925 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244408260>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244408770>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2444285f0>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244408e00>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440be30>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244409d60>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440af90>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440b290>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244408590>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244409e80>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440bd40>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244408f80>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244409760>
2026-01-20 18:32:09.926 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440a210>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244409490>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244408e90>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe2444086b0>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe244409ee0>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440a090>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440a690>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe24440a540>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f770>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c6e0>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679db80>
2026-01-20 18:32:09.927 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c4d0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fe60>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f9b0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d5b0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e8d0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f470>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679dfa0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679ef90>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679ddf0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fbf0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fb30>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c2f0>
2026-01-20 18:32:09.928 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f980>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679cf80>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679ff50>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d640>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f4d0>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e690>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f8c0>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679dc10>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f200>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c710>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fd40>
2026-01-20 18:32:09.929 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d460>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d3d0>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d250>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c7d0>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fda0>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c980>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679da30>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679cb30>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e480>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679cd70>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679faa0>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c290>
2026-01-20 18:32:09.930 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c140>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679db50>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f440>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679fb60>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679de80>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679d940>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e990>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e780>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679f8f0>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679e210>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fe22679c1a0>
2026-01-20 18:32:09.931 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:32:18.573 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:32:18.573 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.q_proj using 512 samples
2026-01-20 18:32:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:32:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 519.90
2026-01-20 18:32:19.152 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:32:19.152 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:32:19.152 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.k_proj using 512 samples
2026-01-20 18:32:19.658 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:32:19.658 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 4.10
2026-01-20 18:32:19.658 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:32:19.659 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:32:19.659 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.v_proj using 512 samples
2026-01-20 18:32:20.181 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:32:20.181 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.67
2026-01-20 18:32:20.182 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:32:20.182 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:32:20.182 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.o_proj using 512 samples
2026-01-20 18:32:20.700 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:32:20.700 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 2.99
2026-01-20 18:32:20.700 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:32:20.700 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:32:20.701 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.gate_proj using 512 samples
2026-01-20 18:32:21.242 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:32:21.242 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 58.24
2026-01-20 18:32:21.243 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:32:21.243 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:32:21.243 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.up_proj using 512 samples
2026-01-20 18:32:21.760 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:32:21.760 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 35.90
2026-01-20 18:32:21.760 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 10.09% | total memory: 25 GB
2026-01-20 18:32:21.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:32:21.761 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.down_proj using 512 samples
2026-01-20 18:32:25.027 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.27s
2026-01-20 18:32:25.028 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.28
2026-01-20 18:32:25.030 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.35% | total memory: 25 GB
2026-01-20 18:32:25.030 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:32:25.031 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:32:39.639 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:32:39.639 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.q_proj using 512 samples
2026-01-20 18:32:40.176 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:32:40.176 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 44.58
2026-01-20 18:32:40.176 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:32:40.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:32:40.176 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.k_proj using 512 samples
2026-01-20 18:32:40.701 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:32:40.701 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 11.90
2026-01-20 18:32:40.701 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:32:40.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:32:40.701 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.v_proj using 512 samples
2026-01-20 18:32:41.220 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:32:41.220 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.45
2026-01-20 18:32:41.220 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:32:41.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:32:41.220 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.o_proj using 512 samples
2026-01-20 18:32:41.751 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:32:41.751 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.08
2026-01-20 18:32:41.751 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:32:41.752 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:32:41.752 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.gate_proj using 512 samples
2026-01-20 18:32:42.314 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:32:42.315 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1643.22
2026-01-20 18:32:42.315 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:32:42.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:32:42.315 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.up_proj using 512 samples
2026-01-20 18:32:42.913 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:32:42.914 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 746.23
2026-01-20 18:32:42.914 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:32:42.914 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:32:42.914 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.down_proj using 512 samples
2026-01-20 18:32:43.047 | WARNING  | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:165 - Failed to invert hessian due to numerical instability. Consider increasing GPTQModifier.dampening_frac, increasing the number of calibration samples, or shuffling the calibration dataset. Falling back to round-to-nearest for this module.
2026-01-20 18:32:46.199 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.28s
2026-01-20 18:32:46.199 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.72
2026-01-20 18:32:46.199 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.55% | total memory: 25 GB
2026-01-20 18:32:46.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:32:46.200 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:32:54.740 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:32:54.740 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.q_proj using 512 samples
2026-01-20 18:32:55.279 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:32:55.280 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 125.03
2026-01-20 18:32:55.280 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:32:55.280 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:32:55.280 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.k_proj using 512 samples
2026-01-20 18:32:55.794 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:32:55.794 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 20.78
2026-01-20 18:32:55.794 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:32:55.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:32:55.795 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.v_proj using 512 samples
2026-01-20 18:32:56.347 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:32:56.347 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.58
2026-01-20 18:32:56.347 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:32:56.348 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:32:56.348 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.o_proj using 512 samples
2026-01-20 18:32:56.865 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:32:56.866 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.81
2026-01-20 18:32:56.866 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:32:56.866 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:32:56.866 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.gate_proj using 512 samples
2026-01-20 18:32:57.432 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:32:57.433 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6243.89
2026-01-20 18:32:57.433 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:32:57.433 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:32:57.433 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.up_proj using 512 samples
2026-01-20 18:32:58.001 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:32:58.001 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 763.96
2026-01-20 18:32:58.001 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:32:58.001 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:32:58.001 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.down_proj using 512 samples
2026-01-20 18:33:01.196 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.19s
2026-01-20 18:33:01.197 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 115.33
2026-01-20 18:33:01.198 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:01.198 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:33:01.198 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:33:09.716 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:33:09.716 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.q_proj using 512 samples
2026-01-20 18:33:10.291 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:33:10.292 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 122.66
2026-01-20 18:33:10.292 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:10.292 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:33:10.292 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.k_proj using 512 samples
2026-01-20 18:33:10.809 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:33:10.810 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 23.74
2026-01-20 18:33:10.810 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:10.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:10.810 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.v_proj using 512 samples
2026-01-20 18:33:11.343 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:33:11.343 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 4.19
2026-01-20 18:33:11.344 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:11.344 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:11.344 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.self_attn.o_proj using 512 samples
2026-01-20 18:33:11.855 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:33:11.855 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.25
2026-01-20 18:33:11.855 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:11.855 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:33:11.856 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.mlp.gate_proj using 512 samples
2026-01-20 18:33:12.427 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:33:12.427 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 4207.83
2026-01-20 18:33:12.427 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:12.428 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:12.428 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.mlp.up_proj using 512 samples
2026-01-20 18:33:13.006 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:33:13.006 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 259.70
2026-01-20 18:33:13.006 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:13.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:13.007 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.3.mlp.down_proj using 512 samples
2026-01-20 18:33:16.159 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.15s
2026-01-20 18:33:16.160 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 23.89
2026-01-20 18:33:16.160 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:16.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:33:16.161 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:33:24.601 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:33:24.601 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.q_proj using 512 samples
2026-01-20 18:33:25.173 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:33:25.174 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 93.30
2026-01-20 18:33:25.174 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:33:25.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:33:25.175 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.k_proj using 512 samples
2026-01-20 18:33:25.737 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:33:25.738 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 15.57
2026-01-20 18:33:25.738 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:33:25.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:25.738 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.v_proj using 512 samples
2026-01-20 18:33:26.291 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:33:26.291 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.33
2026-01-20 18:33:26.292 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:33:26.292 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:26.292 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.self_attn.o_proj using 512 samples
2026-01-20 18:33:26.828 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:33:26.828 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 2.74
2026-01-20 18:33:26.828 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:26.828 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:33:26.829 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.mlp.gate_proj using 512 samples
2026-01-20 18:33:27.412 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:33:27.412 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1985.54
2026-01-20 18:33:27.413 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:27.413 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:27.413 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.mlp.up_proj using 512 samples
2026-01-20 18:33:28.021 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.61s
2026-01-20 18:33:28.022 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 130.63
2026-01-20 18:33:28.022 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:28.022 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:28.022 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.4.mlp.down_proj using 512 samples
2026-01-20 18:33:31.301 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.28s
2026-01-20 18:33:31.303 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 13.50
2026-01-20 18:33:31.303 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:31.303 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:33:31.303 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:33:39.731 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:33:39.731 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.q_proj using 512 samples
2026-01-20 18:33:40.282 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:33:40.282 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 94.12
2026-01-20 18:33:40.282 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:40.283 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:33:40.283 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.k_proj using 512 samples
2026-01-20 18:33:40.840 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:33:40.841 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 17.35
2026-01-20 18:33:40.841 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:40.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:40.842 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.v_proj using 512 samples
2026-01-20 18:33:41.374 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:33:41.375 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.09
2026-01-20 18:33:41.375 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:41.375 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:41.375 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.self_attn.o_proj using 512 samples
2026-01-20 18:33:41.913 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:33:41.913 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.46
2026-01-20 18:33:41.913 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:41.914 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:33:41.914 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.mlp.gate_proj using 512 samples
2026-01-20 18:33:42.536 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.62s
2026-01-20 18:33:42.536 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3777.67
2026-01-20 18:33:42.537 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:42.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:42.537 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.mlp.up_proj using 512 samples
2026-01-20 18:33:43.142 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:33:43.142 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 292.26
2026-01-20 18:33:43.143 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:43.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:43.143 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.5.mlp.down_proj using 512 samples
2026-01-20 18:33:46.483 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.34s
2026-01-20 18:33:46.485 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 20.87
2026-01-20 18:33:46.485 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:33:46.485 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:33:46.485 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:33:54.944 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:33:54.944 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.q_proj using 512 samples
2026-01-20 18:33:55.485 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:33:55.485 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 137.55
2026-01-20 18:33:55.486 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:55.486 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:33:55.486 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.k_proj using 512 samples
2026-01-20 18:33:55.997 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:33:55.997 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 21.30
2026-01-20 18:33:55.997 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:55.998 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:55.998 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.v_proj using 512 samples
2026-01-20 18:33:56.534 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:33:56.535 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.42
2026-01-20 18:33:56.535 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:56.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:33:56.535 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.self_attn.o_proj using 512 samples
2026-01-20 18:33:57.050 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:33:57.050 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.84
2026-01-20 18:33:57.051 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:57.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:33:57.051 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.mlp.gate_proj using 512 samples
2026-01-20 18:33:57.622 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:33:57.623 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 484.10
2026-01-20 18:33:57.623 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:57.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:57.623 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.mlp.up_proj using 512 samples
2026-01-20 18:33:58.188 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:33:58.189 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 120.27
2026-01-20 18:33:58.189 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:33:58.189 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:33:58.189 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.6.mlp.down_proj using 512 samples
2026-01-20 18:34:01.338 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.15s
2026-01-20 18:34:01.339 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 20.37
2026-01-20 18:34:01.340 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:01.340 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:34:01.340 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:34:09.808 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:34:09.808 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.q_proj using 512 samples
2026-01-20 18:34:10.347 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:34:10.347 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 92.83
2026-01-20 18:34:10.347 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:34:10.348 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:34:10.348 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.k_proj using 512 samples
2026-01-20 18:34:10.859 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:34:10.859 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 12.99
2026-01-20 18:34:10.860 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:34:10.860 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:10.860 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.v_proj using 512 samples
2026-01-20 18:34:11.376 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:34:11.376 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.08
2026-01-20 18:34:11.377 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:34:11.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:11.377 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.self_attn.o_proj using 512 samples
2026-01-20 18:34:11.900 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:34:11.901 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.46
2026-01-20 18:34:11.901 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:34:11.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:34:11.901 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.mlp.gate_proj using 512 samples
2026-01-20 18:34:12.456 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:34:12.457 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 297.62
2026-01-20 18:34:12.457 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:34:12.457 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:12.457 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.mlp.up_proj using 512 samples
2026-01-20 18:34:13.014 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:34:13.015 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 121.01
2026-01-20 18:34:13.015 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:34:13.015 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:13.015 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.7.mlp.down_proj using 512 samples
2026-01-20 18:34:16.155 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.14s
2026-01-20 18:34:16.156 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 24.62
2026-01-20 18:34:16.157 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:16.157 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:34:16.157 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:34:24.570 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:34:24.570 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.q_proj using 512 samples
2026-01-20 18:34:25.152 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:34:25.153 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 177.54
2026-01-20 18:34:25.153 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:25.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:34:25.153 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.k_proj using 512 samples
2026-01-20 18:34:25.692 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:34:25.692 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 25.52
2026-01-20 18:34:25.692 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:25.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:25.693 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.v_proj using 512 samples
2026-01-20 18:34:26.246 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:34:26.246 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.00
2026-01-20 18:34:26.246 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:26.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:26.247 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.self_attn.o_proj using 512 samples
2026-01-20 18:34:26.789 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:34:26.790 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.72
2026-01-20 18:34:26.790 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:26.790 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:34:26.790 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.mlp.gate_proj using 512 samples
2026-01-20 18:34:27.394 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:34:27.394 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 380.25
2026-01-20 18:34:27.394 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:27.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:27.395 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.mlp.up_proj using 512 samples
2026-01-20 18:34:27.996 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:34:27.997 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 137.08
2026-01-20 18:34:27.997 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:27.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:27.997 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.8.mlp.down_proj using 512 samples
2026-01-20 18:34:31.211 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.21s
2026-01-20 18:34:31.212 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 25.51
2026-01-20 18:34:31.212 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:31.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:34:31.213 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:34:39.645 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:34:39.645 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.q_proj using 512 samples
2026-01-20 18:34:40.194 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:34:40.194 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 155.81
2026-01-20 18:34:40.194 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:40.194 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:34:40.195 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.k_proj using 512 samples
2026-01-20 18:34:40.715 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:34:40.715 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 19.19
2026-01-20 18:34:40.716 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:40.716 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:40.716 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.v_proj using 512 samples
2026-01-20 18:34:41.235 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:34:41.235 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.33
2026-01-20 18:34:41.235 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:41.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:41.236 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.self_attn.o_proj using 512 samples
2026-01-20 18:34:41.790 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:34:41.790 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.06
2026-01-20 18:34:41.790 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:41.791 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:34:41.791 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.mlp.gate_proj using 512 samples
2026-01-20 18:34:42.392 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:34:42.393 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 324.70
2026-01-20 18:34:42.393 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:42.394 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.mlp.up_proj using 512 samples
2026-01-20 18:34:42.993 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.60s
2026-01-20 18:34:42.993 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 151.28
2026-01-20 18:34:42.993 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:42.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:42.994 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.9.mlp.down_proj using 512 samples
2026-01-20 18:34:46.312 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.32s
2026-01-20 18:34:46.315 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 31.00
2026-01-20 18:34:46.315 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:46.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:34:46.315 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:34:54.808 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:34:54.808 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.q_proj using 512 samples
2026-01-20 18:34:55.348 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:34:55.348 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 169.90
2026-01-20 18:34:55.349 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:34:55.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:34:55.349 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.k_proj using 512 samples
2026-01-20 18:34:55.853 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.50s
2026-01-20 18:34:55.853 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 25.77
2026-01-20 18:34:55.853 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:34:55.853 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:55.854 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.v_proj using 512 samples
2026-01-20 18:34:56.392 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:34:56.392 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 7.41
2026-01-20 18:34:56.392 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:34:56.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:34:56.393 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.self_attn.o_proj using 512 samples
2026-01-20 18:34:56.918 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:34:56.918 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.25
2026-01-20 18:34:56.918 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:56.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:34:56.919 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.mlp.gate_proj using 512 samples
2026-01-20 18:34:57.483 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:34:57.484 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 344.20
2026-01-20 18:34:57.484 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:57.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:57.484 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.mlp.up_proj using 512 samples
2026-01-20 18:34:58.046 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:34:58.046 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 150.41
2026-01-20 18:34:58.047 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:34:58.047 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:34:58.047 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.10.mlp.down_proj using 512 samples
2026-01-20 18:35:01.240 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.19s
2026-01-20 18:35:01.242 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.24
2026-01-20 18:35:01.242 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:01.242 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:35:01.242 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:35:09.727 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:35:09.728 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.q_proj using 512 samples
2026-01-20 18:35:10.260 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:35:10.261 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 149.14
2026-01-20 18:35:10.261 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:10.261 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:35:10.261 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.k_proj using 512 samples
2026-01-20 18:35:10.764 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.50s
2026-01-20 18:35:10.764 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 23.10
2026-01-20 18:35:10.764 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:10.764 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:10.765 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.v_proj using 512 samples
2026-01-20 18:35:11.276 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:35:11.276 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.13
2026-01-20 18:35:11.277 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:11.277 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:11.277 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.self_attn.o_proj using 512 samples
2026-01-20 18:35:11.788 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:35:11.789 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.44
2026-01-20 18:35:11.789 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:11.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:35:11.789 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.mlp.gate_proj using 512 samples
2026-01-20 18:35:12.350 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:35:12.351 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 457.26
2026-01-20 18:35:12.351 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:12.351 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:12.351 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.mlp.up_proj using 512 samples
2026-01-20 18:35:12.906 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:35:12.906 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 166.09
2026-01-20 18:35:12.907 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:12.907 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:12.907 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.11.mlp.down_proj using 512 samples
2026-01-20 18:35:16.092 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.19s
2026-01-20 18:35:16.094 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 24.37
2026-01-20 18:35:16.094 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:16.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:35:16.095 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:35:24.515 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:35:24.515 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.q_proj using 512 samples
2026-01-20 18:35:25.066 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:35:25.067 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 169.39
2026-01-20 18:35:25.078 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:25.078 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:35:25.079 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.k_proj using 512 samples
2026-01-20 18:35:25.608 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:35:25.608 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.74
2026-01-20 18:35:25.609 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:25.609 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:25.609 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.v_proj using 512 samples
2026-01-20 18:35:26.151 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:35:26.151 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.83
2026-01-20 18:35:26.151 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:26.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:26.152 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.self_attn.o_proj using 512 samples
2026-01-20 18:35:26.708 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:35:26.709 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.96
2026-01-20 18:35:26.709 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:26.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:35:26.709 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.mlp.gate_proj using 512 samples
2026-01-20 18:35:27.287 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:35:27.288 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 318.56
2026-01-20 18:35:27.288 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:27.288 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:27.288 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.mlp.up_proj using 512 samples
2026-01-20 18:35:27.867 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:35:27.868 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 162.58
2026-01-20 18:35:27.868 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:27.868 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:27.868 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.12.mlp.down_proj using 512 samples
2026-01-20 18:35:31.002 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.13s
2026-01-20 18:35:31.004 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.92
2026-01-20 18:35:31.004 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:31.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:35:31.004 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:35:39.422 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:35:39.422 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.q_proj using 512 samples
2026-01-20 18:35:39.953 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:35:39.953 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 121.74
2026-01-20 18:35:39.954 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:35:39.954 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:35:39.954 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.k_proj using 512 samples
2026-01-20 18:35:40.491 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:35:40.491 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 22.35
2026-01-20 18:35:40.492 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:35:40.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:40.492 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.v_proj using 512 samples
2026-01-20 18:35:41.043 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:35:41.043 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 7.27
2026-01-20 18:35:41.043 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:35:41.043 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:41.044 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.self_attn.o_proj using 512 samples
2026-01-20 18:35:41.596 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:35:41.597 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 5.72
2026-01-20 18:35:41.597 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:41.597 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:35:41.597 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.mlp.gate_proj using 512 samples
2026-01-20 18:35:42.175 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:35:42.175 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 279.44
2026-01-20 18:35:42.175 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:42.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:42.176 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.mlp.up_proj using 512 samples
2026-01-20 18:35:42.752 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:35:42.753 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 163.18
2026-01-20 18:35:42.753 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:35:42.753 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:42.753 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.13.mlp.down_proj using 512 samples
2026-01-20 18:35:46.042 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.29s
2026-01-20 18:35:46.044 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 21.84
2026-01-20 18:35:46.044 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:46.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:35:46.045 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:35:54.538 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:35:54.538 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.q_proj using 512 samples
2026-01-20 18:35:55.069 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:35:55.070 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 230.77
2026-01-20 18:35:55.071 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:55.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:35:55.071 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.k_proj using 512 samples
2026-01-20 18:35:55.586 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:35:55.586 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 33.21
2026-01-20 18:35:55.587 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:55.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:55.587 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.v_proj using 512 samples
2026-01-20 18:35:56.105 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:35:56.106 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 13.84
2026-01-20 18:35:56.106 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:56.106 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:35:56.106 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.self_attn.o_proj using 512 samples
2026-01-20 18:35:56.626 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:35:56.626 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.59
2026-01-20 18:35:56.627 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:56.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:35:56.627 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.mlp.gate_proj using 512 samples
2026-01-20 18:35:57.168 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:35:57.168 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 313.84
2026-01-20 18:35:57.169 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:57.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:57.169 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.mlp.up_proj using 512 samples
2026-01-20 18:35:57.696 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:35:57.697 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 176.39
2026-01-20 18:35:57.697 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:35:57.697 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:35:57.697 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.14.mlp.down_proj using 512 samples
2026-01-20 18:36:00.819 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.12s
2026-01-20 18:36:00.821 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 36.01
2026-01-20 18:36:00.821 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:00.821 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:36:00.821 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:36:09.311 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:36:09.311 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.q_proj using 512 samples
2026-01-20 18:36:09.835 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:36:09.835 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 628.03
2026-01-20 18:36:09.835 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:09.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:36:09.836 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.k_proj using 512 samples
2026-01-20 18:36:10.368 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:36:10.368 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 24.25
2026-01-20 18:36:10.369 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:10.369 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:10.369 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.v_proj using 512 samples
2026-01-20 18:36:10.871 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.50s
2026-01-20 18:36:10.871 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 10.73
2026-01-20 18:36:10.871 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:10.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:10.872 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.self_attn.o_proj using 512 samples
2026-01-20 18:36:11.381 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:36:11.381 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 9.77
2026-01-20 18:36:11.381 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:11.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:36:11.381 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.mlp.gate_proj using 512 samples
2026-01-20 18:36:11.918 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:36:11.919 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 353.27
2026-01-20 18:36:11.919 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:11.919 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:11.919 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.mlp.up_proj using 512 samples
2026-01-20 18:36:12.454 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:36:12.455 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 183.91
2026-01-20 18:36:12.455 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:12.455 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:12.456 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.15.mlp.down_proj using 512 samples
2026-01-20 18:36:15.527 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.07s
2026-01-20 18:36:15.529 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 39.45
2026-01-20 18:36:15.529 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:15.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:36:15.529 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:36:24.008 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:36:24.008 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.q_proj using 512 samples
2026-01-20 18:36:24.569 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:36:24.569 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 205.80
2026-01-20 18:36:24.570 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:36:24.570 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:36:24.570 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.k_proj using 512 samples
2026-01-20 18:36:25.098 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:36:25.099 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 42.26
2026-01-20 18:36:25.105 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:36:25.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:25.105 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.v_proj using 512 samples
2026-01-20 18:36:25.659 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:36:25.659 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 12.36
2026-01-20 18:36:25.659 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:36:25.659 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:25.660 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.self_attn.o_proj using 512 samples
2026-01-20 18:36:26.213 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:36:26.214 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.35
2026-01-20 18:36:26.214 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:26.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:36:26.214 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.mlp.gate_proj using 512 samples
2026-01-20 18:36:26.793 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:36:26.793 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 351.94
2026-01-20 18:36:26.793 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:26.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:26.794 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.mlp.up_proj using 512 samples
2026-01-20 18:36:27.373 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:36:27.374 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 210.92
2026-01-20 18:36:27.374 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:27.374 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:27.374 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.16.mlp.down_proj using 512 samples
2026-01-20 18:36:30.602 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.23s
2026-01-20 18:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 36.19
2026-01-20 18:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:36:30.604 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:36:39.084 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:36:39.084 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.q_proj using 512 samples
2026-01-20 18:36:39.606 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:36:39.606 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 191.20
2026-01-20 18:36:39.606 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:39.606 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:36:39.606 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.k_proj using 512 samples
2026-01-20 18:36:40.176 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:36:40.176 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 29.29
2026-01-20 18:36:40.177 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:40.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:40.177 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.v_proj using 512 samples
2026-01-20 18:36:40.726 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:36:40.726 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 15.14
2026-01-20 18:36:40.727 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:40.727 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:40.727 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.self_attn.o_proj using 512 samples
2026-01-20 18:36:41.279 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:36:41.280 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6.76
2026-01-20 18:36:41.280 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:41.280 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:36:41.280 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.mlp.gate_proj using 512 samples
2026-01-20 18:36:41.854 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:36:41.854 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 398.48
2026-01-20 18:36:41.854 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:41.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:41.855 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.mlp.up_proj using 512 samples
2026-01-20 18:36:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:36:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 211.66
2026-01-20 18:36:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:42.430 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.17.mlp.down_proj using 512 samples
2026-01-20 18:36:45.698 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.27s
2026-01-20 18:36:45.700 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 34.87
2026-01-20 18:36:45.700 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:36:45.700 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:36:45.700 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:36:54.158 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:36:54.158 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.q_proj using 512 samples
2026-01-20 18:36:54.679 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:36:54.680 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 174.08
2026-01-20 18:36:54.680 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:54.680 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:36:54.680 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.k_proj using 512 samples
2026-01-20 18:36:55.219 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:36:55.219 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 33.30
2026-01-20 18:36:55.220 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:55.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:55.220 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.v_proj using 512 samples
2026-01-20 18:36:55.770 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:36:55.770 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 15.59
2026-01-20 18:36:55.770 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:55.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:36:55.771 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.self_attn.o_proj using 512 samples
2026-01-20 18:36:56.305 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:36:56.305 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 9.06
2026-01-20 18:36:56.305 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:56.305 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:36:56.306 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.mlp.gate_proj using 512 samples
2026-01-20 18:36:56.869 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:36:56.870 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 422.07
2026-01-20 18:36:56.870 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:56.870 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:56.870 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.mlp.up_proj using 512 samples
2026-01-20 18:36:57.420 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:36:57.421 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 238.08
2026-01-20 18:36:57.421 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:36:57.421 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:36:57.421 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.18.mlp.down_proj using 512 samples
2026-01-20 18:37:00.787 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.37s
2026-01-20 18:37:00.789 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 49.14
2026-01-20 18:37:00.789 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:00.790 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:37:00.790 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:37:09.291 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:37:09.291 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.q_proj using 512 samples
2026-01-20 18:37:09.835 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:37:09.836 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 197.08
2026-01-20 18:37:09.836 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:37:09.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:37:09.836 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.k_proj using 512 samples
2026-01-20 18:37:10.385 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:37:10.385 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 43.47
2026-01-20 18:37:10.385 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:37:10.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:10.386 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.v_proj using 512 samples
2026-01-20 18:37:10.910 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:37:10.910 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 19.83
2026-01-20 18:37:10.911 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:37:10.911 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:10.911 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.self_attn.o_proj using 512 samples
2026-01-20 18:37:11.419 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:37:11.420 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 11.09
2026-01-20 18:37:11.420 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:37:11.420 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:37:11.420 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.mlp.gate_proj using 512 samples
2026-01-20 18:37:12.007 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:37:12.007 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 550.09
2026-01-20 18:37:12.007 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:37:12.007 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:12.008 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.mlp.up_proj using 512 samples
2026-01-20 18:37:12.539 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:37:12.539 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 311.87
2026-01-20 18:37:12.539 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:37:12.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:12.540 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.19.mlp.down_proj using 512 samples
2026-01-20 18:37:15.797 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.26s
2026-01-20 18:37:15.799 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 84.67
2026-01-20 18:37:15.800 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:15.800 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:37:15.800 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:37:24.273 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:37:24.273 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.q_proj using 512 samples
2026-01-20 18:37:24.864 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.59s
2026-01-20 18:37:24.864 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 298.63
2026-01-20 18:37:24.864 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:24.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:37:24.865 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.k_proj using 512 samples
2026-01-20 18:37:25.445 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:37:25.445 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 64.28
2026-01-20 18:37:25.445 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:25.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:25.446 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.v_proj using 512 samples
2026-01-20 18:37:26.026 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:37:26.026 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 29.34
2026-01-20 18:37:26.026 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:26.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:26.027 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.self_attn.o_proj using 512 samples
2026-01-20 18:37:26.596 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:37:26.596 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 16.71
2026-01-20 18:37:26.597 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:26.597 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:37:26.597 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.mlp.gate_proj using 512 samples
2026-01-20 18:37:27.165 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:37:27.166 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 644.48
2026-01-20 18:37:27.166 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:27.166 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:27.166 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.mlp.up_proj using 512 samples
2026-01-20 18:37:27.701 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:37:27.701 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 324.37
2026-01-20 18:37:27.701 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:27.702 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:27.702 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.20.mlp.down_proj using 512 samples
2026-01-20 18:37:30.830 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.13s
2026-01-20 18:37:30.832 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 71.26
2026-01-20 18:37:30.832 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:30.832 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:37:30.833 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:37:39.293 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:37:39.293 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.q_proj using 512 samples
2026-01-20 18:37:39.855 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:37:39.855 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 372.63
2026-01-20 18:37:39.856 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:39.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:37:39.856 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.k_proj using 512 samples
2026-01-20 18:37:40.409 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:37:40.410 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 58.38
2026-01-20 18:37:40.410 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:40.410 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:40.410 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.v_proj using 512 samples
2026-01-20 18:37:40.960 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:37:40.961 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 29.95
2026-01-20 18:37:40.961 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:40.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:40.961 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.self_attn.o_proj using 512 samples
2026-01-20 18:37:41.511 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:37:41.511 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 8.42
2026-01-20 18:37:41.511 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:41.512 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:37:41.512 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.mlp.gate_proj using 512 samples
2026-01-20 18:37:42.089 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.58s
2026-01-20 18:37:42.089 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 823.92
2026-01-20 18:37:42.089 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:42.089 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:42.090 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.mlp.up_proj using 512 samples
2026-01-20 18:37:42.664 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:37:42.665 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 441.76
2026-01-20 18:37:42.665 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:42.665 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:42.665 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.21.mlp.down_proj using 512 samples
2026-01-20 18:37:45.921 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.26s
2026-01-20 18:37:45.923 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 111.29
2026-01-20 18:37:45.924 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:45.924 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:37:45.924 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:37:54.385 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:37:54.386 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.q_proj using 512 samples
2026-01-20 18:37:54.921 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:37:54.921 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 317.40
2026-01-20 18:37:54.921 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:37:54.922 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:37:54.922 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.k_proj using 512 samples
2026-01-20 18:37:55.459 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:37:55.460 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 55.38
2026-01-20 18:37:55.460 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:37:55.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:55.460 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.v_proj using 512 samples
2026-01-20 18:37:55.964 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.50s
2026-01-20 18:37:55.964 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 48.62
2026-01-20 18:37:55.965 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.53% | total memory: 25 GB
2026-01-20 18:37:55.965 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:37:55.965 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.self_attn.o_proj using 512 samples
2026-01-20 18:37:56.504 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:37:56.504 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 16.06
2026-01-20 18:37:56.504 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:56.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:37:56.504 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.mlp.gate_proj using 512 samples
2026-01-20 18:37:57.052 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:37:57.052 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 994.69
2026-01-20 18:37:57.052 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:57.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:57.053 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.mlp.up_proj using 512 samples
2026-01-20 18:37:57.601 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:37:57.602 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 534.24
2026-01-20 18:37:57.602 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:37:57.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:37:57.602 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.22.mlp.down_proj using 512 samples
2026-01-20 18:38:00.905 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.30s
2026-01-20 18:38:00.907 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 143.98
2026-01-20 18:38:00.907 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:00.907 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:38:00.907 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:38:09.358 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:38:09.359 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.q_proj using 512 samples
2026-01-20 18:38:09.881 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:38:09.882 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 411.61
2026-01-20 18:38:09.882 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:09.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:38:09.882 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.k_proj using 512 samples
2026-01-20 18:38:10.411 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:38:10.412 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 81.33
2026-01-20 18:38:10.412 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:10.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:10.412 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.v_proj using 512 samples
2026-01-20 18:38:10.918 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:38:10.919 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 66.87
2026-01-20 18:38:10.919 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:10.919 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:10.919 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.self_attn.o_proj using 512 samples
2026-01-20 18:38:11.440 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:38:11.440 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 26.32
2026-01-20 18:38:11.440 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:11.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:38:11.441 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.mlp.gate_proj using 512 samples
2026-01-20 18:38:11.960 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:38:11.960 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 936.91
2026-01-20 18:38:11.960 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:11.960 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:11.961 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.mlp.up_proj using 512 samples
2026-01-20 18:38:12.476 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:38:12.477 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 519.94
2026-01-20 18:38:12.477 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:12.477 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:12.477 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.23.mlp.down_proj using 512 samples
2026-01-20 18:38:15.558 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.08s
2026-01-20 18:38:15.560 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 168.43
2026-01-20 18:38:15.560 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:15.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:38:15.561 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:38:24.021 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:38:24.021 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.q_proj using 512 samples
2026-01-20 18:38:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:38:24.586 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 351.35
2026-01-20 18:38:24.586 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:24.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:38:24.586 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.k_proj using 512 samples
2026-01-20 18:38:25.139 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:38:25.140 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 51.91
2026-01-20 18:38:25.140 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:25.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:25.140 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.v_proj using 512 samples
2026-01-20 18:38:25.690 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:38:25.691 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 133.26
2026-01-20 18:38:25.691 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:25.691 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:25.691 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.self_attn.o_proj using 512 samples
2026-01-20 18:38:26.245 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:38:26.245 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 36.09
2026-01-20 18:38:26.245 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:26.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:38:26.246 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.mlp.gate_proj using 512 samples
2026-01-20 18:38:26.789 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:38:26.789 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 893.76
2026-01-20 18:38:26.790 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:26.790 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:26.790 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.mlp.up_proj using 512 samples
2026-01-20 18:38:27.309 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:38:27.310 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 510.14
2026-01-20 18:38:27.310 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:27.310 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:27.310 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.24.mlp.down_proj using 512 samples
2026-01-20 18:38:30.411 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.10s
2026-01-20 18:38:30.412 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 168.61
2026-01-20 18:38:30.413 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:30.413 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:38:30.413 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:38:38.886 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:38:38.886 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.q_proj using 512 samples
2026-01-20 18:38:39.453 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 18:38:39.454 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 242.10
2026-01-20 18:38:39.454 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:38:39.454 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:38:39.454 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.k_proj using 512 samples
2026-01-20 18:38:40.008 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:38:40.009 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 52.04
2026-01-20 18:38:40.009 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:38:40.009 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:40.009 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.v_proj using 512 samples
2026-01-20 18:38:40.557 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:38:40.557 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 238.12
2026-01-20 18:38:40.557 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.28% | total memory: 25 GB
2026-01-20 18:38:40.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:40.558 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.self_attn.o_proj using 512 samples
2026-01-20 18:38:41.107 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:38:41.108 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 61.86
2026-01-20 18:38:41.108 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:41.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:38:41.108 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.mlp.gate_proj using 512 samples
2026-01-20 18:38:41.671 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:38:41.672 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 950.83
2026-01-20 18:38:41.672 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:41.672 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:41.672 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.mlp.up_proj using 512 samples
2026-01-20 18:38:42.234 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 18:38:42.234 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 602.71
2026-01-20 18:38:42.234 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 8.29% | total memory: 25 GB
2026-01-20 18:38:42.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:42.235 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.25.mlp.down_proj using 512 samples
2026-01-20 18:38:45.527 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.29s
2026-01-20 18:38:45.529 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 240.71
2026-01-20 18:38:45.529 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:45.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:38:45.529 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:38:53.956 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:38:53.957 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.q_proj using 512 samples
2026-01-20 18:38:54.484 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:38:54.485 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 484.73
2026-01-20 18:38:54.485 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:54.485 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:38:54.485 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.k_proj using 512 samples
2026-01-20 18:38:54.993 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:38:54.993 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 73.92
2026-01-20 18:38:54.994 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:54.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:54.994 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.v_proj using 512 samples
2026-01-20 18:38:55.518 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:38:55.519 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 299.91
2026-01-20 18:38:55.519 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:55.519 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:38:55.519 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.self_attn.o_proj using 512 samples
2026-01-20 18:38:56.051 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:38:56.052 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 48.81
2026-01-20 18:38:56.052 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:56.052 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:38:56.053 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.mlp.gate_proj using 512 samples
2026-01-20 18:38:56.606 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 18:38:56.607 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1099.14
2026-01-20 18:38:56.607 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:56.607 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:56.608 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.mlp.up_proj using 512 samples
2026-01-20 18:38:57.129 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:38:57.129 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 738.75
2026-01-20 18:38:57.129 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:38:57.129 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:38:57.130 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.26.mlp.down_proj using 512 samples
2026-01-20 18:39:00.408 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.28s
2026-01-20 18:39:00.410 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 370.18
2026-01-20 18:39:00.410 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:00.410 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:39:00.411 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:39:08.911 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:39:08.911 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.q_proj using 512 samples
2026-01-20 18:39:09.441 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 18:39:09.442 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 527.34
2026-01-20 18:39:09.442 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:09.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 18:39:09.442 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.k_proj using 512 samples
2026-01-20 18:39:09.951 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.51s
2026-01-20 18:39:09.952 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 76.98
2026-01-20 18:39:09.952 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:09.952 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:39:09.952 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.v_proj using 512 samples
2026-01-20 18:39:10.476 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:39:10.477 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 335.76
2026-01-20 18:39:10.477 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:10.477 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 18:39:10.477 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.self_attn.o_proj using 512 samples
2026-01-20 18:39:10.997 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:39:10.998 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 132.12
2026-01-20 18:39:10.998 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:10.998 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 18:39:10.998 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.mlp.gate_proj using 512 samples
2026-01-20 18:39:11.520 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 18:39:11.520 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1214.51
2026-01-20 18:39:11.520 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:11.521 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:39:11.521 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.mlp.up_proj using 512 samples
2026-01-20 18:39:12.059 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 18:39:12.059 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 2627.04
2026-01-20 18:39:12.059 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:12.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 18:39:12.060 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.27.mlp.down_proj using 512 samples
2026-01-20 18:39:15.200 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.14s
2026-01-20 18:39:15.202 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 838.25
2026-01-20 18:39:15.202 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.54% | total memory: 25 GB
2026-01-20 18:39:15.202 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 18:39:15.203 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:39:21.979 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 18:39:21.979 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:39:27.095 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2026-01-20 18:39:27.100 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:39:27.104 | DEBUG    | llmcompressor.core.lifecycle:finalize:134 - Finalizing compression lifecycle
2026-01-20 18:39:27.104 | DEBUG    | llmcompressor.core.lifecycle:finalize:138 - Finalized modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=True started_=True ended_=True smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 18:39:27.104 | DEBUG    | llmcompressor.core.lifecycle:finalize:138 - Finalized modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=True started_=True ended_=True sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 18:39:27.104 | INFO     | llmcompressor.core.lifecycle:finalize:144 - Compression lifecycle finalized for 2 modifiers
2026-01-20 18:39:27.146 | INFO     | llmcompressor.transformers.sparsification.compressed_tensors_utils:get_model_compressor:195 - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.
2026-01-20 18:39:29.224 | DEBUG    | llmcompressor.transformers.utils.helpers:infer_recipe_from_model_path:105 - No recipe found in the model_path: /root/autodl-tmp/Model/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306
