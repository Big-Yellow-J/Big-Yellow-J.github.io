2026-01-20 15:42:23.891 | INFO     | llmcompressor.metrics.logger:_create_default_logger:356 - Logging all LLM Compressor modifier-level logs to sparse_logs/20-01-2026_15.42.23.log
2026-01-20 15:42:23.892 | DEBUG    | llmcompressor.core.lifecycle:initialize:92 - Initializing compression lifecycle
2026-01-20 15:42:23.892 | INFO     | llmcompressor.recipe.recipe:from_modifiers:68 - Creating recipe from modifiers
2026-01-20 15:42:23.893 | INFO     | llmcompressor.modifiers.smoothquant.base:_infer_mappings_from_model:188 - No SmoothQuantModifier.mappings provided, inferring from model...
2026-01-20 15:42:24.756 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:42:24.785 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 15:42:24.785 | INFO     | llmcompressor.core.lifecycle:initialize:110 - Compression lifecycle initialized for 2 modifiers
2026-01-20 15:42:24.785 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `SmoothQuantModifier`
2026-01-20 15:42:25.236 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:42:25.237 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2026-01-20 15:42:25.237 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:42:25.237 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:42:25.237 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2026-01-20 15:42:25.237 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:42:25.237 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:42:25.238 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache()
    return (past_key_values,)
2026-01-20 15:42:25.238 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:42:25.238 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:42:25.239 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2026-01-20 15:42:25.239 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:42:25.239 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:42:25.239 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2026-01-20 15:42:25.239 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:42:25.239 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:42:25.240 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids, *, causal_mask_mapping=None, mask_kwargs=None):
    if not isinstance((causal_mask_mapping := attention_mask), dict):
        mask_kwargs = {'config': self.config, 'input_embeds': inputs_embeds, 'attention_mask': attention_mask, 'cache_position': cache_position, 'past_key_values': past_key_values, 'position_ids': position_ids}
        causal_mask_mapping = {'full_attention': create_causal_mask(**mask_kwargs)}
        if self.has_sliding_layers:
            causal_mask_mapping['sliding_attention'] = create_sliding_window_causal_mask(**mask_kwargs)
    return (causal_mask_mapping, mask_kwargs)
2026-01-20 15:42:25.240 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:42:25.244 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:42:25.244 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2026-01-20 15:42:25.244 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:42:25.319 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2026-01-20 15:42:25.319 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27493ce0>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274743b0>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274749b0>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274855b0>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27476a20>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274746e0>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475d00>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27476090>
2026-01-20 15:42:25.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274767b0>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27476ff0>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475430>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27477740>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27476d80>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27477e90>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475730>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27474ef0>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27474e60>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274752e0>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27476ed0>
2026-01-20 15:42:25.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27477b90>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27477020>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27477470>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475970>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749a900>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475760>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27476e70>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27493200>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475160>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475c10>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274740b0>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274772c0>
2026-01-20 15:42:25.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274764e0>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27490ef0>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e274769f0>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27474890>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e27477200>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749f380>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749f110>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749ed20>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749f1a0>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749e810>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749eb40>
2026-01-20 15:42:25.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749ec90>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749c320>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749cec0>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749d100>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749c1a0>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749d220>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749d880>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749daf0>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749df40>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749e150>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749e390>
2026-01-20 15:42:25.324 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749e7e0>
2026-01-20 15:42:25.325 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749e990>
2026-01-20 15:42:25.325 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749ec00>
2026-01-20 15:42:25.325 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:42:29.981 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:42:29.981 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.0.input_layernorm
2026-01-20 15:42:29.990 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.0.post_attention_layernorm
2026-01-20 15:42:29.991 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:02.636 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:02.637 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.1.input_layernorm
2026-01-20 15:43:02.638 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.1.post_attention_layernorm
2026-01-20 15:43:02.640 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:06.323 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:06.324 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.2.input_layernorm
2026-01-20 15:43:06.326 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.2.post_attention_layernorm
2026-01-20 15:43:06.327 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:09.937 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:09.937 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.3.input_layernorm
2026-01-20 15:43:09.939 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.3.post_attention_layernorm
2026-01-20 15:43:09.941 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:13.542 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:13.542 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.4.input_layernorm
2026-01-20 15:43:13.545 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.4.post_attention_layernorm
2026-01-20 15:43:13.546 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:17.199 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:17.200 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.5.input_layernorm
2026-01-20 15:43:17.201 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.5.post_attention_layernorm
2026-01-20 15:43:17.203 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:20.851 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:20.851 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.6.input_layernorm
2026-01-20 15:43:20.854 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.6.post_attention_layernorm
2026-01-20 15:43:20.855 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:24.415 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:24.416 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.7.input_layernorm
2026-01-20 15:43:24.418 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.7.post_attention_layernorm
2026-01-20 15:43:24.419 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:27.992 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:27.992 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.8.input_layernorm
2026-01-20 15:43:27.994 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.8.post_attention_layernorm
2026-01-20 15:43:27.996 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:31.551 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:31.551 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.9.input_layernorm
2026-01-20 15:43:31.553 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.9.post_attention_layernorm
2026-01-20 15:43:31.555 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:35.153 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:35.153 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.10.input_layernorm
2026-01-20 15:43:35.155 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.10.post_attention_layernorm
2026-01-20 15:43:35.157 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:38.774 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:38.775 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.11.input_layernorm
2026-01-20 15:43:38.777 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.11.post_attention_layernorm
2026-01-20 15:43:38.778 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:42.390 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:42.390 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.12.input_layernorm
2026-01-20 15:43:42.392 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.12.post_attention_layernorm
2026-01-20 15:43:42.393 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:45.947 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:45.948 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.13.input_layernorm
2026-01-20 15:43:45.949 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.13.post_attention_layernorm
2026-01-20 15:43:45.951 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:49.533 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:49.533 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.14.input_layernorm
2026-01-20 15:43:49.535 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.14.post_attention_layernorm
2026-01-20 15:43:49.536 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:53.123 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:53.124 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.15.input_layernorm
2026-01-20 15:43:53.125 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.15.post_attention_layernorm
2026-01-20 15:43:53.126 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:43:56.847 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:43:56.848 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.16.input_layernorm
2026-01-20 15:43:56.850 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.16.post_attention_layernorm
2026-01-20 15:43:56.851 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:00.479 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:00.480 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.17.input_layernorm
2026-01-20 15:44:00.481 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.17.post_attention_layernorm
2026-01-20 15:44:00.483 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:04.083 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:04.083 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.18.input_layernorm
2026-01-20 15:44:04.085 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.18.post_attention_layernorm
2026-01-20 15:44:04.087 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:07.680 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:07.681 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.19.input_layernorm
2026-01-20 15:44:07.683 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.19.post_attention_layernorm
2026-01-20 15:44:07.684 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:11.265 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:11.266 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.20.input_layernorm
2026-01-20 15:44:11.267 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.20.post_attention_layernorm
2026-01-20 15:44:11.269 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:14.856 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:14.857 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.21.input_layernorm
2026-01-20 15:44:14.859 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.21.post_attention_layernorm
2026-01-20 15:44:14.861 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:18.474 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:18.474 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.22.input_layernorm
2026-01-20 15:44:18.476 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.22.post_attention_layernorm
2026-01-20 15:44:18.478 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:22.096 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:22.097 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.23.input_layernorm
2026-01-20 15:44:22.099 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.23.post_attention_layernorm
2026-01-20 15:44:22.100 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:25.667 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:25.667 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.24.input_layernorm
2026-01-20 15:44:25.669 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.24.post_attention_layernorm
2026-01-20 15:44:25.671 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:29.223 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:29.224 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.25.input_layernorm
2026-01-20 15:44:29.225 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.25.post_attention_layernorm
2026-01-20 15:44:29.227 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:32.790 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:32.791 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.26.input_layernorm
2026-01-20 15:44:32.793 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.26.post_attention_layernorm
2026-01-20 15:44:32.794 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:36.412 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:36.413 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.27.input_layernorm
2026-01-20 15:44:36.415 | INFO     | llmcompressor.modifiers.smoothquant.base:_apply_smoothing:276 - Smoothing with model.layers.27.post_attention_layernorm
2026-01-20 15:44:36.416 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:43.233 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:43.233 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:48.288 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2026-01-20 15:44:48.288 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True smoothing_strength=0.8 mappings=[LayerMap(balance_layers=['re:.*q_proj', 're:.*k_proj', 're:.*v_proj'], smooth_layers='re:.*input_layernorm'), LayerMap(balance_layers=['re:.*gate_proj', 're:.*up_proj'], smooth_layers='re:.*post_attention_layernorm')] ignore=[] num_calibration_steps=None calibration_function=None
2026-01-20 15:44:48.292 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `GPTQModifier`
2026-01-20 15:44:48.414 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:44:48.414 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2026-01-20 15:44:48.414 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:44:48.414 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:44:48.415 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2026-01-20 15:44:48.415 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:44:48.415 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:44:48.415 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache()
    return (past_key_values,)
2026-01-20 15:44:48.415 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:44:48.415 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:44:48.416 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2026-01-20 15:44:48.416 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:44:48.416 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:44:48.416 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2026-01-20 15:44:48.416 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:44:48.417 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:44:48.417 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids, *, causal_mask_mapping=None, mask_kwargs=None):
    if not isinstance((causal_mask_mapping := attention_mask), dict):
        mask_kwargs = {'config': self.config, 'input_embeds': inputs_embeds, 'attention_mask': attention_mask, 'cache_position': cache_position, 'past_key_values': past_key_values, 'position_ids': position_ids}
        causal_mask_mapping = {'full_attention': create_causal_mask(**mask_kwargs)}
        if self.has_sliding_layers:
            causal_mask_mapping['sliding_attention'] = create_sliding_window_causal_mask(**mask_kwargs)
    return (causal_mask_mapping, mask_kwargs)
2026-01-20 15:44:48.417 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:44:48.421 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-01-20 15:44:48.421 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2026-01-20 15:44:48.421 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-01-20 15:44:48.479 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2026-01-20 15:44:48.484 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27493ce0>
2026-01-20 15:44:48.484 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27475be0>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2747f890>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2747fbc0>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2746a510>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721d5b0>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721dd30>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721e720>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721e1e0>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721d100>
2026-01-20 15:44:48.485 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721daf0>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721f860>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27480d40>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721cf80>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721c9e0>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721e000>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721f4d0>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721cce0>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de721ca70>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72ff410>
2026-01-20 15:44:48.486 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72fce30>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72febd0>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72fc6e0>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72ff470>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72ff080>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72ffc20>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27477230>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a516a0>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2c3adee0>
2026-01-20 15:44:48.487 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50e30>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50590>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a53da0>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a53ce0>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a53890>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2745e480>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a538c0>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50aa0>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a504d0>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a52360>
2026-01-20 15:44:48.488 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a518b0>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50e90>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a522d0>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a52180>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50fb0>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51160>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a52ab0>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2749a000>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a532c0>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a528a0>
2026-01-20 15:44:48.489 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a52cf0>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51a60>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50c80>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51d60>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50350>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a53bc0>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a53e30>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51220>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50710>
2026-01-20 15:44:48.490 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50bc0>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50b60>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50b90>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a525a0>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a50ce0>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51460>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51fd0>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51be0>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51eb0>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a53b90>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a523f0>
2026-01-20 15:44:48.491 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a52e40>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51af0>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51760>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a24dd0>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a252b0>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a24950>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a26ff0>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a24b30>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27050>
2026-01-20 15:44:48.492 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a24f50>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a250d0>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a25580>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a247d0>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a24ef0>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a241a0>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27493e60>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27482a80>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a277a0>
2026-01-20 15:44:48.493 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a26270>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27950>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27470>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27590>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27ce0>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a26e70>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a270b0>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27f20>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a24ce0>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27380>
2026-01-20 15:44:48.494 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2747ea80>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27c80>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27da0>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27e30>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a26e40>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a26ea0>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a274d0>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a26450>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a26d20>
2026-01-20 15:44:48.495 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a25f70>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a24800>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6fe00>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e0f0>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c6b0>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f7d0>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e150>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f5c0>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d3d0>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f8c0>
2026-01-20 15:44:48.496 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6de50>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6dc70>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6cd40>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d190>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c7a0>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e1b0>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6ce00>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d3a0>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f2c0>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c2c0>
2026-01-20 15:44:48.497 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c410>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e270>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e930>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e0c0>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f3e0>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6cf50>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d100>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c290>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6cad0>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d430>
2026-01-20 15:44:48.498 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c5c0>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d8e0>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e274826c0>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27482c00>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6ca70>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c680>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f2f0>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6da90>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d4c0>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6ccb0>
2026-01-20 15:44:48.499 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e2747e1b0>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27492120>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e390>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6fce0>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c140>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6de20>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d9d0>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27476ed0>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e8d0>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6faa0>
2026-01-20 15:44:48.500 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de72fec00>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c4d0>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f830>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6df40>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6dd00>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d130>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e330>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f950>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6ef30>
2026-01-20 15:44:48.501 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6f320>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6df70>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e4e0>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6e420>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6cb90>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a51d00>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6c590>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de4f6d790>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5216fc0>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e274911c0>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217080>
2026-01-20 15:44:48.502 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5216bd0>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27486300>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8e27454e30>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217770>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217f50>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de52174d0>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5215460>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5215d90>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5215130>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de7a27bc0>
2026-01-20 15:44:48.503 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5216ae0>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de52174a0>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217890>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217740>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217f80>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5216c90>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de52175c0>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217650>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5214980>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7f8de5217380>
2026-01-20 15:44:48.504 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 15:44:57.269 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:44:57.270 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.q_proj using 512 samples
2026-01-20 15:44:57.912 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.64s
2026-01-20 15:44:57.913 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 476.86
2026-01-20 15:44:57.914 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.68% | total memory: 25 GB
2026-01-20 15:44:57.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 15:44:57.916 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.k_proj using 512 samples
2026-01-20 15:44:58.463 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 15:44:58.464 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.89
2026-01-20 15:44:58.465 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.68% | total memory: 25 GB
2026-01-20 15:44:58.466 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 15:44:58.468 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.v_proj using 512 samples
2026-01-20 15:44:59.022 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 15:44:59.023 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.66
2026-01-20 15:44:59.024 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.68% | total memory: 25 GB
2026-01-20 15:44:59.025 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 15:44:59.026 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.self_attn.o_proj using 512 samples
2026-01-20 15:44:59.582 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 15:44:59.583 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 2.91
2026-01-20 15:44:59.584 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.68% | total memory: 25 GB
2026-01-20 15:44:59.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 15:44:59.586 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.gate_proj using 512 samples
2026-01-20 15:45:00.147 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 15:45:00.148 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 55.55
2026-01-20 15:45:00.149 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.68% | total memory: 25 GB
2026-01-20 15:45:00.150 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 15:45:00.151 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.up_proj using 512 samples
2026-01-20 15:45:00.669 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.52s
2026-01-20 15:45:00.670 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 34.29
2026-01-20 15:45:00.671 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.68% | total memory: 25 GB
2026-01-20 15:45:00.672 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 15:45:00.673 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.0.mlp.down_proj using 512 samples
2026-01-20 15:45:03.744 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.07s
2026-01-20 15:45:03.746 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.15
2026-01-20 15:45:03.747 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 12.93% | total memory: 25 GB
2026-01-20 15:45:03.748 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 15:45:03.749 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 15:45:18.665 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:45:18.666 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.q_proj using 512 samples
2026-01-20 15:45:19.231 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 15:45:19.233 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 44.84
2026-01-20 15:45:19.234 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.87% | total memory: 25 GB
2026-01-20 15:45:19.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 15:45:19.236 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.k_proj using 512 samples
2026-01-20 15:45:19.791 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.55s
2026-01-20 15:45:19.793 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 11.66
2026-01-20 15:45:19.794 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.87% | total memory: 25 GB
2026-01-20 15:45:19.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 15:45:19.795 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.v_proj using 512 samples
2026-01-20 15:45:20.333 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 15:45:20.334 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.41
2026-01-20 15:45:20.336 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.87% | total memory: 25 GB
2026-01-20 15:45:20.336 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 15:45:20.337 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.self_attn.o_proj using 512 samples
2026-01-20 15:45:20.879 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.54s
2026-01-20 15:45:20.881 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1.07
2026-01-20 15:45:20.882 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.88% | total memory: 25 GB
2026-01-20 15:45:20.883 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 15:45:20.884 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.gate_proj using 512 samples
2026-01-20 15:45:21.456 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 15:45:21.457 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 1657.07
2026-01-20 15:45:21.458 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.88% | total memory: 25 GB
2026-01-20 15:45:21.459 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 15:45:21.459 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.up_proj using 512 samples
2026-01-20 15:45:22.031 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 15:45:22.032 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 728.78
2026-01-20 15:45:22.033 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 9.88% | total memory: 25 GB
2026-01-20 15:45:22.034 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 15:45:22.035 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.1.mlp.down_proj using 512 samples
2026-01-20 15:45:22.173 | WARNING  | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:165 - Failed to invert hessian due to numerical instability. Consider increasing GPTQModifier.dampening_frac, increasing the number of calibration samples, or shuffling the calibration dataset. Falling back to round-to-nearest for this module.
2026-01-20 15:45:25.145 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.11s
2026-01-20 15:45:25.146 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.72
2026-01-20 15:45:25.147 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.13% | total memory: 25 GB
2026-01-20 15:45:25.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 15:45:25.149 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
2026-01-20 15:45:33.622 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-01-20 15:45:33.623 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.q_proj using 512 samples
2026-01-20 15:45:34.197 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 15:45:34.199 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 130.81
2026-01-20 15:45:34.200 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.12% | total memory: 25 GB
2026-01-20 15:45:34.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.726272 MB
2026-01-20 15:45:34.202 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.k_proj using 512 samples
2026-01-20 15:45:34.770 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.57s
2026-01-20 15:45:34.771 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 20.92
2026-01-20 15:45:34.772 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.12% | total memory: 25 GB
2026-01-20 15:45:34.773 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 15:45:34.774 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.v_proj using 512 samples
2026-01-20 15:45:35.339 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.56s
2026-01-20 15:45:35.341 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 3.49
2026-01-20 15:45:35.342 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.12% | total memory: 25 GB
2026-01-20 15:45:35.342 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 0.787712 MB
2026-01-20 15:45:35.343 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.self_attn.o_proj using 512 samples
2026-01-20 15:45:35.873 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.53s
2026-01-20 15:45:35.875 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 0.79
2026-01-20 15:45:35.876 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.12% | total memory: 25 GB
2026-01-20 15:45:35.877 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 4.7232 MB
2026-01-20 15:45:35.878 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.gate_proj using 512 samples
2026-01-20 15:45:36.491 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.61s
2026-01-20 15:45:36.492 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 6185.22
2026-01-20 15:45:36.493 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.12% | total memory: 25 GB
2026-01-20 15:45:36.494 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 15:45:36.495 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.up_proj using 512 samples
2026-01-20 15:45:37.111 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 0.62s
2026-01-20 15:45:37.113 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 739.46
2026-01-20 15:45:37.114 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.12% | total memory: 25 GB
2026-01-20 15:45:37.114 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.552 MB
2026-01-20 15:45:37.116 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:253 - Quantizing model.layers.2.mlp.down_proj using 512 samples
2026-01-20 15:45:40.512 | METRIC   | llmcompressor.utils.metric_logging:compress:127 - time 3.40s
2026-01-20 15:45:40.515 | METRIC   | llmcompressor.utils.metric_logging:compress:129 - error 166.88
2026-01-20 15:45:40.516 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - GPU 0 | usage: 11.12% | total memory: 25 GB
2026-01-20 15:45:40.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - Compressed module size: 27.529728 MB
2026-01-20 15:45:40.518 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='W8A8' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_update=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=None offload_hessians=False
