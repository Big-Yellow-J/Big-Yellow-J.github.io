import os
import matplotlib.pyplot as plt
import pickle
import imageio
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.cuda import is_available as cuda_available
import torch.nn.functional as F

# Constants and Configuration
CONFIG = {
    'batch_size': 128,
    'learning_rate': 2e-4,
    'epochs': 100,
    'latent_dim': 100,
    'image_size': 28,
    'channels': 1,
    'results_dir': 'MNIST_WGAN_GP_results',
    'device': 'cuda:0' if cuda_available() else 'cpu',
    'n_critic': 5,
    'lambda_gp': 10  # Gradient penalty coefficient
}

class Generator(nn.Module):
    """Generator network using transposed convolutions"""
    def __init__(self, latent_dim=100, channels=1, feature_size=64):
        super().__init__()
        self.main = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, feature_size * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(feature_size * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(feature_size * 4, feature_size * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_size * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(feature_size * 2, feature_size, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_size),
            nn.ReLU(True),
            nn.ConvTranspose2d(feature_size, channels, 4, 2, 1, bias=False),
            nn.Tanh()
        )
    
    def forward(self, input):
        input = input.view(input.size(0), input.size(1), 1, 1)
        return self.main(input)

class Discriminator(nn.Module):
    """Critic network using convolutions without BatchNorm"""
    def __init__(self, channels=1, feature_size=64):
        super().__init__()
        self.main = nn.Sequential(
            nn.Conv2d(channels, feature_size, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(feature_size, feature_size * 2, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(feature_size * 2, feature_size * 4, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(feature_size * 4, 1, 4, 1, 0, bias=False),
        )
    
    def forward(self, input):
        if input.size(2) == 28:
            input = F.pad(input, (2, 2, 2, 2), mode='reflect')
        out = self.main(input)
        return out.view(-1)

def compute_gradient_penalty(critic, real_samples, fake_samples, device):
    """Calculate gradient penalty for WGAN-GP"""
    batch_size = real_samples.size(0)
    alpha = torch.rand(batch_size, 1, 1, 1, device=device)
    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)
    critic_interpolates = critic(interpolates)
    grad_outputs = torch.ones_like(critic_interpolates, device=device)
    gradients = torch.autograd.grad(
        outputs=critic_interpolates,
        inputs=interpolates,
        grad_outputs=grad_outputs,
        create_graph=True,
        retain_graph=True
    )[0]
    gradients = gradients.view(batch_size, -1)
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
    return gradient_penalty

def prepare_directories():
    """Create necessary directories for saving results"""
    os.makedirs(CONFIG['results_dir'], exist_ok=True)
    os.makedirs(os.path.join(CONFIG['results_dir'], 'Random_results'), exist_ok=True)
    os.makedirs(os.path.join(CONFIG['results_dir'], 'Fixed_results'), exist_ok=True)

def get_data_loader():
    """Prepare MNIST data loader"""
    transform = transforms.Compose([
        transforms.Resize(32),  # Resize to 32x32 for DCGAN
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.5,), std=(0.5,))  # Single channel for MNIST
    ])
    dataset = datasets.MNIST(
        'data', train=True, download=True, transform=transform
    )
    return DataLoader(
        dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2
    )

def weights_init(m):
    """Initialize weights for DCGAN"""
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)
        
def train_gan():
    """Main training loop for WGAN-GP"""
    generator = Generator(CONFIG['latent_dim'], CONFIG['channels']).to(CONFIG['device'])
    critic = Discriminator(CONFIG['channels']).to(CONFIG['device'])
    
    generator.apply(weights_init)
    critic.apply(weights_init)
    
    g_optimizer = optim.Adam(generator.parameters(), lr=CONFIG['learning_rate'], betas=(0.0, 0.9))
    c_optimizer = optim.Adam(critic.parameters(), lr=CONFIG['learning_rate'], betas=(0.0, 0.9))
    
    fixed_z = torch.randn((25, CONFIG['latent_dim']), device=CONFIG['device'])
    history = {'C_losses': [], 'G_losses': []}
    train_loader = get_data_loader()
    
    for epoch in range(CONFIG['epochs']):
        c_losses, g_losses = [], []
        
        for i, (real_images, _) in enumerate(train_loader):
            real_images = real_images.to(CONFIG['device'])
            batch_size = real_images.size(0)
            
            # Train Critic
            for _ in range(CONFIG['n_critic']):
                critic.zero_grad()
                
                outputs = critic(real_images)
                c_loss_real = -outputs.mean()
                
                z = torch.randn(batch_size, CONFIG['latent_dim'], device=CONFIG['device'])
                fake_images = generator(z)
                outputs = critic(fake_images.detach())
                c_loss_fake = outputs.mean()
                
                gradient_penalty = compute_gradient_penalty(critic, real_images, fake_images.detach(), CONFIG['device'])
                c_loss = c_loss_real + c_loss_fake + CONFIG['lambda_gp'] * gradient_penalty
                
                c_loss.backward()
                c_optimizer.step()
                c_losses.append(c_loss.item())
            
            # Train Generator
            generator.zero_grad()
            z = torch.randn(batch_size, CONFIG['latent_dim'], device=CONFIG['device'])
            fake_images = generator(z)
            outputs = critic(fake_images)
            g_loss = -outputs.mean()
            g_loss.backward()
            g_optimizer.step()
            
            g_losses.append(g_loss.item())
        
        avg_c_loss = sum(c_losses) / len(c_losses)
        avg_g_loss = sum(g_losses) / len(g_losses)
        history['C_losses'].append(avg_c_loss)
        history['G_losses'].append(avg_g_loss)
        print(f'Epoch-WGAN_GP [{epoch+1}/{CONFIG["epochs"]}] | C Loss: {avg_c_loss:.4f} | G Loss: {avg_g_loss:.4f}')
        
        save_samples(generator, epoch, fixed_z)
    
    save_results(generator, critic, history)
    create_animation()


def save_samples(generator, epoch, fixed_z, num_samples=5):
    """Save generated samples for visualization"""
    with torch.no_grad():
        # Random samples
        random_z = torch.randn(num_samples**2, CONFIG['latent_dim'], device=CONFIG['device'])
        generated = generator(random_z)
        save_image(generated, os.path.join(
            CONFIG['results_dir'], 'Random_results', f'MNIST_DCGAN_{epoch+1}.png'
        ))
        
        # Fixed samples
        generated = generator(fixed_z)
        save_image(generated, os.path.join(
            CONFIG['results_dir'], 'Fixed_results', f'MNIST_DCGAN_{epoch+1}.png'
        ))

def save_image(tensor, path):
    """Helper function to save tensor as image"""
    from torchvision.utils import save_image
    save_image(tensor, path, nrow=5, normalize=True)

def save_results(generator, discriminator, history):
    """Save models and training history"""
    torch.save(generator.state_dict(), os.path.join(CONFIG['results_dir'], 'generator.pth'))
    torch.save(discriminator.state_dict(), os.path.join(CONFIG['results_dir'], 'discriminator.pth'))
    
    with open(os.path.join(CONFIG['results_dir'], 'train_history.pkl'), 'wb') as f:
        pickle.dump(history, f)
    
    # Plot training history
    plt.figure(figsize=(10, 5))
    plt.plot(history['C_losses'], label='Discriminator Loss')
    plt.plot(history['G_losses'], label='Generator Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(CONFIG['results_dir'], 'training_history.png'))
    plt.close()

def create_animation():
    """Create GIF animation of training progress"""
    images = []
    for e in range(CONFIG['epochs']):
        img_path = os.path.join(
            CONFIG['results_dir'], 'Fixed_results', f'MNIST_DCGAN_{e+1}.png'
        )
        images.append(imageio.v2.imread(img_path))
    imageio.mimsave(
        os.path.join(CONFIG['results_dir'], 'training_progress.gif'),
        images, fps=5
    )

if __name__ == '__main__':
    prepare_directories()
    train_gan()