import os
import matplotlib.pyplot as plt
import pickle
import imageio
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.cuda import is_available as cuda_available

# Constants and Configuration
CONFIG = {
    'batch_size': 128,
    'learning_rate': 1e-4,
    'epochs': 100,
    'latent_dim': 100,
    'image_size': 28 * 28,
    'results_dir': 'MNIST_GAN_results',
    'device': 'cuda:0' if cuda_available() else 'cpu'
}

class Generator(nn.Module):
    def __init__(self, latent_dim=100, output_dim=784):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, output_dim),
            nn.Tanh()
        )
    def forward(self, z):
        return self.model(z)

class Discriminator(nn.Module):
    def __init__(self, input_dim=784):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
    def forward(self, img):
        return self.model(img).view(-1)

def prepare_directories():
    os.makedirs(CONFIG['results_dir'], exist_ok=True)
    os.makedirs(os.path.join(CONFIG['results_dir'], 'Random_results'), exist_ok=True)
    os.makedirs(os.path.join(CONFIG['results_dir'], 'Fixed_results'), exist_ok=True)

def get_data_loader():
    """Prepare MNIST data loader"""
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.5,), std=(0.5,))  # Single channel for MNIST
    ])
    dataset = datasets.MNIST(
        'data', train=True, download=True, transform=transform
    )
    return DataLoader(
        dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2
    )

def train_gan():
    # Initialize networks
    generator = Generator(CONFIG['latent_dim'], CONFIG['image_size']).to(CONFIG['device'])
    discriminator = Discriminator(CONFIG['image_size']).to(CONFIG['device'])

    # Loss and optimizers
    criterion = nn.BCELoss()
    g_optimizer = optim.Adam(generator.parameters(), lr=CONFIG['learning_rate'])
    d_optimizer = optim.Adam(discriminator.parameters(), lr=CONFIG['learning_rate'])

    # Fixed noise for visualization
    fixed_z = torch.randn((25, CONFIG['latent_dim']), device=CONFIG['device'])

    # Training history
    history = {'D_losses': [], 'G_losses': []}

    # Get data loader
    train_loader = get_data_loader()

    for epoch in range(CONFIG['epochs']):
        d_losses, g_losses = [], []
        
        for real_images, _ in train_loader:
            batch_size = real_images.size(0)
            real_images = real_images.view(batch_size, -1).to(CONFIG['device'])
            real_images = real_images + 0.05 * torch.randn_like(real_images).to(CONFIG['device'])
            
            # Labels
            real_labels = torch.full((batch_size,), 1.0, device=CONFIG['device'])
            fake_labels = torch.full((batch_size,), 0.0, device=CONFIG['device'])
            
            # Train Discriminator
            discriminator.zero_grad()
            
            # Real images
            outputs = discriminator(real_images)
            d_loss_real = criterion(outputs, real_labels)
            
            # Fake images
            z = torch.randn(batch_size, CONFIG['latent_dim'], device=CONFIG['device'])
            fake_images = generator(z)
            outputs = discriminator(fake_images.detach())
            d_loss_fake = criterion(outputs, fake_labels)
            
            # Total discriminator loss
            d_loss = d_loss_real + d_loss_fake
            d_loss.backward()
            d_optimizer.step()
            
            # Train Generator
            generator.zero_grad()
            outputs = discriminator(fake_images)
            g_loss = criterion(outputs, real_labels)
            g_loss.backward()
            g_optimizer.step()
            
            # Save losses
            d_losses.append(d_loss.item())
            g_losses.append(g_loss.item())
        
        # Record epoch losses
        avg_d_loss = sum(d_losses) / len(d_losses)
        avg_g_loss = sum(g_losses) / len(g_losses)
        history['D_losses'].append(avg_d_loss)
        history['G_losses'].append(avg_g_loss)
        
        # Print progress and save samples
        print(f'Epoch-GAN [{epoch+1}/{CONFIG["epochs"]}] | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f}')
        
        # Save sample images
        save_samples(generator, epoch, fixed_z)
    
    # Save models and training history
    save_results(generator, discriminator, history)
    create_animation()

def save_samples(generator, epoch, fixed_z, num_samples=5):
    """Save generated samples for visualization"""
    with torch.no_grad():
        # Random samples
        random_z = torch.randn(num_samples**2, CONFIG['latent_dim'], device=CONFIG['device'])
        generated = generator(random_z).view(-1, 1, 28, 28)
        save_image(generated, os.path.join(
            CONFIG['results_dir'], 'Random_results', f'MNIST_GAN_{epoch+1}.png'
        ))
        
        # Fixed samples
        generated = generator(fixed_z).view(-1, 1, 28, 28)
        save_image(generated, os.path.join(
            CONFIG['results_dir'], 'Fixed_results', f'MNIST_GAN_{epoch+1}.png'
        ))

def save_image(tensor, path):
    """Helper function to save tensor as image"""
    from torchvision.utils import save_image
    save_image(tensor, path, nrow=5, normalize=True)

def save_results(generator, discriminator, history):
    """Save models and training history"""
    torch.save(generator.state_dict(), os.path.join(CONFIG['results_dir'], 'generator.pth'))
    torch.save(discriminator.state_dict(), os.path.join(CONFIG['results_dir'], 'discriminator.pth'))
    
    with open(os.path.join(CONFIG['results_dir'], 'train_history.pkl'), 'wb') as f:
        pickle.dump(history, f)
    
    # Plot training history
    plt.figure(figsize=(10, 5))
    plt.plot(history['D_losses'], label='Discriminator Loss')
    plt.plot(history['G_losses'], label='Generator Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(CONFIG['results_dir'], 'training_history.png'))
    plt.close()

def create_animation():
    """Create GIF animation of training progress"""
    images = []
    for e in range(CONFIG['epochs']):
        img_path = os.path.join(
            CONFIG['results_dir'], 'Fixed_results', f'MNIST_GAN_{e+1}.png'
        )
        images.append(imageio.v2.imread(img_path))
    imageio.mimsave(
        os.path.join(CONFIG['results_dir'], 'training_progress.gif'),
        images, fps=5
    )

if __name__ == '__main__':
    prepare_directories()
    train_gan()