---
layout: mypost
title: æ·±å…¥æµ…å‡ºäº†è§£ç”Ÿæˆæ¨¡å‹-7ï¼šç”ŸæˆåŠ é€Ÿç­–ç•¥æ¦‚è¿°
categories: ç”Ÿæˆæ¨¡å‹
extMath: true
images: true
address: é•¿æ²™ğŸŒ·
show_footer_image: true
tags:
- ç”Ÿæˆæ¨¡å‹
- diffusion model
- é‡åŒ–æŠ€æœ¯
show: true
stickie: true
description: 
---
## æ‰©æ•£æ¨¡å‹ç”ŸæˆåŠ é€Ÿç­–ç•¥
Diffusionæ¨ç†åŠ é€Ÿçš„æ–¹æ¡ˆï¼Œä¸»è¦åŒ…æ‹¬Cacheã€é‡åŒ–ã€åˆ†å¸ƒå¼æ¨ç†ã€é‡‡æ ·å™¨ä¼˜åŒ–å’Œè’¸é¦ç­‰ã€‚ä¸‹é¢å†…å®¹ä¸»è¦æ˜¯å»å¯¹Cacheã€è®¡ç®—åŠ é€Ÿæ¡†æ¶ä»¥åŠé‡åŒ–æŠ€æœ¯è¿›è¡Œä»‹ç»
> SDæ¨¡å‹åŠ é€Ÿæ–¹å¼ï¼š[https://github.com/xlite-dev/Awesome-DiT-Inference?tab=readme-ov-file#Quantization](https://github.com/xlite-dev/Awesome-DiT-Inference?tab=readme-ov-file#Quantization)

### ä¸€èˆ¬åŠ é€Ÿæ¡†æ¶
è¿™éƒ¨åˆ†å†…å®¹çš„è¯æ¯”è¾ƒæ‚ï¼Œä¸»è¦æ˜¯ä»‹ç»attnè®¡ç®—åŠ é€Ÿæ–¹å¼ï¼Œæ¯”å¦‚è¯´ä¸€èˆ¬å°±æ˜¯ç›´æ¥ä½¿ç”¨æ¯”å¦‚è¯´`flash_attn`è¿›è¡Œattentionè®¡ç®—åŠ é€Ÿï¼Œæ¯”å¦‚è¯´ï¼š
```python
pipeline.transformer.set_attention_backend("_flash_3_hub") # å¯ç”¨flash attnè®¡ç®—åŠ é€Ÿ
pipeline.transformer.reset_attention_backend()             # å…³é—­flash attnè®¡ç®—åŠ é€Ÿ
```
ä½¿ç”¨`torch.compile`è¿›è¡ŒåŠ é€Ÿï¼Œä¸è¿‡å€¼å¾—æ³¨æ„çš„æ˜¯**åœ¨å¼€å§‹ä½¿ç”¨è¿‡ç¨‹ä¸­ä¼šæ¯”è¾ƒæ…¢**ï¼Œå› ä¸ºåœ¨æ‰§è¡Œæ—¶ï¼Œå®ƒä¼šå°†æ¨¡å‹ç¼–è¯‘ä¸ºä¼˜åŒ–çš„å†…æ ¸ï¼Œæ‰€ä»¥ç›¸å¯¹ä¼šæ¯”è¾ƒæ…¢ï¼Œä½†æ˜¯å¦‚æœå¯¹ç¼–è¯‘åæ¨¡å‹è¿›è¡Œæ‰¹é‡æµ‹è¯•åœ¨æ—¶é—´ä¸Šå°±ä¼šæœ‰æ‰€æå‡æ¯”å¦‚è¯´åœ¨ä»£ç [df_acceralate.ipynb](code/Python/DFModelCode/DF_acceralate/df_acceralate.ipynb)ä¸­æµ‹è¯•ç»“æœä½¿ç”¨compileåœ¨z-imageä¸Šç”Ÿæˆ5å¼ å›¾ç‰‡è€—æ—¶ï¼š86.49sï¼ˆ**å¹³å‡ç”Ÿå›¾æ—¶é—´**4sï¼‰ä¸ä½¿ç”¨compileï¼š29.92ï¼ˆ**å¹³å‡ç”Ÿå›¾æ—¶é—´**5sï¼‰
#### 1ã€xFormersåŠ é€Ÿ
> é¡¹ç›®åœ°å€ï¼šhttps://github.com/facebookresearch/xformers

åœ¨SDæ¨¡å‹ä¸­å¯¹äºxformersåŸºæœ¬ä½¿ç”¨æ–¹å¼å¦‚ä¸‹æ‰€ç¤ºï¼š
```python
import torch
from diffusers import StableDiffusionXLPipeline

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
).to("cuda")
# ä½¿ç”¨xformeråŠ é€Ÿ
pipeline.enable_xformers_memory_efficient_attention()
# å…³é—­xformeråŠ é€Ÿ
pipeline.disable_xformers_memory_efficient_attention()
```
xformersä½œç”¨åœ¨äº**åŠ é€Ÿattentionè®¡ç®—å¹¶é™ä½æ˜¾å­˜**ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜æä¾›äº†å¤šç§æ³¨æ„åŠ›å®ç°æ–¹å¼ï¼Œå¦‚casual attentionç­‰ã€‚æ ¹æ®[å®˜æ–¹æ–‡æ¡£](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.fmha.cutlass.FwOp)ä¸­çš„æè¿°ï¼Œå¯¹äºå¯¹äº`xformers.ops.memory_efficient_attention`åœ¨ä½¿ç”¨ä¸Šå‚æ•°ä¸»è¦æ˜¯ï¼š1ã€è¾“å…¥æ•°æ®ä¹Ÿå°±æ˜¯QKVçš„æ ¼å¼ä¸Šå¿…é¡»æ»¡è¶³ä¸ºï¼š`[B, M, H, K]`åˆ†åˆ«è¡¨ç¤ºçš„æ˜¯å…¶ä¸­B ä¸ºbatch size, Nä¸ºåºåˆ—é•¿åº¦, num_headsä¸ºå¤šå¤´æ³¨æ„åŠ›å¤´çš„ä¸ªæ•°, dim_headåˆ™ä¸ºæ¯ä¸ªå¤´å¯¹åº”çš„embeding sizeï¼›2ã€attn_biaså®é™…ä¸Šå……å½“ä¸ºåœ¨ä½¿ç”¨mask attentionæ—¶çš„maskï¼›3ã€pä¹Ÿå°±æ˜¯dropoutå¯¹åº”å€¼ï¼›4ã€opä¸ºTupleï¼Œç”¨äºæŒ‡å®šä¼˜åŒ–self-attentionè®¡ç®—æ‰€é‡‡ç”¨çš„ç®—å­ã€‚åŸºæœ¬ä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š
```python
import xformers.ops as xops
y = xops.memory_efficient_attention(q, k, v)
y = xops.memory_efficient_attention(q, k, v, p=0.2) # ä½¿ç”¨dropout
y = xops.memory_efficient_attention(
    q, k, v,
    attn_bias=xops.LowerTriangularMask()
)# ä½¿ç”¨casual æ³¨æ„åŠ›
```
å€¼å¾—ç€é‡äº†è§£çš„å°±æ˜¯å…¶ä¸­`attn_bias`å‚æ•°ï¼Œç®€å•ç›´è§‚çš„ç†è§£ï¼šç”¨äºæ§åˆ¶æ³¨æ„åŠ›å¯è§æ€§å’Œç»“æ„çš„ç»Ÿä¸€æ¥å£ï¼Œ**æ—¢å¯ä»¥è¡¨ç¤º maskï¼Œä¹Ÿå¯ä»¥è¡¨ç¤ºç¨€ç–/å±€éƒ¨/å› æœç­‰é«˜çº§æ³¨æ„åŠ›æ¨¡å¼**ï¼Œå¹¶ä¸”ä»¥é«˜æ€§èƒ½æ–¹å¼èå…¥ attention å†…æ ¸ã€‚æ¯”å¦‚è¯´ï¼š
1ã€`xops.LowerTriangularMask()`ï¼šå¸¸è§„çš„causalæ³¨æ„åŠ›ä¹Ÿå°±æ˜¯ä¸‹ä¸‰è§’mask
2ã€`xops.LocalAttentionFromBottomRightMask`ï¼šå±€éƒ¨æ³¨æ„åŠ›ï¼Œæ¯ä¸ªtokenåªèƒ½çœ‹æœ€è¿‘çš„window_sizeä¸ªtoken
### cacheç­–ç•¥
cacheæŒ‡çš„æ˜¯ï¼š**ç¼“å­˜é€šè¿‡å­˜å‚¨å’Œé‡ç”¨ä¸åŒå±‚ï¼ˆä¾‹å¦‚æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆå±‚ï¼‰çš„ä¸­é—´è¾“å‡ºæ¥åŠ é€Ÿæ¨ç†ï¼Œè€Œä¸æ˜¯åœ¨æ¯ä¸ªæ¨ç†æ­¥éª¤æ‰§è¡Œæ•´ä¸ªè®¡ç®—**ã€‚å®ƒä»¥æ›´å¤šå†…å­˜ä¸ºä»£ä»·æ˜¾ç€æé«˜äº†ç”Ÿæˆé€Ÿåº¦ï¼Œå¹¶ä¸”ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒã€‚ä¸»è¦è¯¦ç»†ä»‹ç»ä¸¤ç§ï¼š1ã€DeepCacheï¼›2ã€FORAã€‚å¯¹äºæ›´åŠ å¤šçš„cacheç­–ç•¥å¯ä»¥çœ‹[çŸ¥ä¹](https://zhuanlan.zhihu.com/p/711223667)ï¼Œ**æ¨èç›´æ¥ä½¿ç”¨**[CacheDit](#cachedit)æ¥è¿›è¡ŒåŠ é€Ÿã€‚
#### DeepCacheç­–ç•¥
> Paper:[https://arxiv.org/pdf/2312.00858](https://arxiv.org/pdf/2312.00858)
> Code:[https://link.zhihu.com/?target=https%3A//github.com/horseee/DeepCache](https://link.zhihu.com/?target=https%3A//github.com/horseee/DeepCache)

**ä¸»è¦é’ˆå¯¹UNetæ¶æ„**çš„Diffusionæ¨¡å‹è¿›è¡Œæ¨ç†åŠ é€Ÿã€‚DeepCache æ˜¯ä¸€ç§Training-freeçš„æ‰©æ•£æ¨¡å‹åŠ é€Ÿç®—æ³•ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯**åˆ©ç”¨æ‰©æ•£æ¨¡å‹åºåˆ—å»å™ªæ­¥éª¤ä¸­å›ºæœ‰çš„æ—¶é—´å†—ä½™æ¥å‡å°‘è®¡ç®—å¼€é”€**ã€‚
![](https://s2.loli.net/2026/01/13/7fSrYDnbHFLu6iG.png)
åŸºäº U-Net ç»“æ„ç‰¹æ€§ï¼Œå‘ç°ç›¸é‚»å»å™ªæ­¥éª¤çš„é«˜å±‚ç‰¹å¾å…·æœ‰æ˜¾è‘—æ—¶é—´ä¸€è‡´æ€§ï¼ˆAdjacent steps in the denoising process exhibit significant temporal similarity in high-level features.ï¼‰ï¼Œæ¯”å¦‚è¯´ä¸Šå›¾ä¸­ä½œè€…åœ¨æµ‹è¯•ä¸Šé‡‡ç”¨block $U_2$çš„ç‰¹å¾å’Œå…¶å®ƒæ‰€æœ‰çš„é‡‡æ ·æ­¥ä¹‹é—´ç›¸ä¼¼æ€§è®¡ç®—ï¼ˆå›¾bï¼‰ï¼Œå› æ­¤ç¼“å­˜è¿™äº›é«˜å±‚ç‰¹å¾å¹¶ä»…ä»¥ä½æˆæœ¬æ›´æ–°ä½å±‚ç‰¹å¾ï¼Œä»è€Œé¿å…é‡å¤è®¡ç®—ã€‚å…·ä½“æ–¹æ³•ä¸ºï¼š
![](https://s2.loli.net/2026/01/13/eXRHCFcdxLi2z7K.png)
æ¯”å¦‚è¯´åœ¨å®˜æ–¹çš„ä½¿ç”¨ä¸­æœ‰å‚æ•°ï¼š`helper.set_params(cache_interval=3,cache_branch_id=0,)`è¡¨ç¤ºæ˜¯æ¯3ä¸ªæ—¶é—´æ­¥è¿›è¡Œä¸€æ¬¡å®Œæˆforwardç„¶ååˆ·æ–°cacheï¼Œè€Œå…¶ä¸­å‚æ•°cache_branch_idå€¼å¾—æ˜¯ä¸€èˆ¬è€Œè¨€åœ¨UNetä¸­ä¼šå®šä¹‰`branch 0 â†’ early / down blocks`ç­‰å°±æ˜¯é€‰æ‹©å“ªäº›å±‚çš„è¾“å‡ºã€‚å…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼št=1è¿›è¡Œè®¡ç®—ç¼“å­˜ï¼Œt=2,3éƒ½ç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼Œt=4å®Œæ•´è®¡ç®—å¾—åˆ°ç¼“å­˜ã€‚
#### FORA
> Paper: [https://arxiv.org/pdf/2407.01425](https://arxiv.org/pdf/2407.01425)
> Code: [https://github.com/prathebaselva/FORA](https://github.com/prathebaselva/FORA)

**ä¸»è¦æ˜¯äº‰å¯¹Ditæ¶æ„**çš„Diffusionæ¨¡å‹è¿›è¡Œæ¨ç†åŠ é€Ÿã€‚åˆ©ç”¨ Diffusion Transformer æ‰©æ•£è¿‡ç¨‹çš„é‡å¤ç‰¹æ€§å®ç°äº†å¯ç”¨äºDiTçš„Training-freeçš„CacheåŠ é€Ÿç®—æ³•ã€‚
![](https://s2.loli.net/2026/01/13/UCOEAJDLZNHXFW5.png)
FORAçš„æ ¸å¿ƒåœ¨äºå‘ç°Ditåœ¨å»å™ªè¿‡ç¨‹ä¸­ï¼Œ**ç›¸é‚»æ—¶é—´æ­¥çš„Attnå’ŒMLPå±‚ç‰¹å¾å­˜åœ¨æ˜¾è‘—é‡å¤æ€§**ï¼ˆå¦‚ä¸Šå›¾æ‰€ç¤º:åœ¨layer0ã€9ã€18ã€27è¿™äº›å±‚ä»¥åŠ250æ­¥é‡‡æ ·ä¸­ï¼Œéšåé‡‡æ ·æ­¥çº¦å¾€åç‰¹å¾ä¹‹é—´ç›¸ä¼¼æ€§ä¹Ÿå°±è¶Šé«˜ã€‚ï¼‰ã€‚é€šè¿‡Cachingç‰¹å¾ï¼ŒFORA å°†è¿™äº›é‡å¤è®¡ç®—çš„ä¸­é—´ç‰¹å¾ä¿å­˜å¹¶åœ¨åç»­æ—¶é—´æ­¥ç›´æ¥å¤ç”¨ï¼Œé¿å…é€æ­¥é‡æ–°è®¡ç®—ã€‚
![](https://s2.loli.net/2026/01/13/dSp5Zy9zua3gjw4.png)
å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹ä»¥å›ºå®šé—´éš” N é‡æ–°è®¡ç®—å¹¶ç¼“å­˜ç‰¹å¾ï¼šå½“æ—¶é—´æ­¥ t æ»¡è¶³ t mod N=0 æ—¶ï¼Œæ›´æ–°æ‰€æœ‰å±‚çš„ç¼“å­˜ï¼›åœ¨åç»­ N-1 æ­¥ä¸­ï¼Œç›´æ¥æ£€ç´¢cachedçš„ Attn å’Œ MLP ç‰¹å¾ï¼Œè·³è¿‡é‡å¤è®¡ç®—ã€‚è¿™ç§ç­–ç•¥åˆ©ç”¨äº† DiT æ¶æ„åœ¨é‚»è¿‘æ—¶é—´æ—¶é—´æ­¥çš„ç‰¹å¾ç›¸ä¼¼æ€§ï¼Œåœ¨ä¸ä¿®æ”¹DiTæ¨¡å‹ç»“æ„çš„å‰æä¸‹å®ç°åŠ é€Ÿã€‚ä¾‹å¦‚ï¼Œåœ¨ 250 æ­¥ DDIM é‡‡æ ·ä¸­ï¼Œå½“ N=3 æ—¶ï¼Œæ¨¡å‹ä»…éœ€åœ¨ç¬¬ 3ã€6ã€9... æ­¥é‡æ–°è®¡ç®—ç‰¹å¾ï¼Œå…¶ä½™æ­¥éª¤å¤ç”¨Cacheï¼Œä½¿è®¡ç®—é‡å‡å°‘çº¦ 2/3ã€‚å®éªŒè¡¨æ˜ï¼ŒFORAå¯¹åæœŸå»å™ªé˜¶æ®µçš„ç‰¹å¾ç›¸ä¼¼æ€§åˆ©ç”¨æ›´ä¸ºé«˜æ•ˆï¼Œæ­¤æ—¶ç‰¹å¾å˜åŒ–ç¼“æ…¢ï¼Œç¼“å­˜å¤ç”¨çš„æ€§ä»·æ¯”æœ€é«˜ã€‚
#### CacheDit
[cache-dit](https://github.com/vipshop/cache-dit)è¿™ä¸ªæ¡†æ¶ä¸»è¦æ˜¯é€‚ç”¨äºDitç»“æ„çš„æ‰©æ•£æ¨¡å‹ä½¿ç”¨ï¼Œå…¶å…·ä½“åŸç†å¦‚ä¸‹ï¼Œå…¶ä¸­å…·ä½“ä½¿ç”¨å¦‚ä¸‹ï¼š[df_acceralate.ipynb](code/Python/DFModelCode/DF_acceralate/df_acceralate.ipynb)
### é‡åŒ–æŠ€æœ¯æ¦‚è¿°
[é‡åŒ–æŠ€æœ¯](https://www.big-yellow-j.top/posts/2025/10/11/Quantized.html)æ˜¯ä¸€ç§æ¨¡å‹å‹ç¼©çš„å¸¸è§æ–¹æ³•ï¼Œå°†æ¨¡å‹æƒé‡ä»é«˜ç²¾åº¦ï¼ˆå¦‚FP16æˆ–FP32ï¼‰é‡åŒ–ä¸ºä½æ¯”ç‰¹ä½ï¼ˆå¦‚INT8ã€INT4ï¼‰ã€‚å¸¸è§çš„é‡åŒ–ç­–ç•¥å¯ä»¥åˆ†ä¸ºPTQå’ŒQATä¸¤å¤§ç±»ã€‚é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQuantization-Aware Trainingï¼‰ï¼šåœ¨**æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œé‡åŒ–**ï¼Œä¸€èˆ¬æ•ˆæœä¼šæ›´å¥½ä¸€äº›ï¼Œä½†éœ€è¦é¢å¤–è®­ç»ƒæ•°æ®å’Œå¤§é‡è®¡ç®—èµ„æºã€‚åé‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰ï¼šåœ¨**æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œå¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–**ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚å¯¹äºçº¿æ€§é‡åŒ–ä¸‹ï¼Œæµ®ç‚¹æ•°ä¸å®šç‚¹æ•°ä¹‹é—´çš„è½¬æ¢å…¬å¼å¦‚ä¸‹ï¼š$Q=\frac{R}{S}+Z;R=(Q-Z)*S$ï¼Œå…¶ä¸­R è¡¨ç¤ºé‡åŒ–å‰çš„æµ®ç‚¹æ•°ã€Q è¡¨ç¤ºé‡åŒ–åçš„å®šç‚¹æ•°ã€Sï¼ˆScaleï¼‰è¡¨ç¤ºç¼©æ”¾å› å­çš„æ•°å€¼ã€Zï¼ˆZeroï¼‰è¡¨ç¤ºé›¶ç‚¹çš„æ•°å€¼ã€‚
æ¯”å¦‚è¯´åœ¨LLMä¸­å¸¸ç”¨çš„ä¸¤ç§**åé‡åŒ–æŠ€æœ¯**ï¼š1ã€**GPTQé‡åŒ–æŠ€æœ¯**ï¼šé€šè¿‡é‡åŒ–â€”â€”è¡¥å¿â€”â€”é‡åŒ–è¿­ä»£æ–¹æ³•ï¼Œé¦–å…ˆé‡åŒ–$W_{:,j}$ï¼Œè€Œåå»è®¡ç®—è¯¯å·®å¹¶ä¸”è¡¥å……åˆ° $W_{:,j:(i+B)}$è€Œåè¿›è¡Œè¿­ä»£å®ç°æ‰€æœ‰å‚æ•°çš„é‡åŒ–ï¼›2ã€**AWQé‡åŒ–æŠ€æœ¯**ï¼šæ¨¡å‹è®¡ç®—è¿‡ç¨‹ä¸­åªæœ‰å…³é”®å‚æ•°èµ·ä½œç”¨å› æ­¤å¯¹äºå…³é”®å‚æ•°ä¿æŒåŸæ¥çš„ç²¾åº¦(FP16)ï¼Œå¯¹å…¶ä»–æƒé‡è¿›è¡Œä½æ¯”ç‰¹é‡åŒ–ï¼Œä½†æ˜¯è¿™æ ·ä¸åŒè¿›åº¦å‚æ•°ä¼šå¯¼è‡´ç¡¬ä»¶é—®é¢˜ï¼Œå› æ­¤åœ¨AWQä¸­**å¯¹æ‰€æœ‰æƒé‡å‡è¿›è¡Œä½æ¯”ç‰¹é‡åŒ–ï¼Œä½†æ˜¯ï¼Œåœ¨é‡åŒ–æ—¶ï¼Œå¯¹äºæ˜¾è‘—æƒé‡ä¹˜ä»¥è¾ƒå¤§çš„scaleï¼Œç›¸å½“äºé™ä½å…¶é‡åŒ–è¯¯å·®ï¼›åŒæ—¶ï¼Œå¯¹äºéæ˜¾è‘—æƒé‡ï¼Œä¹˜ä»¥è¾ƒå°çš„scaleï¼Œç›¸å½“äºç»™äºˆæ›´å°‘çš„å…³æ³¨ã€‚**
#### Bitsandbytes é‡åŒ–
é€šè¿‡ä½¿ç”¨bitsandbytesé‡åŒ–æ¥å®ç°8-bitï¼ˆint8ï¼‰æˆ–è€…4-bitï¼ˆint4ã€Qloraä¸­ä¸€èˆ¬å°±ä¼šä½¿ç”¨ï¼‰é‡åŒ–ï¼Œä¸è¿‡åŒºåˆ«ä¸Šé¢æåˆ°çš„AWQä»¥åŠGPTQé‡åŒ–ï¼Œbitsandbyteså±äºé‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼Œå‰è€…éœ€è¦é€šè¿‡æ•°æ®æ¥ä¿è¯é‡åŒ–ç²¾åº¦ï¼ˆé‡åŒ–è¿‡ç¨‹æ˜¯ç¦»çº¿ã€ä¸€æ¬¡æ€§è¿‡ç¨‹ï¼‰ï¼Œåè€…é‡åŒ–è¿‡ç¨‹æ˜¯å³æ—¶çš„å¯é€†çš„ã€‚å…¶æŠ€æœ¯åŸç†å¦‚ä¸‹ï¼š$wâ‰ˆs q$å…¶ä¸­wè¡¨ç¤ºåŸå§‹çš„FP16æƒé‡ï¼Œqä»£è¡¨int4/int8æƒé‡ï¼Œsç¼©æ”¾å› å­ï¼Œå…¶é‡åŒ–è¿‡ç¨‹ä¸ºå¯¹æ¯ä¸€ä¸ªblockæƒé‡è®¡ç®—ï¼š$\max(\text{abs}(w))$è€Œåå»è®¡ç®—scaleï¼š$s=\frac{amx(\| w\|)}{2^{b-1}-1}$è€Œåä»£å…¥å…¬å¼å°±å¯ä»¥å¾—åˆ°é‡åŒ–åæƒé‡ï¼Œæ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œï¼šåé‡åŒ– + çŸ©é˜µä¹˜æ³•èåˆåœ¨ä¸€ä¸ª CUDA kernel ä¸­å®Œæˆï¼š$Y=X(sq)$ã€‚å› æ­¤å¯¹äºå…¶ä½¿ç”¨ä¹Ÿå¾ˆç®€å•ï¼Œæ¯”å¦‚è¯´åœ¨ä»£ç ä¸­ï¼š[cache_acceralate.py](code/Python/DFModelCode/DF_acceralate/cache_acceralate.py)
```python
# åœ¨ZImagePipelineä¸­å‚æ•°ä¸ºï¼š
class ZImagePipeline(DiffusionPipeline, ZImageLoraLoaderMixin, FromSingleFileMixin):
    def __init__(,..,vae, text_encoder, tokenizr, transformer):
        ...
# å› æ­¤å¯ä»¥ç›´æ¥å¯¹é‡Œé¢çš„text_encoderä½¿ç”¨é‡åŒ–å¤„ç†

from diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig
quantization_config = DiffusersBitsAndBytesConfig(
    load_in_4bit=True,# åœ¨æ¨¡å‹åŠ è½½é˜¶æ®µï¼Œå°†æƒé‡ä»¥ 4-bit é‡åŒ–å½¢å¼åŠ è½½
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,# æŒ‡å®š åé‡åŒ–åå‚ä¸è®¡ç®—çš„ dtype
    bnb_4bit_use_double_quant=True,#å¯ç”¨ Double Quantizationï¼ˆåŒé‡é‡åŒ–ï¼‰ï¼Œä¹Ÿå°±æ˜¯å¯¹blockçš„scaleåœ¨è¿›è¡Œä¸€æ¬¡é‡åŒ–
    llm_int8_skip_modules=["transformer_blocks.0.img_mod"],# æŒ‡å®š ä¸å‚ä¸ bitsandbytes é‡åŒ–çš„æ¨¡å—
)
transformer = AutoModel.from_pretrained(
    model_name,
    cache_dir=cache_dir,
    subfolder="transformer",
    quantization_config=quantization_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    mirror='https://hf-mirror.com'
)
```
å»å¯¹ä½ çš„`model_name`é‡Œé¢çš„transformerè¿›è¡Œé‡åŒ–å¤„ç†ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜æœ‰ä½¿ç”¨ä¾‹å­å°±æ˜¯è¿›è¡Œä¼˜åŒ–å™¨é‡åŒ–ï¼Œæ¯”å¦‚è¯´
```python
# å’Œä½¿ç”¨adamwæ–¹å¼ä¸€æ ·ï¼Œä½¿ç”¨qloraä½¿ç”¨ä¸€èˆ¬å¸¦ä¸Šè¿™ä¸ªä¼˜åŒ–å™¨
import bitsandbytes as bnb
optimizer_class = bnb.optim.AdamW8bit
```
#### SVDQuanté‡åŒ–
> https://github.com/nunchaku-ai/nunchaku

#TODO: é‡åŒ–ä¾¯æ¨¡å‹å¦‚ä½•è¿›è¡Œåè®­ç»ƒå¯ä»¥ç›´æ¥ä½¿ç”¨ flux1-dev-kontext_fp8_scaled.safetensors è¿›è¡Œä»‹ç»
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTg3NDMyNDk4XX0=
-->