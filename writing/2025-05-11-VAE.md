---
layout: mypost
title: 深入浅出了解生成模型-2：VAE模型原理以及代码实战
categories: 生成模型
extMath: true
images: true
address: changsha
show_footer_image: true
tags: [生成模型, VAE]
description: 日常使用比较多的生成模型比如GPT/Qwen等这些大多都是“文生文”模型（当然GPT有自己的大一统模型可以“文生图”）但是网上流行很多AI生成图像，而这些生成图像模型大多都离不开下面三种模型：1、GAN；2、VAE；3、Diffusion Model。因此本文通过介绍这三个模型作为生成模型的入门。本文主要介绍GAN模型
---

前文已经介绍了GAN的基本原理以及代码操作，本文主要介绍VAE其基本原理以及代码实战

## VAE or AE
介绍VAE之前了解两个概念：AE（AutoEncoder，自编码器）和VAE（Variational Autoencoder，变自编码器）。**AE**：自编码器是一种无监督学习神经网络，旨在通过将输入数据压缩到一个低维表示（编码），然后从该表示重建输入数据（解码），来学习数据的特征表示。**VAE**：变分自编码器是自编码器的扩展，结合了概率模型和深度学习，通过引入变分推理使潜在空间具有概率分布特性，适合生成任务。
**AE**的数学描述对于输入 $x$通过编码器将输入映射到 **低纬空间** $z=f(x)$而后通过解码器得到输出：$\hat{x}=g(x)$
**VAE**的数学描述对于输入 $x$通过编码器将输入映射成 **概率分布** $q(z|x)$，假设为高斯分布，输出 𝜇和 𝜎，从 $q(z|x)$采样 $z$而后通过 $z=\mu+ \sigma+ \epsilon$ 其中 $\epsilon \in N(0,1)$，而后通过采样得到的$z$重新构建输入，生成$p(x|z)$
前者不适合对于图片进行生成而后者则是更加适合图像生成，这是因为AE将输入映射到一个低纬空间z这个低纬空间并没有明确的结构，进而就可能不适合去生成新的数据，而VAE之所以可以用于生成新的数据是，比如说对于图像数据（比如说：猫）如果知道其分布特征，就可以直接通过分布特征去构建一个新的图像

![](https://s2.loli.net/2025/05/13/Ji5sAMmGehLjdf9.png)

## VAE（Variational Autoencoder）
上面简单介绍了VAE数学描述这里重新再描述一下其数学描述：
### 1.基本框架
VAE 是一种生成模型，**目标是学习数据的概率分布 p(x)，让模型能生成类似真实数据的新样本**，想象我们要制作各种蛋糕（数据 $x$），但不知道蛋糕的“秘方”（潜在变量 $z$）。假设所有蛋糕组成数据集 $X = {x_1, \dots, x_n}$，每种蛋糕（如巧克力蛋糕或水果蛋糕）背后有独特的秘方。VAE 通过学习秘方的分布和生成过程，制造出逼真的蛋糕。
**秘方**：VAE 假设秘方 $z$ 服从标准正态分布，即先验分布 $p(z) = \mathcal{N}(0, I)$。这意味着大多数秘方是“普通”的，围绕平均值分布。
**生成蛋糕（解码器）**：给定秘方 $z$，VAE 使用一个“蛋糕机”（解码器，参数 $\theta$）生成蛋糕 $x$。解码器建模条件分布 $p_\theta(x|z) = \mathcal{N}(x; \mu_\theta(z), \sigma_\theta^2(z))$，表示从 $z$ 生成 $x$ 的概率。
**猜测秘方（编码器）**：直接从蛋糕 $x$ 反推秘方（后验分布 $p(z|x)$）很困难（因为我的变量是一个高纬的）。VAE 引入一个“猜测机”（编码器，参数 $\phi$），用变分分布 $q_\phi(z|x) = \mathcal{N}(z; \mu_\phi(x), \text{diag}(\sigma_\phi^2(x)))$ 近似后验分布，估计可能的秘方。
大致总结一下就是：VAE的主要的任务就是，最开始的数据集里面，我希望通过对这个数据记得潜在分布进行学习，如果我模型学会了各类数据的分布，那么就可以通过这些分布去进一步生成新的数据。

### 2.模型参数求解
了解模型基本框架之后就需要对整个模型的参数进行求解

## 总结

## 参考
1、https://github.com/hkproj/vae-from-scratch-notes/blob/main/VAE.pdf
2、https://mbernste.github.io/posts/vae/
3、https://arxiv.org/pdf/1906.02691