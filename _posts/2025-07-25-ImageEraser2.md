---
layout: mypost
title: å›¾åƒæ¶ˆé™¤è®ºæ–‡-2ï¼šRORemã€ObjectClear
categories: å›¾åƒæ¶ˆé™¤
address: æ­¦æ±‰ğŸ¯
extMath: true
show_footer_image: true
tags:
- diffusion model
- å›¾åƒæ¶ˆé™¤
special_tag: æ›´æ–°ä¸­
description: 
---

æœ¬æ–‡ä¸»è¦ä»‹ç»å‡ ç¯‡å›¾åƒæ“¦é™¤è®ºæ–‡æ¨¡å‹ï¼šRORemã€ObjectClear
## RORem
> https://arxiv.org/pdf/2501.00740
> https://github.com/leeruibin/RORem


## ObjectClear
> https://arxiv.org/pdf/2505.22636
> https://github.com/zjx0101/ObjectClear
> **åŸºåº§æ¨¡å‹**ï¼š**SDXL-Inpainting**

æœ¬æ–‡å‡ºå‘ç‚¹ä¸»è¦ä¸ºä¸¤ä¸ªï¼š1ã€åˆ›å»ºæ•°æ®é›†ï¼›2ã€é€šè¿‡å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼ˆattention-maskï¼‰å»å¼•å¯¼æ¨¡å‹æ¶ˆé™¤
### æ•°æ®é›†æ„å»º
![image.png](https://s2.loli.net/2025/07/25/bKsqRJNEf3DcH2a.png)

ä¸»è¦ä¸ºä¸¤éƒ¨åˆ†æ•°æ®é›†ï¼š1ã€æ‹æ‘„æ•°æ®é›†ï¼ˆ2875å¼ å›¾ç‰‡ï¼‰ï¼›2ã€æ¨¡å‹æ•°æ®é›†ã€‚å¯¹äº **æ‹æ‘„æ•°æ®é›†**ï¼šé¦–å…ˆå°†å›¾ç‰‡å¤„ç†ä¸º512x512è€Œåï¼Œç›´æ¥é€šè¿‡DIBO+SAMå»è¯†åˆ«ç„¶ååˆ‡å‰²å®ä½“å¾—åˆ°maskï¼ˆ$M_o$ï¼‰ç„¶åå»ç»“åˆâ€œmaskç›¸å…³çš„è¯­ä¹‰ç‰¹å¾â€ï¼ˆæ¯”å¦‚è¯´é˜´å½± $M_e$ ç­‰ï¼‰å¾—åˆ°$M_{fg}=[M_o,M_e]$

### æ¨¡å‹ç»“æ„
![image.png](https://s2.loli.net/2025/07/25/XUlB5YM8zNqS2hZ.png)

å°†åŸºåº§æ¨¡å‹ï¼ˆ**SDXL-Inpainting**ï¼‰çš„è¾“å…¥ï¼ˆ1ã€å™ªå£°åˆ†å¸ƒ$z_t$ï¼›2ã€masked image $I_m$è¿™ä¸ªä¸€èˆ¬å°±æ˜¯ç›´æ¥å°†maskä»å›¾ä¸­æ‰£é™¤ï¼›3ã€maskï¼š$M_o$ï¼›4ã€æ–‡æœ¬promptï¼š$c$ï¼‰ä¸­çš„mask imageæ›¿æ¢ä¸ºåŸå§‹çš„å›¾åƒï¼š$I_{in}$ï¼ˆè¿™å’Œä¹‹å‰çš„SmartEraserå¤„ç†æ–¹å¼ç±»ä¼¼ï¼‰ï¼Œé™¤æ­¤ä¹‹å¤–å¯¹äºè¾“å…¥DFæ¨¡å‹ä¸­çš„å¤„ç†æ€è·¯å’ŒSmartEraserä¹Ÿæ˜¯ç›¸ä¼¼çš„ï¼š**å›¾åƒï¼ˆéœ€è¦æ¶ˆé™¤çš„ï¼‰å’Œæ–‡æœ¬åˆ†åˆ«é€šè¿‡Clipä¸åŒç¼–ç å™¨å¤„ç†ç„¶åç»„åˆ**ã€‚è€Œåè¾“å…¥åˆ°DFçš„Attentionè®¡ç®—å½“ä¸­ï¼Œå¯¹äºç‰¹å¾ç»„åˆéƒ¨åˆ†ä»£ç å¤„ç†æ–¹å¼ä¸ºï¼š
```python
text_object_embed = self.fuse_fn(object_embeds)#ä¸¤å±‚mlp+norm
text_embeds_new = text_embeds.clone()
text_embeds_new[:, fuse_index, :] = text_object_embed.squeeze(1)
```
å°†å¾—åˆ°çš„`text_object_embed`ä½œä¸ºæ–‡æœ¬ç‰¹å¾ç¼–ç ç‰¹å¾è¾“å…¥åˆ°unetä¸­è¿›è¡Œè®¡ç®—ã€‚é™¤æ­¤ä¹‹å¤–è®ºæ–‡ä¸­æ·»åŠ äº†ä¸€ä¸ªmask lossè®¡ç®—ã€‚
é™¤æ­¤ä¹‹å¤–ä½¿ç”¨`Attention-Guided Fusion`å…·ä½“ä»£ç å¤„ç†æ–¹å¼ä¸ºï¼š
```python3
def unet_store_cross_attention_scores(self, unet, attention_scores):
    from diffusers.models.attention_processor import (
        Attention,
        AttnProcessor,
        AttnProcessor2_0,
    )
    import types

    UNET_LAYER_NAMES = [
        "down_blocks.0",
        "down_blocks.1",
        "down_blocks.2",
        "mid_block",
        "up_blocks.1",
        "up_blocks.2",
        "up_blocks.3",
    ]

    start_layer = 0
    end_layer = 2
    applicable_layers = UNET_LAYER_NAMES[start_layer:end_layer]

    def make_new_get_attention_scores_fn(name):
        def new_get_attention_scores(module, query, key, attention_mask=None):
            attention_probs = module.old_get_attention_scores(
                query, key, attention_mask
            )
            attention_scores[name] = attention_probs
            return attention_probs

        return new_get_attention_scores

    for name, module in unet.named_modules():
        if isinstance(module, Attention) and "attn2" in name:
            if not any(layer in name for layer in applicable_layers):
                continue
            if isinstance(module.processor, AttnProcessor2_0):
                module.set_processor(AttnProcessor())
            module.old_get_attention_scores = module.get_attention_scores
            module.new_get_attention_scores = types.MethodType(
                make_new_get_attention_scores_fn(name), module
            )
            module.get_attention_scores = module.new_get_attention_scores

    return unet
....
fuse_index = 5
if self.config.apply_attention_guided_fusion:
    if i == len(timesteps) - 1:
        attn_key, attn_map = next(iter(self.cross_attention_scores.items()))
        attn_map = self.resize_attn_map_divide2(attn_map, mask, fuse_index)
        init_latents_proper = image_latents
        if self.do_classifier_free_guidance:
            _, init_mask = attn_map.chunk(2)
        else:
            init_mask = attn_map
        attn_map = init_mask
    self.clear_cross_attention_scores(self.cross_attention_scores)
...
attn_pils = []
if output_type == "pil" and attn_map is not None:
    for i in range(len(attn_map)):
        attn_np = attn_map[i].mean(dim=0).cpu().numpy() * 255.
        attn_pil = PIL.Image.fromarray(attn_np.astype(np.uint8)).convert("L")
        attn_pils.append(attn_pil)
    
    original_pils = self.image_processor.postprocess(init_image, output_type="pil")

    generated_pils = image

    fused_images = []
    for i in range(len(generated_pils)):
        ori_pil = original_pils[i]
        gen_pil = generated_pils[i]
        attn_pil = attn_pils[i]

        fused_np = attention_guided_fusion(np.array(ori_pil), np.array(gen_pil), np.array(attn_pil))
        fused_pil = PIL.Image.fromarray(fused_np.astype(np.uint8)).resize(ori_pil.size)

        fused_images.append(fused_pil)

    image = fused_images
```
**é¦–å…ˆ**å¯¹äº`unet_store_cross_attention_scores`ä¸»è¦æ˜¯å¤„ç†å¦‚ä¸‹ä¸¤ä¸ªæ­¥éª¤ï¼š1ã€æœé›†down_blocks.0å’Œdown_blocks.1ä¸­attn2æ¨¡å—çš„æ³¨æ„åŠ›åˆ†æ•°ï¼›2ã€å°†down_blocks.0å’Œdown_blocks.1ä¸­attn2æ¨¡å—å¤„ç†å™¨ä»AttnProcessor2_0æ›¿æ¢ä¸ºAttnProcessor