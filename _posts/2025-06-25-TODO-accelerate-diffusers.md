---
layout: mypost
title: æ·±å…¥æµ…å‡ºäº†è§£ç”Ÿæˆæ¨¡å‹-5ï¼šdiffuser/accelerateåº“å­¦ä¹ 
categories: python
extMath: true
images: true
address: æ­¦æ±‰ğŸ¯
show_footer_image: true
tags: [ç”Ÿæˆæ¨¡å‹,diffusion model,python]
show: true
stickie: true
description: å·¥æ¬²å–„å…¶äº‹å¿…å…ˆåˆ©å…¶å™¨ï¼Œä»‹ç»å†å¤šçš„ç”Ÿæˆæ¨¡å‹æ²¡æœ‰ä¸€ä¸ªå¥½çš„å·¥å…·æ˜¯ä¸è¡Œçš„ï¼Œå› æ­¤æœ¬ä½ä¸»è¦ä»‹ç»å‡ ä¸ªåœ¨ç”Ÿæˆæ¨¡å‹ä¸­å¸¸ç”¨çš„pythonåº“ï¼šdiffuser/accelerateçš„åŸºæœ¬ä½¿ç”¨ä»¥åŠä»£ç æ“ä½œã€‚
---

å·¥æ¬²å–„å…¶äº‹ï¼Œå¿…å…ˆåˆ©å…¶å™¨ã€‚å³ä¾¿ä»‹ç»äº†å†å¤šç”Ÿæˆæ¨¡å‹ï¼Œæ²¡æœ‰è¶æ‰‹çš„å·¥å…·ä¹Ÿéš¾ä»¥æ–½å±•æ‰åã€‚å› æ­¤ï¼Œæœ¬æ–‡å°†é‡ç‚¹ä»‹ç»å‡ ä¸ªåœ¨ç”Ÿæˆæ¨¡å‹å¼€å‘ä¸­å¸¸ç”¨çš„ Python åº“ï¼Œç€é‡è®²è§£ **Diffusers** å’Œ **Accelerate** çš„åŸºæœ¬ä½¿ç”¨ã€‚æ„Ÿè°¢ Hugging Face ä¸ºæ— æ•°ç®—æ³•å·¥ç¨‹å¸ˆæä¾›äº†å¼ºå¤§çš„å¼€æºæ”¯æŒï¼éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå®˜æ–¹æ–‡æ¡£å¯¹è¿™ä¸¤ä¸ªåº“å·²æœ‰è¯¦å°½çš„è¯´æ˜ï¼Œæœ¬æ–‡ä»…ä½œä¸ºä¸€ç¯‡ç®€æ˜çš„ä½¿ç”¨ç¬”è®°ï¼ŒæŠ›ç –å¼•ç‰ï¼Œä¾›å‚è€ƒå’Œäº¤æµã€‚

## accelerate
> æ¨èç›´æ¥é˜…è¯»å®˜æ–¹æ–‡æ¡£ï¼š[https://huggingface.co/docs/accelerate/index](https://huggingface.co/docs/accelerate/index)
> [`pip install accelerate`](https://huggingface.co/docs/accelerate/basic_tutorials/install)

ä»‹ç»ä¹‹å‰äº†è§£ä¸€ä¸‹è¿™ä¸ªåº“æ˜¯å¹²ä»€ä¹ˆçš„ï¼šè¿™ä¸ªåº“ä¸»è¦æä¾›ä¸€ä¸ªå¿«é€Ÿçš„åˆ†å¸ƒå¼è®­ç»ƒï¼ˆé¿å…äº†ç›´æ¥ç”¨torchè¿›è¡Œæ‰‹æ“ï¼‰å¹¶ä¸”æ”¯æŒå„ç±»åŠ é€Ÿæ–¹æ³•ï¼š[æ··åˆç²¾åº¦è®­ç»ƒ](https://www.big-yellow-j.top/posts/2025/01/01/mixed-precision.html)ã€[Deepspeed](https://www.big-yellow-j.top/posts/2025/02/24/deepspeed.html)ã€æ¢¯åº¦ç´¯è®¡ç­‰

## ä¸€ä¸ªåŸºæœ¬ä½¿ç”¨åœºæ™¯
ä¸€èˆ¬ä»»åŠ¡ä¸­ä¸€ä¸ªå¸¸è§çš„åº”ç”¨åœºæ™¯æ˜¯ï¼šéœ€è¦å®ç°ä¸€ä¸ªå¤šæ˜¾å¡ï¼ˆè¿™é‡Œå‡è®¾ä¸ºåŒæ˜¾å¡ï¼‰åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¹¶ä¸”ä½¿ç”¨æ¢¯åº¦ç´¯è®¡ã€æ··åˆç²¾åº¦è®­ç»ƒï¼Œå¹¶ä¸”è®­ç»ƒå¾—åˆ°çš„ç»“æœé€šè¿‡tensorboard/wandbè¿›è¡Œè®°å½•ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜éœ€è¦ä½¿ç”¨warm-upå­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥ï¼Œå¹¶ä¸”æˆ‘çš„æ¨¡å‹ä¸åŒæ¨¡å—ä½¿ç”¨çš„å­¦ä¹ ç‡ä¸åŒï¼Œè®­ç»ƒå®Œæˆä¹‹åæ‰€æœ‰çš„æ¨¡å‹æƒé‡è¦è¿›è¡Œä¿å­˜/è¯»å–æƒé‡è¿›è¡Œæµ‹è¯•ã€‚é‚£ä¹ˆå¯ä»¥ç›´æ¥é€šè¿‡ä¸‹é¢ä»£ç è¿›è¡Œå®ç°ï¼ˆéƒ¨åˆ†åº“çš„å¯¼å…¥ä»¥åŠä¸€äº›å‚æ•°æ¯”å¦‚è¯´configç›´æ¥å¿½ç•¥ï¼‰

```python
from accelerate import Accelerator
kwargs_handlers=[DistributedDataParallelKwargs(find_unused_parameters=True)] # ä¸æ˜¯å¿…é¡»çš„
# Step-1 é¦–å…ˆåˆå§‹åŒ– accelerate
accelerator = Accelerator(mixed_precision= 'fp16', 
                            gradient_accumulation_steps= 2,
                            log_with= ['tensorboard', 'wandb'], # ä¸€èˆ¬æ¥è¯´ç”¨ä¸€ä¸ªå³å¯
                            project_dir=os.path.join(config.output_dir, "logs"),
                            kwargs_handlers= kwargs_handlers
                            )
# ä»…åœ¨ä¸»çº¿ç¨‹ä¸Šåˆ›å»ºæ–‡ä»¶å¤¹
if accelerator.is_main_process: 
    os.makedirs(config.output_dir, exist_ok=True)
    # åˆå§‹åŒ–ä¸€ä¸ªå®éªŒè®°å½•å™¨ï¼ˆæ­¤å¤„å†…å®¹éœ€è¦æ³¨æ„â­ï¼‰
    # accelerator.init_trackers(f"Train-{config.training}")
    log_name = 'Model-Test'
    accelerator.init_trackers(
        project_name= f"Page-Layout-Analysis-{config.pred_heads}",
        init_kwargs={
            "wandb": {
                "name": log_name,
                "dir": os.path.join(config.output_dir, "logs"),
                "config": vars(config)
            }
        }
        )
 
# Step-2 åˆå§‹åŒ–å®Œæˆä¹‹åå¯ä»¥ç›´æ¥å°†æˆ‘ä»¬éœ€è¦çš„å†…å®¹é€šè¿‡ accelerator.prepare è¿›è¡Œå¤„ç†
optimizer = torch.optim.AdamW([
        {'params': model.image_model.parameters(), 'lr': 2e-5, 'weight_decay': 1e-4},
        {'params': model.text_model.parameters(), 'lr': 4e-5},
        {'params': [p for n, p in model.named_parameters() 
                    if 'image_model' not in n and 'text_model' not in n], 
        'lr': config.learning_rate, 'weight_decay': 1e-4}, 
    ])
total_steps = config.epochs * len(train_dataloader)
warmup_steps = int(0.15 * total_steps)

# Warmup è°ƒåº¦å™¨ï¼šä» 0.1*lr çº¿æ€§å¢åŠ åˆ° lr
warmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, 
                                                        start_factor=0.1, 
                                                        total_iters=warmup_steps
)

# ä½™å¼¦é€€ç«è°ƒåº¦å™¨ï¼šæ·»åŠ  eta_min é˜²æ­¢å­¦ä¹ ç‡è¿‡ä½
cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 
                                                                T_max=total_steps - warmup_steps, 
                                                                eta_min=1e-6
)

cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 
                                                                T_max=total_steps - warmup_steps)
lr_scheduler = torch.optim.lr_scheduler.SequentialLR(
    optimizer,
    schedulers=[warmup_scheduler, cosine_scheduler],
    milestones=[warmup_steps] 
)
dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)

# Step-3 æ¨¡å‹è®­ç»ƒä»¥åŠæ¨¡å‹ä¼˜åŒ–
total_data = len(dataloader)
for i, batch in enumerate(dataloader):
    with accelerator.accumulate(model): # æ¢¯åº¦ç´¯è®¡
        inputs, targets = batch

        # ä¸‹é¢ä¸¤å¥å¯ä»¥ä¸ç”¨ï¼Œä½†æ˜¯ä¹ æƒ¯è¿˜æ˜¯ç›´æ¥ä½¿ç”¨
        inputs = inputs.to(accelerator.device)
        targets = targets.to(accelerator.device)

        outputs = model(inputs)
        loss = loss_function(outputs, targets)
        accelerator.backward(loss)
        if accelerator.sync_gradients: # è¿›è¡Œæ¢¯åº¦è£å‰ª
            accelerator.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()

        # è®°å½•ä¸€ä¸‹å®éªŒç»“æœ
        logs = {
                "Train/loss": loss.item(),
                "Train/lr": optimizer.param_groups[0]['lr'], # è¿™é‡Œæ˜¯å‡è®¾æ¨¡å‹ä½¿ç”¨çš„ä¼˜åŒ–å­¦ä¹ ç‡ä¸åŒ æˆ–è€…ç›´æ¥ä½¿ç”¨ scheduler.get_last_lr()[0]
                "Train/ACC": acc,
            }
            progress_bar.set_postfix(
                loss=loss.item(),
                acc=acc, f1=f1)
            accelerator.log(logs, step= epoch* total_data+ i)

# Step-3 åŒæ­¥ä¸åŒè¿›ç¨‹
accelerator.wait_for_everyone()
if accelerator.is_main_process:
    model = accelerator.unwrap_model(model)
    model.save_pretrained(os.path.join(args.output_dir, "model"))
accelerator.end_training()
```

ä¸è¿‡å¯¹äºä¸Šé¢çš„ä»£ç éœ€è¦æ³¨æ„å¦‚ä¸‹å‡ ä¸ªå†…å®¹
1ã€è¿½è¸ªå™¨ä½¿ç”¨ï¼šä¸€èˆ¬å¤šæ˜¾å¡ä½¿ç”¨è¿‡ç¨‹ä¸­é€šè¿‡ä½¿ç”¨ `accelerator.end_training()` å»ç»“æŸ `tracker`
2ã€tqdmä½¿ç”¨ï¼šä¸€èˆ¬åªéœ€è¦ä¸»è¿›ç¨‹è¿›è¡Œæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œå› æ­¤ä¸€èˆ¬ç›´æ¥ï¼š`tqdm(..., disable=not accelerator.is_local_main_process)`

## diffuser
> æ¨èç›´æ¥é˜…è¯»å®˜æ–¹æ–‡æ¡£ï¼š[https://huggingface.co/docs/diffusers/main/en/index](https://huggingface.co/docs/diffusers/main/en/index)
> [`pip install git+https://github.com/huggingface/diffusers`](https://huggingface.co/docs/diffusers/main/en/installation?install=Python)

### åŸºæœ¬ä½¿ç”¨
å¯¹äº[Diffusion ModelåŸç†](https://www.big-yellow-j.top/posts/2025/05/19/DiffusionModel.html)ç†è§£å¯ä»¥å‚è€ƒï¼Œä»¥åŠç›´æ¥é€šè¿‡ä¸‹é¢[è®­ç»ƒä¸€ä¸ªDiffusion Modelä»£ç ](https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelTraining/df_training.py)ï¼ˆä»£ç ä¸ä¸€å®šå¾ˆè§„èŒƒï¼‰è¿›è¡Œè§£é‡Šã€‚

```python
from diffusers import DDPMScheduler

noise_scheduler = DDPMScheduler(num_train_timesteps= config.num_train_timesteps,
                            beta_start= config.beta_start, # ä¸¤ä¸ªbetaä»£è¡¨åŠ å™ªæƒé‡
                            beta_end= config.beta_end,
                            beta_schedule= 'scaled_linear')
...
# training
for epoch in range(config.epochs):
    for i, batch in enumerate(train_dataloader):
        image = batch["images"]
        ...
        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, 
                                    (image.shape[0],), 
                                    device=image.device, 
                                    dtype=torch.int64)
            
        noise = torch.randn(image.shape, device= accelerator.device)
        noise_image = noise_scheduler.add_noise(image, noise, timesteps)
        ...
        noise_pred = model(noise_image, timesteps)
        loss = F.mse_loss(noise_pred, noise)
        ...
# eva
def evaluate(..., noise_scheduler, ):
    ...
    noise = torch.randn((config.eval_batch_size, config.channel, config.image_size, config.image_size)) # å¯ä»¥é€‰æ‹©å›ºå®šéšæœºæ•°ç§å­
    for t in noise_scheduler.timesteps:
        t_tensor = torch.full((noise.shape[0],), 
                                t, 
                                dtype=torch.long, 
                                device= device)
        predicted_noise = model(noise, t_tensor, text_label)
        noise = noise_scheduler.step(predicted_noise, t, noise).prev_sample
    images = (noise.clamp(-1, 1) + 1) / 2
    ...
```

è®­ç»ƒè¿‡ç¨‹
**1ã€åŠ å™ªå¤„ç†**ï¼šé€šè¿‡é€‰æ‹©ä½¿ç”¨DDPM/DDIMè€Œåå°†ç”Ÿæˆçš„"ç¡®å®šçš„å™ªå£°"æ·»åŠ åˆ°å›¾ç‰‡ä¸Š `noise_scheduler.add_noise(image, noise, timesteps)`
![image.png](https://s2.loli.net/2025/06/27/yLPrx7tkdOh3AiD.webp)

**2ã€æ¨¡å‹é¢„æµ‹**ï¼šé€šè¿‡æ¨¡å‹å»é¢„æµ‹æ‰€æ·»åŠ çš„å™ªå£°å¹¶ä¸”è®¡ç®—loss
ç”Ÿæˆè¿‡ç¨‹
**3ã€é€æ­¥è§£å™ª**ï¼šè®­ç»ƒå¥½çš„æ¨¡å‹é€æ­¥é¢„æµ‹å™ªå£°ä¹‹åå°†å…¶ä»å™ªå£°å›¾ç‰‡ä¸­å°†å™ªå£°å‰¥ç¦»å‡ºæ¥

### 1ã€Scheduler
> https://huggingface.co/docs/diffusers/api/schedulers/overview

ä»¥[DDPMScheduler](https://github.com/huggingface/diffusers/blob/d7dd924ece56cddf261cd8b9dd901cbfa594c62c/src/diffusers/schedulers/scheduling_ddpm.py#L129)ä¸ºä¾‹ä¸»è¦ä½¿ç”¨ä¸¤ä¸ªåŠŸèƒ½ï¼š
**1ã€add_noise**ï¼ˆ[è¾“å…¥](https://github.com/huggingface/diffusers/blob/d7dd924ece56cddf261cd8b9dd901cbfa594c62c/src/diffusers/schedulers/scheduling_ddpm.py#L501)ï¼š`sampleã€noiseã€timesteps`ï¼‰ï¼šè¿™ä¸ªæ¯”è¾ƒç®€å•å°±æ˜¯ç›´æ¥ï¼š$x=\sqrt{\alpha}x+ \sqrt{1-\alpha}\epsilon$
**2ã€step**ï¼ˆ[è¾“å…¥](https://github.com/huggingface/diffusers/blob/d7dd924ece56cddf261cd8b9dd901cbfa594c62c/src/diffusers/schedulers/scheduling_ddpm.py#L398)ï¼š`model_outputã€timestepã€sample`ï¼‰ï¼šstepåšçš„å°±æ˜¯å°†ä¸Šé¢çš„add_noiseè¿›è¡Œé€†æ“ä½œã€‚å…·ä½“ä»£ç å¤„ç†
* [**Step-1**](https://github.com/huggingface/diffusers/blob/d7dd924ece56cddf261cd8b9dd901cbfa594c62c/src/diffusers/schedulers/scheduling_ddpm.py#L437) é¦–å…ˆè®¡ç®—å‡ ä¸ªå‚æ•°ï¼š$\alphaã€\beta$

```python
alpha_prod_t = self.alphas_cumprod[t]
alpha_prod_t_prev = self.alphas_cumprod[prev_t] if prev_t >= 0 else self.one
beta_prod_t = 1 - alpha_prod_t
beta_prod_t_prev = 1 - alpha_prod_t_prev
current_alpha_t = alpha_prod_t / alpha_prod_t_prev
current_beta_t = 1 - current_alpha_t
```

* [**Step-2**](https://github.com/huggingface/diffusers/blob/d7dd924ece56cddf261cd8b9dd901cbfa594c62c/src/diffusers/schedulers/scheduling_ddpm.py#L445) æ ¹æ®è®¡ç®—å¾—åˆ°å‚æ•°åæ¨$t-1$çš„è®¡ç®—ç»“æœï¼ˆæä¾›3ç§ç±»ï¼Œä»‹ç»â€œepsilonâ€ï¼‰$x_0=\frac{x_T- \sqrt{1- \alpha_t}\epsilon}{\alpha_t}$

```pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)```

* [**Step-3**](https://github.com/huggingface/diffusers/blob/d7dd924ece56cddf261cd8b9dd901cbfa594c62c/src/diffusers/schedulers/scheduling_ddpm.py#L469C9-L474C109)ï¼šä»æ•°å­¦å…¬å¼ä¸Šåœ¨ä¸Šä¸€æ­¥å°±å¯ä»¥è®¡ç®—å¾—åˆ°ï¼Œä½†æ˜¯åœ¨[è®ºæ–‡](https://arxiv.org/pdf/2006.11239)ä¸­ä¸ºäº†æ›´åŠ è¿‘ä¼¼é¢„æµ‹ç»“æœè¿˜ä¼šè®¡ç®—ï¼š

$$
\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{1-\bar{\alpha}_{t}}\mathbf{x}_{0}+\frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_{t}}\mathbf{x}_{t}
$$

```python
pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * current_beta_t) / beta_prod_t
current_sample_coeff = current_alpha_t ** (0.5) * beta_prod_t_prev / beta_prod_t
pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample
```

åŒºåˆ«DDIMçš„å¤„ç†è¿‡ç¨‹å°†DDPMçš„é©¬å°”ç§‘å¤«é“¾æ›¿æ¢ä¸ºéé©¬å°”ç§‘å¤«é“¾è¿‡ç¨‹è€Œåè¿›è¡Œé‡‡æ ·ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥æ¯æ¬¡è¿­ä»£ä¸­è·¨å¤šä¸ªstepï¼Œä»è€Œå‡å°‘æ¨ç†è¿­ä»£æ¬¡æ•°å’Œæ—¶é—´ï¼š

$$
x_{t-1}=\sqrt{\alpha_{t-1}}\left(\frac{x_t-\sqrt{1-\alpha_t}\epsilon_\theta(x_t,t)}{\sqrt{\alpha_t}}\right)+\sqrt{1-\alpha_{t-1}-\sigma_t^2}\epsilon_\theta(x_t,t)+\sigma_tz
$$

```python
std_dev_t = eta * variance ** (0.5)
pred_sample_direction = (1 - alpha_prod_t_prev - std_dev_t**2) ** (0.5) * pred_epsilon
prev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction
 
prev_sample = prev_sample + variance
```

### 2ã€pipeline
> https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/README.md
> https://huggingface.co/docs/diffusers/v0.34.0/en/api/pipelines/overview#diffusers.DiffusionPipeline

å¾ˆå¤šè®ºæ–‡é‡Œé¢åŸºæœ¬éƒ½æ˜¯ç›´æ¥å»å¾®è°ƒè®­ç»ƒå¥½çš„æ¨¡å‹æ¯”å¦‚è¯´StableDiffusionç­‰ï¼Œä½¿ç”¨åˆ«äººè®­ç»ƒåçš„å°±å°‘ä¸äº†çœ‹åˆ° `pipeline`çš„å½±å­ï¼Œç›´æ¥ä»‹ç»[`StableDiffusionPipeline`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py)çš„æ„å»ºï¼ˆæ–‡ç”Ÿå›¾pipelineï¼‰ã€‚

![image.png](https://s2.loli.net/2025/06/21/5eTfQwG6tLDpycv.webp)

å‚è€ƒï¼š
1ã€https://github.com/huggingface/diffusers/blob/v0.34.0/src/diffusers/pipelines/pipeline_utils.py#L180
