---
layout: mypost
title: å¼€æºæ¨¡å‹æŠ€æœ¯æ€»ç»“-1â€”â€”â€”â€”Qwenç³»åˆ—æ¨¡å‹
categories: å¤šæ¨¡æ€
extMath: true
images: true
address: æ­¦æ±‰ğŸ¯
tags:
- cv-backbone
- å¤šæ¨¡æ€
- llm
- multimodal
show_footer_image: true
special_tag: é•¿æœŸæ›´æ–°
description: Qwenå¤šæ¨¡æ€ç³»åˆ—æ¨¡å‹è¿­ä»£è‡³QwenVL3ï¼Œå„ç‰ˆæœ¬æ ¸å¿ƒæ”¹è¿›åŒ…æ‹¬ï¼šQwenVLé‡‡ç”¨ViT-bigGè§†è§‰ç¼–ç å™¨ï¼Œå•å±‚Cross-Attentionèåˆå™¨å‹ç¼©è§†è§‰tokenè‡³256é•¿åº¦ï¼Œæ•´åˆäºŒç»´ç»å¯¹ä½ç½®ç¼–ç ï¼›QwenVL2å¼•å…¥åŠ¨æ€åˆ†è¾¨ç‡å¤„ç†ï¼Œ2x2ç›¸é‚»tokenæ‹¼æ¥åŠå¤šæ¨¡æ€æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆM-RoPEï¼‰ï¼Œå¢åŠ æ—¶é—´ç»´åº¦å¯¹é½è§†é¢‘å¤„ç†æµç¨‹ï¼›QwenVL2.5ä½¿ç”¨RMSNormæ›¿æ¢LayerNormï¼ŒViTä¸­MLPæ”¹ä¸ºSwiGLUç»“æ„ï¼Œæ–°å¢window-attentionï¼›QwenVL3å‡çº§MRoPE-Interleaveä½ç½®ç¼–ç ã€DeepStackæŠ€æœ¯èåˆViTå¤šå±‚æ¬¡ç‰¹å¾ï¼Œæ–‡æœ¬æ—¶é—´æˆ³å¯¹é½æœºåˆ¶æå‡è§†é¢‘äº‹ä»¶å®šä½ç²¾åº¦ï¼Œpatch_sizeä»14å¢è‡³16ï¼Œä¸‰ç»´å·ç§¯å«biasï¼ŒViTéšå±‚ç»´åº¦1280è°ƒæ•´ä¸º1152ï¼Œå›ºå®šé¢„è®­ç»ƒä½ç½®ç¼–ç é€šè¿‡åŒçº¿æ€§æ’å€¼é€‚é…æ–°åˆ†è¾¨ç‡ã€‚
---

## Qwenå¤§è¯­è¨€ç³»åˆ—æ¨¡å‹
## Qwenå¤šæ¨¡æ€ç³»åˆ—æ¨¡å‹
ç›®å‰QwenVLè¿­ä»£æ›´æ–°è¿­ä»£åˆ°3ï¼ˆ**æˆªè‡³2025.10.10**ï¼‰ä¸»è¦ä»‹ç»QwenVLã€QwenVL2ã€QwenVL2.5ã€QwenVL3
### QwenVL
åœ¨QwenVL[^4]ä¸­åœ¨è®ºæ–‡é‡Œé¢ä½œè€…æåˆ°çš„å…¶æ¨¡å‹çš„æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š
![](https://s2.loli.net/2025/09/21/HEhlRPFJBMKpjoZ.webp)
> ä»…ä»æä¾›çš„ä¸åŒé˜¶æ®µè¿˜æ˜¯å¾ˆå®¹æ˜“å‘ç°QwenVLè¿˜æ˜¯æ˜¯é‡‡ç”¨å’ŒBLIPç›¸ä¼¼çš„ä½¿ç”¨ learned-queryæ¥å¯¹é½æ¨¡æ€ä¿¡æ¯
> è¯­è¨€æ¨¡å‹ä½¿ç”¨ï¼ˆ7.7Bï¼‰ï¼šQwen-7B
> è§†è§‰ç¼–ç å™¨ï¼ˆ1.9Bï¼‰ï¼šVit-bigG
> èåˆå™¨ï¼ˆ0.08Bï¼‰ï¼šLearnable Query

ä¸è¿‡è®ºæ–‡é‡Œé¢å¯¹äºæ¨¡å‹ç»†èŠ‚ä»‹ç»ä¸æ˜¯å¾ˆå¤šï¼Œä»ä»£ç è§’åº¦å‡ºå‘çª¥å…¶æ¨¡å‹ç»“æ„ï¼š
**æ¨¡å‹è§†è§‰ç¼–ç å™¨**ï¼šè§†è§‰ç¼–ç å™¨ä½¿ç”¨çš„æ˜¯ViTæ¶æ„ï¼ˆVision Transformerï¼‰ï¼ŒViTçš„ç½‘ç»œè®¾ç½®å’Œåˆå§‹åŒ–å‚æ•°ä½¿ç”¨äº†OpenCLIPé¢„è®­ç»ƒå¥½çš„**ViT-bigGæ¨¡å‹**ã€‚å…·ä½“çš„ä»£ç å¤„ç†è¿‡ç¨‹ï¼ˆ[ä»£ç ](https://huggingface.co/Qwen/Qwen-VL/blob/main/visual.py)ï¼‰ï¼Œå…¶ä¸­æ¨¡å‹è¾“å‡ºç»´åº¦å˜åŒ–è¿‡ç¨‹ï¼š1x3x448x448-->1x1664x32x32ï¼ˆé¦–å…ˆå·ç§¯å¤„ç†ï¼‰-->1x1024x1664ï¼ˆæ‹‰å¹³äº¤æ¢ç»´åº¦ï¼‰
**ç‰¹å¾èåˆå™¨**ï¼šä¸Šè¿°ViTå¤„ç†åï¼Œå¯¹äº$448\times 448$åˆ†è¾¨ç‡çš„å›¾åƒï¼Œç”Ÿæˆä¸€ä¸ª **[1024, 1664]**çš„åºåˆ—ï¼Œä¹Ÿå°±æ˜¯å‘é‡ç»´åº¦ä¸º1664çš„é•¿åº¦ä¸º1024çš„åºåˆ—ã€‚ä¸ºäº†å‹ç¼©è§†è§‰tokençš„è¾“å…¥é•¿åº¦ï¼ŒQwen-VLå¼•å…¥äº†ä¸€ä¸ªAdapteræ¥å‹ç¼©å›¾åƒç‰¹å¾ã€‚è¿™ä¸ªAdaperå°±æ˜¯ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„å•å±‚Cross-Attentionæ¨¡å—ã€‚è¯¥æ¨¡å—ä½¿ç”¨ä¸€ç»„å¯å­¦ä¹ çš„queryå‘é‡ï¼Œå°†æ¥è‡ªViTçš„å›¾åƒç‰¹å¾ä½œä¸ºKeyå‘é‡ã€‚é€šè¿‡Cross-Attentionæ“ä½œåå°†è§†è§‰ç‰¹å¾åºåˆ—å‹ç¼©åˆ°å›ºå®šçš„256é•¿åº¦ï¼ˆä¹Ÿå°±æ˜¯å°†è§†è§‰ç‰¹å¾å‹ç¼©åˆ° **256 1644**ï¼‰
æ­¤å¤–ï¼Œè€ƒè™‘åˆ°ä½ç½®ä¿¡æ¯å¯¹äºç²¾ç»†å›¾åƒç†è§£çš„é‡è¦æ€§ï¼ŒQwen-VLå°†äºŒç»´ç»å¯¹ä½ç½®ç¼–ç ï¼ˆä¸‰è§’ä½ç½®ç¼–ç ï¼‰æ•´åˆåˆ°Cross-Attentionçš„ $q,k$ä¸­ï¼Œä»¥å‡å°‘å‹ç¼©è¿‡ç¨‹ä¸­å¯èƒ½ä¸¢å¤±çš„ä½ç½®ç»†èŠ‚ã€‚éšåå°†é•¿åº¦ä¸º256çš„å‹ç¼©å›¾åƒç‰¹å¾åºåˆ—è¾“å…¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ã€‚
### QwenVL-2
å¯¹äºQwenVL-2[^3]å…¶æ¨¡å‹çš„åŸºæœ¬ç»“æ„å¦‚ä¸‹ï¼š
![](https://s2.loli.net/2025/09/21/5c1jovnLVOaS62H.webp)
**1ã€ä½¿ç”¨åŠ¨æ€åˆ†è¾¨ç‡**ï¼ˆä¹Ÿå°±æ˜¯è¯´è¾“å…¥å›¾åƒä¸éœ€è¦å†å»æ”¹å˜å›¾åƒå°ºå¯¸åˆ°ä¸€ä¸ªå›ºå®šå€¼ï¼‰ï¼Œäºæ­¤åŒæ—¶ä¸ºäº†å‡å°‘ **visual-token**æ•°é‡ï¼Œå°†**2x2çš„çš„ç›¸é‚»çš„tokenè¿›è¡Œæ‹¼æ¥**åˆ°ä¸€ä¸ªtokenè€Œåé€šè¿‡MLPå±‚è¿›è¡Œå¤„ç†ã€‚
![](https://s2.loli.net/2025/09/21/w3agENHmLVcoSdt.webp)
**åŠ¨æ€åˆ†è¾¨ç‡**å¤„ç†å¦‚ä¸Šï¼Œé€šè¿‡æŒ‡å®š`[mix_pixels, max_pixels]`èŒƒå›´ç„¶åå°†å›¾åƒä¿æŒåŸå§‹çš„çºµæ¨ªæ¯”å»ç¼©å‡å›¾åƒåˆ°ä¸Šé¢çš„èŒƒå›´ä¸­ï¼ˆ[å¤„ç†è¿‡ç¨‹](https://github.com/QwenLM/Qwen2.5-VL/blob/c15045f8829fee29d4b3996e068775fe6a5855db/qwen-vl-utils/src/qwen_vl_utils/vision_process.py#L59)ï¼Œé¦–å…ˆè®¡ç®—åŸå§‹å›¾åƒçš„åƒç´ æ•°é‡ï¼Œè€Œååˆ¤æ–­å’Œä¸Šé¢æŒ‡æ ‡çš„èŒƒå›´ï¼Œå¦‚æœè¶…å‡ºèŒƒå›´å°±å»è®¡ç®—éœ€è¦ä¿®æ”¹çš„æ¯”ä¾‹ï¼Œåœ¨å°†æ•´ä¸ªæ¯”ä¾‹å»å¤„ç†åˆ°åˆ†è¾¨ç‡ä¸Šï¼‰
åœ¨é€šè¿‡ä½¿ç”¨åŠ¨æ€åˆ†è¾¨ç‡å¤„ç†å›¾åƒä¹‹åä¼šåœ¨å•ä¸€**å›¾ç‰‡å¢åŠ æ—¶é—´ç»´åº¦**ä¹Ÿå°±æ˜¯å°†ï¼šCHW-->TCHWï¼ˆè¿™ç‚¹æ˜¯ä¸ºäº†å’Œè§†é¢‘å¤„ç†è¿‡ç¨‹è¿›è¡Œå¯¹é½ï¼‰ï¼Œåœ¨æºç ä¸­Té€‰æ‹©æ•°å€¼ä¸º2ä¹Ÿå°±æ˜¯å°†å›¾ç‰‡â€œå¤åˆ¶ä¸€æ¬¡â€ï¼Œè€Œåå¯¹å¸§åºåˆ—è¿›è¡ŒPatchificationæ“ä½œ
```python
def _preprocess(): 
    ......   
    channel = patches.shape[1]
    grid_t = patches.shape[0] // self.temporal_patch_size
    grid_h, grid_w = resized_height // self.patch_size, resized_width // self.patch_size
    patches = patches.reshape(
        grid_t,                            # 0
        self.temporal_patch_size, channel, # 1 2
        grid_h // self.merge_size,         # 3
        self.merge_size, self.patch_size,  # 4 5
        grid_w // self.merge_size,         # 6
        self.merge_size, self.patch_size,  # 7 8
    ) # self.merge_size=2 self.patch_size=14 self.temporal_patch_size=2
    ### å°†2x2çš„é‚»åŸŸPatchæ”¾åˆ°ä¸€èµ·ï¼Œæ–¹ä¾¿åç»­åšé¢†åŸŸçš„Patchè¿‡Projectorå±‚åšèšåˆå‹ç¼©
    patches = patches.transpose(0, 3, 6, 4, 7, 2, 1, 5, 8)
    ### Patchåºåˆ—åŒ–ï¼Œå¹¶ä¿ç•™Patchä½ç½®ä¿¡æ¯ï¼ˆæ—¶é—´ï¼Œé«˜ï¼Œå®½ï¼‰
    flatten_patches = patches.reshape(
        grid_t * grid_h * grid_w, channel * self.temporal_patch_size * self.patch_size * self.patch_size
    )
```
ä¸Šé¢è¿‡ç¨‹ä¹Ÿå°±æ˜¯è¿›è¡Œæ‰€è°“çš„â€œ2x2çš„ç›¸é‚»tokenæ‹¼æ¥â€ï¼Œæœ€åå¾—åˆ°`[grid_t * grid_h * grid_w, channel * temporal_patch_size(2) * patch_size(14) * patch_size(14)]`ï¼ˆå…¶ä¸­`grid_h=resized_height // self.patch_size(14)`ï¼‰
2ã€**å¤šæ¨¡æ€çš„æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆM-RoPEï¼‰**,ä¹Ÿå°±æ˜¯å°†åŸæ¥ä½ç½®ç¼–ç æ‰€æºå¸¦çš„ä¿¡æ¯å¤„ç†ä¸ºï¼šæ—¶åºï¼ˆtemporalï¼‰ã€é«˜åº¦ï¼ˆheightï¼‰ã€å®½åº¦ï¼ˆwidthï¼‰ã€‚æ¯”å¦‚ä¸‹å›¾ä¸­å¯¹äºæ–‡æœ¬å¤„ç†ç›´æ¥åˆå§‹åŒ–ä¸ºï¼š$(i,i,i)$ã€‚ä½†æ˜¯å¯¹äºå›¾ç‰‡è€Œè¨€å°±æ˜¯ï¼š$(i,x,y)$ å…¶ä¸­ $i$ æ˜¯æ’å®šçš„ï¼Œè€Œå¯¹äºè§†é¢‘å°±ä¼šå°† $i$ æ¢æˆè§†é¢‘ä¸­å›¾åƒçš„é¡ºåº
**æ€»ç»“å¤„ç†è¿‡ç¨‹**ï¼šåŠ¨æ€åˆ†è¾¨ç‡å¤„ç†-->å¤åˆ¶æ—¶é—´ç»´åº¦-->å°†åºåˆ—åˆ‡å‰²ä¸ºpatchã€‚è¿™æ ·ä¸€æ¥å°±ä¼šç›´æ¥å°†å›¾åƒå¤„ç†ä¸ºï¼š`[grid_t * grid_h * grid_w, channel * temporal_patch_size(2) * patch_size(14) * patch_size(14)]`ï¼ˆå…¶ä¸­`grid_h=resized_height // self.patch_size(14)`ï¼‰é™¤æ­¤ä¹‹å¤–è€Œåå»è®¡ç®— 3d-RoPEæœ€åé€šè¿‡ä¸€å±‚çº¿æ€§å±‚å¤„ç†å°±å¾—åˆ°æœ€åçš„è§†è§‰tokenã€‚
### QwenVL-2.5
åœ¨QwenVL2.5ä¸­[^6]æ¨¡å‹å…·ä½“çš„ä»£ç å¤„ç†è¿‡ç¨‹å‚è€ƒBlog[^5]å…·ä½“æ¨¡å‹ç»“æ„ï¼š
![](https://s2.loli.net/2025/09/21/R8yLfVqpznvkgZw.webp)
åœ¨å›¾åƒå¤„ç†è¿‡ç¨‹ä¸Šå’ŒQwenVL2å·®å¼‚ä¸å¤§éƒ½æ˜¯ç›´æ¥ï¼šåŠ¨æ€åˆ†è¾¨ç‡å¤„ç†-->å¤åˆ¶æ—¶é—´ç»´åº¦-->å°†åºåˆ—åˆ‡å‰²ä¸ºpatchï¼Œå¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹å·®å¼‚ï¼š
![](https://s2.loli.net/2025/09/22/NvKgQqhC36WAkjU.webp)
1ã€é‡‡ç”¨ RMSNorm æ›¿æ¢äº†æ‰€æœ‰ LayerNormï¼›2ã€ViTä¸­æ¯ä¸€ä¸ªVisionBlockä¸­çš„MLPæ¢æˆäº†SwiGLU ç»“æ„ã€‚åªä»æ¨¡å‹ç»“æ„ä¸Šå·®å¼‚ä¸åˆ°ï¼Œåœ¨QwenVL2.5ä¸­ä¸»è¦è¿›è¡Œæ”¹åŠ¨ï¼š1ã€ä½¿ç”¨window-attentionï¼ˆå¯¹åº”ä¸Šè¿°ç»“æ„ä¸­çš„`Qwen2_5_VLVisionAttention`ï¼‰å¯¹äºå…·ä½“çš„åˆ’åˆ†windowæ–¹æ³•ï¼ˆ[ä»£ç ](https://github.com/huggingface/transformers/blob/41925e42135257361b7f02aa20e3bbdab3f7b923/src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py#L465)ï¼‰ï¼šæ ¹æ®è¾“å…¥çš„å›¾åƒå¤§å° (gird_t, grid_h, grid_w)å»å¾—åˆ°çª—å£ç´¢å¼• (window_index) å’Œ ç´¯ç§¯åºåˆ—é•¿åº¦ (cu_window_seqlens)ã€‚å…·ä½“ä¾‹å­å¦‚ä¸‹ï¼š
```python
# æ•°æ®æ•°æ®ç‰¹å¾
[ [ 0,  1,  2,  3,  4,  5],
  [ 6,  7,  8,  9, 10, 11],
  [12, 13, 14, 15, 16, 17],
  [18, 19, 20, 21, 22, 23],
  [24, 25, 26, 27, 28, 29],
  [30, 31, 32, 33, 34, 35] ]
# ä¿è¯å¯ä»¥è¢«window_sizeåˆ’åˆ†éœ€è¦è¿›è¡Œå¡«å……
[ [ 0,  1,  2,  3,  4,  5, X, X],
  [ 6,  7,  8,  9, 10, 11, X, X],
  [12, 13, 14, 15, 16, 17, X, X],
  [18, 19, 20, 21, 22, 23, X, X],
  [24, 25, 26, 27, 28, 29, X, X],
  [30, 31, 32, 33, 34, 35, X, X],
  [ X,  X,  X,  X,  X,  X, X, X],
  [ X,  X,  X,  X,  X,  X, X, X] ]
# è€Œåç›´æ¥æ›´å…·windowå¤§å°å¾—åˆ°æ¯ä¸ªéœ€è¦è®¡ç®—æ³¨æ„åŠ›çš„window
# window-0
[ 0,  1,  2,  3]
[ 6,  7,  8,  9] 
[12, 13, 14, 15]
[18, 19, 20, 21]
# å±•å¹³é‡æ–°æ’åˆ—å¾—åˆ°ï¼š
# window-0
[0, 1, 2, 3, 6, 7, 8, 9, 12, 13, 14, 15, 18, 19, 20, 21]
# window-1 
[4, 5, 10, 11, 16, 17, 22, 23]
# è®¡ç®—ç´¯è®¡é•¿åº¦
seqlens = (index_padded != -100).sum([2, 3]) # è®¡ç®—æœ‰æ•ˆé•¿åº¦ï¼šwindow-0ï¼š16 window-1ï¼š8.....
cu_seqlens_tmp = seqlens.cumsum(0) * 4 + cu_window_seqlens[-1]
cu_window_seqlens.extend(cu_seqlens_tmp.tolist())
# [0, 64, 96, 128, 144]
# å¾—åˆ°æœ€åè¿”å›ç»“æœwindow_index, cu_window_seqlens
```
åœ¨å¾—åˆ°window_indexå’Œcu_window_seqlensä¹‹åå°±æ˜¯[è®¡ç®—æ³¨æ„åŠ›è¿‡ç¨‹](https://github.com/huggingface/transformers/blob/41925e42135257361b7f02aa20e3bbdab3f7b923/src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py#L267C9-L275C100)
```python
for i in range(1, len(cu_seqlens)):
  attention_mask[..., cu_seqlens[i - 1] : cu_seqlens[i], cu_seqlens[i - 1] : cu_seqlens[i]] = 0

q = q.transpose(0, 1)
k = k.transpose(0, 1)
v = v.transpose(0, 1)
attn_weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.head_dim)
attn_weights = attn_weights + attention_mask
attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(q.dtype)
```
### QwenVL-3
åœ¨å®˜æ–¹Blog[^7]çš„ä»‹ç»ä¸­
![20260226135106](https://ghfast.top/https://raw.githubusercontent.com/Big-Yellow-J/BlogImage/main/image/20260226135106.png)
å¯¹äºæ¨¡å‹æ¶æ„çš„æ›´æ–°ç®€å•æ€»ç»“ä¸ºï¼š1ã€**MRoPE-Interleave**: æ”¹è¿›ä½ç½®ç¼–ç ï¼Œé‡‡ç”¨æ—¶é—´(t)ã€é«˜åº¦(h)ã€å®½åº¦(w)äº¤é”™åˆ†å¸ƒå½¢å¼ï¼Œæå‡å¯¹é•¿è§†é¢‘çš„ç†è§£èƒ½åŠ›ã€‚2ã€**DeepStack æŠ€æœ¯**: èåˆ ViT å¤šå±‚æ¬¡ç‰¹å¾ï¼Œå°†è§†è§‰ç‰¹å¾æ³¨å…¥ LLM çš„å¤šå±‚ä¸­ï¼Œå®ç°æ›´ç²¾ç»†åŒ–çš„è§†è§‰ç†è§£å’Œå›¾æ–‡å¯¹é½ç²¾åº¦ã€‚3ã€**æ–‡æœ¬æ—¶é—´æˆ³å¯¹é½æœºåˆ¶ (T-RoPE å‡çº§)**: é‡‡ç”¨â€œæ—¶é—´æˆ³-è§†é¢‘å¸§â€äº¤é”™è¾“å…¥å½¢å¼ï¼Œå®ç°å¸§çº§åˆ«æ—¶é—´ä¿¡æ¯ä¸è§†è§‰å†…å®¹çš„ç»†ç²’åº¦å¯¹é½ï¼Œæå‡è§†é¢‘äº‹ä»¶å®šä½ç²¾åº¦ã€‚æ•´ä½“æ¨¡å‹ç»“æ„åœ¨åŒºåˆ«ä¸Šä¸€ä»£QwenVL-2.5æ”¹è¿›ç‚¹åœ¨äºï¼špatch_embedçš„patch_sizeå˜å¤§äº†ï¼ˆ14->16ï¼‰ï¼Œembedä½¿ç”¨çš„ä¸‰ç»´å·ç§¯é‡ŒåŠ äº†biasï¼ŒViTçš„éšå±‚ç»´åº¦hiddeen_dimä»1280->1152ï¼Œè€Œåä½¿ç”¨DeepStackã€MRoPE-Interleaveã€‚
* **DeepStack æŠ€æœ¯åŸç†**

ä»æœ€ä¸Šé¢çš„æ¨¡å‹ç»“æ„å›¾ä¸­å¯ä»¥å‘ç°DeepStackå°±æ˜¯å°†è§†è§‰è§†è§‰ç¼–ç å™¨ç‰¹å¾èå…¥åˆ°LLM Blockçš„æ¯ä¸€å±‚ä¸­ï¼Œå‚è€ƒè®ºæ–‡ä¸­çš„ç»“æ„å›¾[^9]:
![20260226135226](https://ghfast.top/https://raw.githubusercontent.com/Big-Yellow-J/BlogImage/main/image/20260226135226.png)
ä¹‹æ‰€ä»¥è¦ä½¿ç”¨è¯¥æŠ€æœ¯æ˜¯ä¸ºäº†è§£å†³ï¼š**è®¡ç®—ä¸å†…å­˜å¼€é”€è¿‡é«˜**:ä¼ ç»ŸLMMså°†æ‰€æœ‰è§†è§‰visual tokensæ‹¼æ¥æˆä¸€ç»´åºåˆ—è¾“å…¥åˆ°è¯­è¨€æ¨¡å‹çš„ç¬¬ä¸€å±‚ï¼Œå¯¼è‡´éœ€è¦å¤„ç†çš„è¾“å…¥åºåˆ—é•¿åº¦æ˜¾è‘—å¢åŠ ï¼Œå°¤å…¶åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæˆ–å¤šå¸§è§†é¢‘æ—¶ï¼Œè®¡ç®—å’Œå†…å­˜æˆæœ¬æ€¥å‰§ä¸Šå‡ã€‚**ç»†ç²’åº¦è§†è§‰ä¿¡æ¯ä¸¢å¤±**:ç°æœ‰æ–¹æ³•é€šè¿‡å‹ç¼©è§†è§‰Token(å¦‚ç©ºé—´æ± åŒ–ã€æ„ŸçŸ¥å™¨é‡é‡‡æ ·ç­‰)æ¥å¹³è¡¡è®¡ç®—å¼€é”€ä¸ä¿¡æ¯ä¿ç•™ï¼Œä½†ä¼šç‰ºç‰²é«˜åˆ†è¾¨ç‡å›¾åƒä¸­çš„ç»†èŠ‚ä¿¡æ¯ã€‚**è§†è§‰ä¸è¯­è¨€äº¤äº’æ•ˆç‡ä¸è¶³**:ç°æœ‰æ–¹æ³•ä»…é€šè¿‡ç¬¬ä¸€å±‚Transformerå¤„ç†æ‰€æœ‰è§†è§‰Tokenï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨è¯­è¨€æ¨¡å‹æ·±å±‚ç»“æ„çš„å±‚æ¬¡åŒ–ç‰¹å¾æå–èƒ½åŠ›ã€‚
#### æºç ç»“æ„
å¯¹äºå…·ä½“æºç ï¼ˆ[ä»£ç ](https://github.com/huggingface/transformers/blob/0419ff881d7bb503f4fc0f0a7a5aac3d012c9b91/src/transformers/models/qwen3_vl/modular_qwen3_vl.py)ï¼‰åˆ†ææ•´ä½“æ¨¡å‹å¤„ç†è¿‡ç¨‹å¦‚ä¸‹ï¼ˆ[ä»£ç ](https://github.com/huggingface/transformers/blob/0419ff881d7bb503f4fc0f0a7a5aac3d012c9b91/src/transformers/models/qwen3_vl/modeling_qwen3_vl.py#L885)ï¼‰
> **å€¼å¾—æ³¨æ„çš„æ˜¯åœ¨è¾“å…¥æ•°æ®é¢„å¤„ç†é˜¶æ®µQwenVL-3å’Œ2.5çš„å¤„ç†æ˜¯ç›¸åŒçš„é€šè¿‡smart_resizeå»ä¿®æ”¹åˆ†è¾¨ç‡**

```python
class Qwen3VLModel(Qwen3VLPreTrainedModel):
  ...
  def __iniit__(...):
    super().__init__(config)
    self.visual = Qwen3VLVisionModel._from_config(config.vision_config)
    self.language_model = Qwen3VLTextModel._from_config(config.text_config)
    self.rope_deltas = None  # cache rope_deltas here
    self.post_init()
  def forward(...):
    ...
    # å›¾åƒå¤„ç†è¿‡ç¨‹
    if pixel_values is not None:
      image_embeds, deepstack_image_embeds = self.get_image_features(pixel_values, image_grid_thw)
      image_embeds = torch.cat(image_embeds, dim=0).to(inputs_embeds.device, inputs_embeds.dtype)
      image_mask, _ = self.get_placeholder_mask(
          input_ids, inputs_embeds=inputs_embeds, image_features=image_embeds
      )
      inputs_embeds = inputs_embeds.masked_scatter(image_mask, image_embeds)
    ...
    outputs = self.language_model(...,inputs_embeds=inputs_embeds,...)
```
* `get_image_features`å¤„ç†è¿‡ç¨‹ï¼šé€šè¿‡Qwenè§†è§‰ç¼–ç å…¶å¤„ç†å¹¶ä¸”è·å–ç‰¹å®šå±‚è§†è§‰ç¼–ç ç‰¹å¾

é€šè¿‡è§†è§‰ç¼–ç å¤„ç†å¾—åˆ°`image_embeds`å’Œ `deepstack_image_embeds`è€Œåå†å»å¯¹ `image_embeds`è¿›è¡Œè£å‰ªï¼Œè£å‰ªçš„é€»è¾‘ä¸ºï¼š`split_sizes = (image_grid_thw.prod(-1) // self.visual.spatial_merge_size**2).tolist();image_embeds = torch.split(image_embeds, split_sizes)` å›åˆ°`self.visual`ä¸­æ¨¡å‹å…·ä½“å¤„ç†è¿‡ç¨‹å¦‚ä¸‹ï¼ˆ[ä»£ç ](https://github.com/huggingface/transformers/blob/0419ff881d7bb503f4fc0f0a7a5aac3d012c9b91/src/transformers/models/qwen3_vl/modeling_qwen3_vl.py#L701)ï¼‰ï¼š
```python
# https://github.com/huggingface/transformers/blob/0419ff881d7bb503f4fc0f0a7a5aac3d012c9b91/src/transformers/models/qwen3_vl/modeling_qwen3_vl.py#L701
class Qwen3VLVisionModel(Qwen3VLPreTrainedModel):
  def __init__(...):
    ...
    self.blocks = nn.ModuleList([Qwen3VLVisionBlock(config) for _ in range(config.depth)])
    self.merger = Qwen3VLVisionPatchMerger(...)
    self.deepstack_visual_indexes = config.deepstack_visual_indexes
    self.deepstack_merger_list = nn.ModuleList(
        [
            Qwen3VLVisionPatchMerger(
                config=config,
                use_postshuffle_norm=True,
            )
            for _ in range(len(config.deepstack_visual_indexes))
        ]
    )
  def forward(self, hidden_states: torch.Tensor, grid_thw: torch.Tensor, **kwargs):
    ... # å¯¹å›¾åƒæ•°æ®é€šè¿‡ patch_embed è¿›è¡Œå¤„ç†è€Œåè¡¥å……ä½ç½®ç¼–ç 
    # Vitå¤„ç†
    deepstack_feature_lists = []
    for layer_num, blk in enumerate(self.blocks):
        hidden_states = blk(...)
        if layer_num in self.deepstack_visual_indexes:
            deepstack_feature = self.deepstack_merger_list[self.deepstack_visual_indexes.index(layer_num)](hidden_states)
            deepstack_feature_lists.append(deepstack_feature)
    hidden_states = self.merger(hidden_states) # ç›´æ¥é€šè¿‡ä¸¤å±‚fcè¿›è¡Œå¤„ç†
    return hidden_states, deepstack_feature_lists
```
`patch_embed`å°±æ˜¯ç›´æ¥ä½¿ç”¨3ç»´å·ç§¯ï¼ˆbiasä¸ºTrueï¼‰ï¼š`Conv3d(3, 1152, kernel_size=(2, 16, 16), stride=(2, 16, 16))`ï¼ˆç»´åº¦ä¸Šå¯¹åº”ï¼š`(grid_t*grid_h*grid_w, hiddend_size)`ï¼‰ï¼Œå¯¹äºä¸Šè¿°DStackè¿‡ç¨‹ä¸­ä¹Ÿæ¯”è¾ƒå¥½ç†è§£ç›´æ¥ä»éœ€è¦å¤„ç†çš„æ¯å±‚ï¼ˆé€šè¿‡Qwen3VLVisionBlockæ€»å…±ç”±27å±‚å åŠ ï¼‰ä¸­æŒ‘é€‰å‡ºå¯¹åº”çš„å¤„ç†åçš„ç‰¹å¾ï¼Œç›´æ¥æŒ‘é€‰[8, 16, 24]å±‚å¤„ç†åçš„ç‰¹å¾ã€‚
> åœ¨ ViT æ¨¡å‹çš„é¢„è®­ç»ƒé˜¶æ®µï¼Œé€šå¸¸ä½¿ç”¨å›ºå®šçš„è¾“å…¥åˆ†è¾¨ç‡ï¼ˆä¾‹å¦‚ 224Ã—224ï¼‰ï¼Œå¹¶å°†å…¶åˆ’åˆ†ä¸ºå›ºå®šæ•°é‡çš„ patchï¼ˆä¾‹å¦‚ 14Ã—14ï¼Œå…± 196 ä¸ª patchï¼‰ã€‚è¿™æ„å‘³ç€æ¨¡å‹å†…éƒ¨çš„ pos_embed æ˜¯ä¸€ä¸ªå›ºå®šé•¿åº¦çš„å¯å­¦ä¹ å‚æ•°çŸ©é˜µï¼Œæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å·²ç»éšå¼åœ°å­¦ä¹ åˆ°äº†è¿™äº›ä½ç½®ç¼–ç ä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚å½“æ¨ç†é˜¶æ®µè¾“å…¥çš„åˆ†è¾¨ç‡å‘ç”Ÿå˜åŒ–æ—¶ï¼Œå¦‚æœç›´æ¥é‡æ–°è®¡ç®—æˆ–ç”Ÿæˆæ–°çš„ä½ç½®ç¼–ç ï¼Œå°±ä¼šç ´åæ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå­¦åˆ°çš„ç©ºé—´è¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼ŒQwenVL-3 ç­‰æ¨¡å‹çš„åšæ³•æ˜¯ï¼š**å›ºå®šä¸€å¥—åœ¨é¢„è®­ç»ƒé˜¶æ®µå­¦ä¹ åˆ°çš„ä½ç½®ç¼–ç **ï¼Œåœ¨è¾“å…¥æ–°çš„åˆ†è¾¨ç‡æ—¶ï¼Œä¸é‡æ–°ç”Ÿæˆç¼–ç ï¼Œè€Œæ˜¯é€šè¿‡ **åŒçº¿æ€§æ’å€¼** å°†åŸå§‹ä½ç½®ç¼–ç æ˜ å°„åˆ°æ–°çš„ç©ºé—´å°ºåº¦ä¸Šï¼Œä»è€Œåœ¨ä¿æŒé¢„è®­ç»ƒç©ºé—´ç»“æ„çš„å‰æä¸‹ï¼Œé€‚é…ä¸åŒè¾“å…¥å°ºå¯¸ã€‚æ¢å¥è¯è¯´ï¼Œæ–°çš„ patch ä½ç½®ä¸å†é‡æ–°è®¡ç®— embeddingï¼Œè€Œæ˜¯é€šè¿‡æ’å€¼åœ¨åŸæœ‰ä½ç½®ç¼–ç ä¸Šâ€œæ‰¾åˆ°â€å…¶å¯¹åº”çš„ç©ºé—´ä½ç½®ã€‚
* llmå¤„ç†è¿‡ç¨‹ï¼šç›´æ¥å°†è§†è§‰tokenä½ç½®ä¸Šè¡¥å……æˆ‘çš„DeepStackç‰¹å¾

```python
# https://github.com/huggingface/transformers/blob/0419ff881d7bb503f4fc0f0a7a5aac3d012c9b91/src/transformers/models/qwen3_vl/modeling_qwen3_vl.py#L760
class Qwen3VLTextModel(Qwen3VLPreTrainedModel):
    def __init__(self, config: Qwen3VLTextConfig):
        super().__init__(config)
        self.padding_idx = config.pad_token_id
        self.vocab_size = config.vocab_size

        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)
        self.layers = nn.ModuleList(
            [Qwen3VLTextDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]
        )
        self.norm = Qwen3VLTextRMSNorm(config.hidden_size, eps=config.rms_norm_eps)
        self.rotary_emb = Qwen3VLTextRotaryEmbedding(config=config)
        self.gradient_checkpointing = False

    def forward(...,input_ids: Optional[torch.LongTensor] = None,
        attention_mask: Optional[torch.Tensor] = None,
        position_ids: Optional[torch.LongTensor] = None,...
        visual_pos_masks: Optional[torch.Tensor] = None,
        deepstack_visual_embeds: Optional[list[torch.Tensor]] = None,
    ):
        ...
        for layer_idx, decoder_layer in enumerate(self.layers):
            layer_outputs = decoder_layer(...) # æ¨¡å‹è§£ç è¾“å‡º
            hidden_states = layer_outputs

            if deepstack_visual_embeds is not None and layer_idx in range(len(deepstack_visual_embeds)):
                hidden_states = self._deepstack_process(
                    hidden_states,
                    visual_pos_masks,
                    deepstack_visual_embeds[layer_idx],
                )
        hidden_states = self.norm(hidden_states)
        ...
    def _deepstack_process(
        self, hidden_states: torch.Tensor, visual_pos_masks: torch.Tensor, visual_embeds: torch.Tensor
    ):
        visual_pos_masks = visual_pos_masks.to(hidden_states.device) # å½¢çŠ¶ batch_size, seqlen
        visual_embeds = visual_embeds.to(hidden_states.device, hidden_states.dtype)
        local_this = hidden_states[visual_pos_masks, :].clone() + visual_embeds
        hidden_states[visual_pos_masks, :] = local_this
        return hidden_states
```
å…¶å®ä»ä¸Šé¢ä»£ç ä¸­å¾ˆå®¹æ˜“å‘ç°åœ¨DeepStackä¸­QwenVL-3å¤„ç†æ–¹å¼å¾ˆç®€å•ç›´æ¥é€‰å‡º**æ‰€æœ‰è§†è§‰tokenä½ç½®**è€Œåå°†è§†è§‰ç‰¹å¾è¿›è¡Œè¡¥å……ï¼Œå…¶ä¸­visual_pos_masksçš„å½¢çŠ¶æ˜¯batch_size, seqlen
### æ€»ç»“
ä»QwenVLåˆ°QwenVL2.5è§†è§‰ç¼–ç å™¨å¤„ç†è¿‡ç¨‹ï¼š
**QwenVL**ï¼šå°†å›¾åƒè½¬åŒ–ä¸º**å›ºå®šçš„åˆ†è¾¨ç‡**è€Œåå°†è¾“å…¥åˆ°Vit-bigGè¿›è¡Œå¤„ç†å¾—åˆ°è§†è§‰ç‰¹å¾ä¹‹åå†å»ä½¿ç”¨ç±»ä¼¼Q-formerå¤„ç†è¿‡ç¨‹ï¼ˆQwenVLä¸­ä½¿ç”¨çš„æ˜¯*ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„å•å±‚Cross-Attentionæ¨¡å—*ï¼‰ä½¿ç”¨learned-queryï¼ˆå‹ç¼©åˆ°**å›ºå®šçš„256é•¿åº¦çš„token**ï¼‰å°†è§†è§‰tokenè¿›è¡Œå‹ç¼©è€Œåè¾“å…¥åˆ°LLMä¸­ã€‚
**QwenVL2**ï¼šé¦–å…ˆä½¿ç”¨**åŠ¨æ€åˆ†è¾¨ç‡**ï¼ˆå°†å›¾åƒ**é™¤ä»¥å›ºå®šçš„factorè€Œåä¿æŒæ¨ªçºµæ¯”**å°†å…¶ç¼©å‡åˆ° `[mix_pixels, max_pixels]`ä¸­ï¼‰å»å¤„ç†å›¾åƒè€Œåå°†å…¶è¾“å…¥åˆ°è§†è§‰ç¼–ç å™¨ä¸­ï¼Œè€Œåå°†**2x2çš„çš„ç›¸é‚»çš„tokenè¿›è¡Œæ‹¼æ¥**ï¼ˆä¹Ÿå°±æ˜¯å°†å›¾åƒè¡¥å……ä¸€ä¸ªæ—¶é—´å¸§å¾—åˆ°TCHWï¼Œè€Œåå†å»åœ¨THWä¸‰ä¸ªç»´åº¦åˆ’åˆ†å¾—åˆ°ä¸åŒçš„patchï¼šgrid_t,grid_h,grid_wï¼‰åˆ°ä¸€ä¸ªtokenè€Œåé€šè¿‡MLPå±‚è¿›è¡Œå¤„ç†ã€‚
**QwenVL2.5**ï¼šæ•´ä½“æ¡†æ¶ä¸Šå’ŒQwenVL2å·®å¼‚ä¸å¤§ï¼ŒåŒºåˆ«åœ¨äºä½¿ç”¨äº†window-attentionä»¥åŠ2D-RoPE
## å‚è€ƒ
[^1]: [https://arxiv.org/abs/2504.07491](https://arxiv.org/abs/2504.07491)
[^2]: [https://zhuanlan.zhihu.com/p/25267823390](https://zhuanlan.zhihu.com/p/25267823390)
[^3]: [http://arxiv.org/abs/2409.12191](http://arxiv.org/abs/2409.12191)
[^4]: [https://arxiv.org/pdf/2308.12966](https://arxiv.org/pdf/2308.12966)
[^5]: [https://www.big-yellow-j.top/posts/2025/08/29/QwenVLCode.html](https://www.big-yellow-j.top/posts/2025/08/29/QwenVLCode.html)
[^6]: [https://arxiv.org/abs/2502.13923](https://arxiv.org/abs/2502.13923)
[^7]: [QwenVL-3-Blog](https://qwen.ai/blog?id=99f0335c4ad9ff6153e517418d48535ab6d8afef&from=research.latest-advancements-list)
[^8]: [https://arxiv.org/pdf/2511.21631](https://arxiv.org/pdf/2511.21631)
[^9]: [https://arxiv.org/pdf/2406.04334](https://arxiv.org/pdf/2406.04334)