---
layout: mypost
title: Docunmen AI 中多视觉编码技术汇总
categories: paper
extMath: true
images: true
address: wuhan
show_footer_image: true
---

采用不同`Fushion Model`
![](https://s2.loli.net/2025/01/21/Oj7hwnSEdWD658B.png)
Brave [16] and Mousi [11] use sequence concatenation, LLaVA-HR [33] employs an MR-adaptor, MiniGemini [23] uses cross-attention, and Eagle [40] utilizes channel concatenation.

## 1、`LEO`

![](https://s2.loli.net/2025/01/21/KpUVtwQFYjd3DaM.png)

![](https://s2.loli.net/2025/01/21/Oj7hwnSEdWD658B.png)


## 2、`InternVL`

## 3、`BRAVE`

## 4、`EAGLE`

![](https://s2.loli.net/2025/02/19/Hh7iYPB1cZaVUyn.png)

## 5、`Mini-Gemini`

![](https://s2.loli.net/2025/02/19/Jcrq19W2kBUZpDa.png)

## 参考

1、LEO: Boosting Mixture of Vision Encoders for Multimodal Large Language Models
2、[InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks](https://arxiv.org/pdf/2312.14238)
3、[BRAVE : Broadening the visual encoding of vision-language models](https://arxiv.org/pdf/2404.07204)
4、[EAGLE: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders](https://arxiv.org/pdf/2408.15998)
5、[Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models](https://arxiv.org/pdf/2403.18814)