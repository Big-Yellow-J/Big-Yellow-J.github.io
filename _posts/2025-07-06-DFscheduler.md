---
layout: mypost
title: æ·±å…¥æµ…å‡ºäº†è§£ç”Ÿæˆæ¨¡å‹-7ï¼šè°ƒåº¦å™¨ï¼ˆschedulerï¼‰åŸç†
categories: ç”Ÿæˆæ¨¡å‹
extMath: true
images: true
address: é•¿æ²™ğŸŒ·
show_footer_image: true
tags:
- ç”Ÿæˆæ¨¡å‹
- diffusion model
- scheduler
show: true
special_tag: æ›´æ–°ä¸­
description: æœ¬æ–‡ä»‹ç»äº†SDEï¼ˆéšæœºå¾®åˆ†æ–¹ç¨‹ï¼‰ä¸ODEï¼ˆå¸¸å¾®åˆ†æ–¹ç¨‹ï¼‰åœ¨æ‰©æ•£æ¨¡å‹ä¸­çš„åº”ç”¨å·®å¼‚ï¼Œå› è°ƒåº¦å™¨ä¸åŒå…¶å®ç°æ–¹å¼æœ‰æ‰€åŒºåˆ«ï¼Œå¹¶é‡ç‚¹è§£æäº†DDPMä¸DDIMä¸¤ç§æ‰©æ•£æ¨¡å‹è°ƒåº¦å™¨ã€‚DDPMå°†åŠ å»å™ªè§†ä¸ºé©¬å°”ç§‘å¤«é“¾è¿‡ç¨‹ï¼Œéœ€å¤šæ­¥ï¼ˆé€šå¸¸1000æ­¥ï¼‰ç”Ÿæˆå›¾åƒå¯¼è‡´é€Ÿåº¦è¾ƒæ…¢ï¼›DDIMåˆ™é€šè¿‡â€œè·³æ­¥â€ä¼˜åŒ–ï¼Œæå‡ç”Ÿæˆæ•ˆç‡ã€‚æ–‡ä¸­è¿˜è¯¦ç»†è¯´æ˜äº†diffusersåº“ä¸­è°ƒåº¦å™¨çš„å¤„ç†æµç¨‹ï¼šåˆå§‹åŒ–å‚æ•°æ—¶ä¾æ®beta_scheduleç”Ÿæˆç›¸å…³å‚æ•°å¹¶è®¡ç®—ç´¯ä¹˜ç»“æœï¼ŒåŠ å™ªè¿‡ç¨‹é€šè¿‡å…¬å¼ç›´æ¥è®¡ç®—ï¼›ç”Ÿæˆè¿‡ç¨‹æ¶‰åŠmodel_outputï¼ˆé¢„æµ‹å™ªå£°ï¼‰ã€timestepï¼ˆæ—¶é—´æ­¥ï¼‰ã€sampleï¼ˆåˆå§‹å™ªå£°æ ·æœ¬ï¼‰ï¼ŒåŒ…å«epsilonï¼ˆé¢„æµ‹å™ªå£°ï¼‰ã€sampleï¼ˆç›´æ¥è¾“å‡ºï¼‰ã€v_predictionï¼ˆStable
  Diffusion 2.xå¸¸ç”¨ï¼‰ä¸‰ç§æ–¹å¼ã€‚å¯¹æ¯”DDPMä¸DDIMçš„å·®å¼‚ï¼šDDPMé€šè¿‡æ—¶é—´æ­¥ç›´æ¥è·å–ä¸Šä¸€æ­¥ï¼ŒDDIMéœ€è®¡ç®—â€œè·³æ­¥â€æ—¶é—´æ­¥ï¼Œä¸¤è€…åœ¨ç”Ÿæˆå…¬å¼ä¸Šä¹Ÿå­˜åœ¨ä¸åŒã€‚æ­¤å¤–ï¼Œè¿˜å¯¹æ¯”äº†DPMSolverã€UniPCMultistepSchedulerç­‰è°ƒåº¦å™¨çš„ç”Ÿæˆæ•ˆæœï¼ŒæŒ‡å‡ºåœ¨SDXLæ¨¡å‹ä¸‹20-30æ­¥ç”Ÿæˆä¸€å¼ å›¾åƒçº¦éœ€0.2sï¼ˆA100-80Gã€float16ï¼‰ï¼ŒåŒæ—¶æåŠLCMæ¨¡å‹çš„ç›¸å…³å¤„ç†è¦ç‚¹ã€‚
---

æ³¨æ„å¦‚ä¸‹å†…å®¹çš„æè¿°ï¼š1ã€SDEä»¥åŠODEå› ä¸ºä¸åŒçš„è°ƒåº¦å™¨å¯èƒ½å°±æ˜¯åŸºäºä¸åŒçš„æ–¹å¼å‡ºå‘çš„ï¼›2ã€å¯ä»¥äº†è§£ä¸€ä¸‹flow-matchingï¼›3ã€æ³¨æ„LCMæ¨¡å‹é‡Œé¢çš„å¤„ç†
> flow-matchingæ¨èæ–‡ç« 
> https://diffusionflow.github.io/

## SDEä»¥åŠODE
åœ¨æ­£å¼ä»‹ç»ä¹‹å‰ç®€çŸ­äº†è§£ä¸€äº›SDEï¼ˆéšæœºå¾®åˆ†æ–¹ç¨‹ï¼‰ä»¥åŠODEï¼ˆå¸¸å¾®åˆ†æ–¹ç¨‹ï¼‰ï¼Œå¯¹äº**ODEä¸€èˆ¬å®šä¹‰**å°±æ˜¯ï¼š$\frac{dx_t}{dt}=f(x_t,t)$ï¼Œå¯¹äº**SDEä¸€èˆ¬å®šä¹‰**å°±æ˜¯ï¼š$dx_t=f(x_t,t)dt+g(x_t,t)dW_t$ã€‚ä¸¤è€…ä¹‹é—´çš„å·®å¼‚å°±æ˜¯SDEä¼šæ¯”ODEå¤šä¸€ä¸ªéšæœºå™ªå£°é¡¹ç›®ï¼Œå› ä¸ºå¤šäº†è¿™ä¸ªå°±ä¼šå¯¼è‡´SDEçš„è½¨è¿¹ä¸åœ¨å”¯ä¸€æ¯æ¬¡çš„æ±‚è§£éƒ½æ˜¯ä¸åŒçš„ï¼Œé‚£ä¹ˆSDE/ODEå’Œæ‰©æ•£æ¨¡å‹ä¹‹é—´è”ç³»åœ¨å“ªï¼Ÿ

## DDPMã€DDIM
å¯¹äºDDPM[^2]ä»¥åŠDDIM[^1]åœ¨ä¹‹å‰çš„[åšå®¢](https://www.big-yellow-j.top/posts/2025/05/19/DiffusionModel.html)æœ‰è¿‡ç®€çŸ­ä»‹ç»è¿™é‡Œç›´æ¥å°†ä¸¤ä¸ªæ”¾åˆ°ä¸€èµ·è¿›è¡Œä»‹ç»ã€‚æ‰©æ•£æ¨¡å‹è¿‡ç¨‹ä¸ºï¼š

$$
X_T=\sqrt{\bar{\alpha_T}}x_0+ \sqrt{1- \bar{\alpha_T}}\epsilon
$$

é€šè¿‡å¯¹å›¾ç‰‡ï¼ˆ$x_0$ï¼‰ä¸æ–­æ·»åŠ é«˜æ–¯å™ªå£°æœ€åå¾—åˆ° $x_T$è€Œåé€šè¿‡åå‘å»å™ªåˆå¾—åˆ°æ–°çš„å›¾ç‰‡ã€‚ä¸è¿‡DDPMå’ŒDDIMä¹‹é—´å­˜åœ¨ä¸€ä¸ªå¾ˆæ˜æ˜¾çš„å·®å¼‚å°±æ˜¯ï¼šDDPMå°†åŠ ï¼ˆå»ï¼‰å™ªè§†ä½œä¸€ä¸ªé©¬å°”ç§‘å¤«é“¾è¿‡ç¨‹ï¼ˆç®€å•ç†è§£ä¸ºæ¯ä¸€æ­¥ $t$éƒ½è¦ä¾é ä¸Šä¸€æ­¥ $t-1$ï¼‰ï¼Œä½†æ˜¯åœ¨DDIMè¿‡ç¨‹ä¸­å°±ä¼šä½¿ç”¨â€œè·³æ­¥â€æ¥è¿›è¡Œ
![](https://s2.loli.net/2025/06/21/pwIndituAKX4kjh.webp)

**DDPMç”Ÿæˆè¿‡ç¨‹**ï¼š

$$
x_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1- \alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t,t)\right)+\sigma_tz,\quad z\sim\mathcal{N}(0,I)
$$

ä½†æ˜¯å¯¹äºDDPMå­˜åœ¨ä¸€ä¸ªæœ€å¤§çš„é—®é¢˜å°±æ˜¯éœ€è¦å¤šæ­¥ï¼ˆä¸€èˆ¬é€‰æ‹©T=1000ï¼‰æ¥ç”Ÿæˆå›¾åƒï¼Œè¿™æ ·ä¸€æ¥å°±ä¼šå¯¼è‡´ç”Ÿæˆçš„é€Ÿåº¦å¾ˆæ…¢ï¼Œå› æ­¤åç»­å°±æå‡ºäº†DDIMå…¶ä¸­**DDIMç”Ÿæˆè¿‡ç¨‹**ä¸ºï¼š

$$
x_{t-1}=\sqrt{\alpha_{t-1}}\left(\frac{x_t-\sqrt{1-\alpha_t}\epsilon_\theta(x_t,t)}{\sqrt{\alpha_t}}\right)+\sqrt{1-\alpha_{t-1}-\sigma_t^2}\epsilon_\theta(x_t,t)+\sigma_tz
$$

é‡ç‚¹äº†è§£ä¸€ä¸‹åœ¨diffusersåº“ä¸­å¦‚ä½•å¤„ç†è¿™ä¸¤ä¸ªè°ƒåº¦å™¨çš„ï¼Œä»¥DDPMï¼ˆ[æºä»£ç ](https://github.com/huggingface/diffusers/blob/d7dd924ece56cddf261cd8b9dd901cbfa594c62c/src/diffusers/schedulers/scheduling_ddpm.py#L129)ï¼‰ä¸ºä¾‹ï¼Œä¸€èˆ¬æ¥è¯´ä½¿ç”¨è°ƒåº¦å™¨æ— ç–‘å°±æ˜¯ä¸‹é¢å‡ ä¸ªæ­¥éª¤ï¼š
```python
from diffusers import DDPMScheduler
# ç›´æ¥ä½¿ç”¨åˆå§‹åŒ–çš„ è°ƒåº¦å™¨
noise_scheduler = DDPMScheduler(num_train_timesteps= config.num_train_timesteps,
                            beta_start= config.beta_start,
                            beta_end= config.beta_end,
                            beta_schedule= 'scaled_linear')
# æˆ–åˆ™ç›´æ¥åŠ è½½å…¶ä»–çš„æ¨¡å‹çš„è°ƒåº¦å™¨
noise_scheduler = DDPMScheduler.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", cache_dir= config.cache_dir, subfolder="scheduler")
'''
ä¸è¿‡å€¼å¾—æ³¨æ„çš„æ˜¯åœ¨DDIMä¸­ä¼šï¼šnoise_scheduler.set_timesteps(inference_steps) æ¥å‘Šè¯‰ç”¨å¤šå°‘æ­¥è¿›è¡Œæ¨ç†ï¼ˆï¼‰
'''
# å°†å™ªå£°æ·»åŠ åˆ°å›¾ç‰‡ä¸Š
noise = torch.randn(image.shape, device= accelerator.device)
noise_image = noise_scheduler.add_noise(image, noise, timesteps)
...
# å°†å™ªå£°è¿›è¡Œå‰”é™¤
noise = noise_scheduler.step(predicted_noise, t, noise).prev_sample
```

ç®€çŸ­äº†è§£ä¸€ä¸‹åœ¨`DDPMScheduler`ä¸­è®¾è®¡æ¡†æ¶æ˜¯å¦‚ä½•çš„ï¼š

```python
class DDPMScheduler(SchedulerMixin, ConfigMixin):
    @register_to_config
    def __init__(
        self, 
        num_train_timesteps: int = 1000, # åŠ å™ªçš„æ­¥æ•°
        beta_start: float = 0.0001,      # \beta èµ·å§‹æ•°å€¼
        beta_end: float = 0.02,          # \beta æœ€åæ•°å€¼
        beta_schedule: str = "linear",   # çº¿æ€§åŠ å™ªæ–¹å¼
        ...)
        ...
        if ...:
            ...
        elif beta_schedule == "linear":
            self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps, dtype=torch.float32)
        # 1ã€åˆå§‹åŒ–å‚æ•°
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        ...
        self.timesteps = torch.from_numpy(np.arange(0, num_train_timesteps)[::-1].copy())
    def add_noise(
        self,
        original_samples: torch.Tensor,
        noise: torch.Tensor,
        timesteps: torch.IntTensor,)
        # 2ã€åŠ å™ªè¿‡ç¨‹
        self.alphas_cumprod = self.alphas_cumprod.to(device=original_samples.device)
        alphas_cumprod = self.alphas_cumprod.to(dtype=original_samples.dtype)
        timesteps = timesteps.to(original_samples.device)

        sqrt_alpha_prod = alphas_cumprod[timesteps] ** 0.5
        sqrt_alpha_prod = sqrt_alpha_prod.flatten()
        while len(sqrt_alpha_prod.shape) < len(original_samples.shape):
            sqrt_alpha_prod = sqrt_alpha_prod.unsqueeze(-1)

        sqrt_one_minus_alpha_prod = (1 - alphas_cumprod[timesteps]) ** 0.5
        sqrt_one_minus_alpha_prod = sqrt_one_minus_alpha_prod.flatten()
        while len(sqrt_one_minus_alpha_prod.shape) < len(original_samples.shape):
            sqrt_one_minus_alpha_prod = sqrt_one_minus_alpha_prod.unsqueeze(-1)

        noisy_samples = sqrt_alpha_prod * original_samples + sqrt_one_minus_alpha_prod * noise
        return noisy_samples

    def step(
        self,
        model_output: torch.Tensor,
        timestep: int,
        sample: torch.Tensor,
        generator=None,
        return_dict: bool = True,):
        # 3ã€ç”Ÿæˆè¿‡ç¨‹
        t = timestep
        prev_t = self.previous_timestep(t)
        # é¦–å…ˆè®¡ç®— alphaç­‰å‚æ•°
        alpha_prod_t = self.alphas_cumprod[t]
        alpha_prod_t_prev = self.alphas_cumprod[prev_t] if prev_t >= 0 else self.one
        beta_prod_t = 1 - alpha_prod_t
        beta_prod_t_prev = 1 - alpha_prod_t_prev
        current_alpha_t = alpha_prod_t / alpha_prod_t_prev
        current_beta_t = 1 - current_alpha_t
        # è€Œåè®¡ç®— é¢„æµ‹ç»“æœ DDPMæœ‰3ç§è®¡ç®—è¿‡ç¨‹ epsilon sample v_prediction
        if self.config.prediction_type == "epsilon":
            pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)
        ...
        # è£å‰ªé¢„æµ‹å€¼
        ...
        elif self.config.clip_sample:
            pred_original_sample = pred_original_sample.clamp(
                    -self.config.clip_sample_range, self.config.clip_sample_range
                )
        # important
```
1ã€åˆå§‹åŒ–å‚æ•°ï¼ˆ**DDPMå’ŒDDIMä¸­æ²¡ä»€ä¹ˆå·®å¼‚**ï¼‰ã€‚é¦–å…ˆæ˜¯æ ¹æ® `beta_schedule`æ¥ç”Ÿæˆåœ¨ `num_train_timesteps`ä¸‹å‚æ•° $\beta$çš„å€¼ï¼ˆæ¯”å¦‚è¯´ `linear`é‚£ä¹ˆåœ¨1000æ­¥ä¸‹å°±ä¼šç”Ÿæˆï¼ˆç›´æ¥é€šè¿‡`torch.linspace`ï¼‰ä» `(1-beta_start)-(1-beta_end)` çš„1000ä¸ªæ•°å­—ï¼‰è€Œåå°±æ˜¯å®šä¹‰å¥½åŠ å™ªæ¯”è¾ƒé‡è¦çš„å‡ ä¸ªå‚æ•°ï¼š$\alpha$ ä»¥åŠè¿­ä»£æ¬¡æ•° $t$ï¼Œå¯¹äº`self.alphas_cumprod`åˆ™æ˜¯ç›´æ¥è®¡ç®—**ç´¯ä¹˜å¾—åˆ°çš„ç»“æœ**ã€‚ä¸Šé¢è¿‡ç¨‹å¯¹åº”ï¼š
![](https://s2.loli.net/2025/07/22/aVTbcnwKBNj4plg.webp)
2ã€åŠ å™ªè¿‡ç¨‹ï¼ˆ**DDPMå’ŒDDIMä¸­æ²¡ä»€ä¹ˆå·®å¼‚**ï¼‰ã€‚è¿™ä¸ªæ•´ä¸ªè¿‡ç¨‹ä¹Ÿæ¯”è¾ƒç®€å•å°±æ˜¯ç›´æ¥é€šè¿‡è®¡ç®—ï¼š$X_T=\sqrt{\bar{\alpha_T}}x_0+ \sqrt{1- \bar{\alpha_T}}\epsilon$
3ã€ç”Ÿæˆè¿‡ç¨‹ã€‚è¾“å…¥ä¸‰ä¸ªå‚æ•°åˆ†åˆ«è¡¨ç¤ºï¼š**1ã€model_output**ï¼šæ¨¡å‹é¢„æµ‹å¾—åˆ°çš„å™ªå£°æ•°å€¼ï¼›**2ã€timestep**ï¼šæ—¶é—´æ­¥ï¼›**3ã€sample**ï¼šå°±æ˜¯æˆ‘ä»¬åŠ è½½åçš„$x_t$ï¼ˆæœ€å¼€å§‹å°±æ˜¯ä¸€ä¸ªçº¯å™ªå£°éšç€è¿­ä»£é€æ¸â€œæ¸…æ™°â€ï¼‰ã€‚ç”Ÿæˆå›¾åƒè¿‡ç¨‹ä¸­æ— ç–‘å°±æ˜¯ç›´æ¥é€šè¿‡$t$å»æ¨å¯¼ $t-1$çš„å›¾åƒç»“æœï¼Œå› æ­¤**åœ¨DDPMç”Ÿæˆè¿‡ç¨‹ä¸­** é¦–å…ˆæ˜¯åˆ†åˆ«è®¡ç®— $\alpha_{t}$ä»¥åŠ $\alpha_{t-1}$ï¼Œä¸è¿‡ç”Ÿæˆè¿‡ç¨‹æœ‰ä¸‰ç§ã€‚
* `epsilon`ï¼šé¢„æµ‹å™ªå£° $\epsilon$ï¼ˆå°†ä¸Šé¢åŠ å™ªå…¬å¸é€†æ¨å¾—åˆ°$x_0$ï¼‰
* `sample`ï¼šç›´æ¥ç”¨ $x_0$å°±æ˜¯æ¨¡å‹çš„è¾“å‡º
* `v_prediction`ï¼šé¢„æµ‹$v$ï¼ˆStable Diffusion 2.xä¸€èˆ¬å°±æ˜¯è¿™ä¸ªï¼‰

æœ€é‡è¦çš„æ˜¯åé¢çš„ `important`éƒ¨åˆ†ä»£ç ï¼Œåœ¨DDPMä¸­éœ€è¦è®¡ç®—ï¼š

$$
x_{t-1}=\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{1-\bar{\alpha}_{t}}\mathbf{x}_{0}+\frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_{t}}\mathbf{x}_{t}
$$

ä»£ç ä¸­å¯¹åº”ï¼š
```python
pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * current_beta_t) / beta_prod_t
current_sample_coeff = current_alpha_t ** (0.5) *beta_prod_t_prev / beta_prod_t
pred_prev_sample = pred_original_sample_coeff *pred_original_sample + current_sample_coeff * sample
```
æœ€ååœ¨æ¨¡å‹é‡Œé¢ä¼šè¿”å›ä¸¤éƒ¨åˆ†å†…å®¹ï¼š1ã€pred_prev_sampleï¼›2ã€pred_original_sampleã€‚å¯¹äºè¿™ä¸¤ä¸ªå€¼åˆ†åˆ«è¡¨ç¤ºçš„æ˜¯ï¼šæ¨¡å‹è®¤ä¸ºæœ€ç»ˆçš„å¹²å‡€å›¾åƒï¼ˆå®Œå…¨æ— å™ªå£°ï¼‰ï¼ˆpred_original_sampleï¼‰ã€‚é‡‡æ ·ä¸€æ­¥åï¼Œé¢„è®¡åœ¨ç¬¬ 499 æ­¥åº”è¯¥é•¿çš„æ ·å­ï¼ˆpred_prev_sampleï¼‰ã€‚**å¯¹æ¯”åœ¨DDIMä¸­çš„å·®å¼‚**ï¼Œç¬¬ä¸€ä¸ªå°±æ˜¯**æ—¶é—´æ­¥å¤„ç†å·®å¼‚**ï¼Œåœ¨DDPMä¸­ç›´æ¥ç”¨$t-1$æ¥è·å–ä¸Šä¸€æ­¥å°±è¡Œï¼Œä½†æ˜¯åœ¨DDIMä¸­éœ€è¦è®¡ç®—`timestep - self.config.num_train_timesteps // self.num_inference_steps`è¿™æ˜¯å› ä¸ºDDIMä¼šä½¿ç”¨â€œè·³æ­¥â€ï¼›2ã€åœ¨è®¡ç®— $x_0$ä¸Šä¸¤è€…ä¹‹é—´ä¸å­˜å·®å¼‚ï¼Œåªæ˜¯è®¡ç®—ä¸Šä¸€æ­¥åœ¨å…¬å¼ä¸Šå­˜åœ¨å·®å¼‚ï¼ˆDDIMè®¡ç®—å…¬å¼ï¼‰ï¼š
![image.png](https://s2.loli.net/2025/08/06/7VyP3ENhK5rWscO.webp)

```python
variance = self._get_variance(timestep, prev_timestep)
std_dev_t = eta * variance ** (0.5)
if use_clipped_model_output:
    pred_epsilon = (sample - alpha_prod_t ** (0.5) * pred_original_sample) / beta_prod_t ** (0.5)
pred_sample_direction = (1 - alpha_prod_t_prev - std_dev_t**2) ** (0.5) * pred_epsilon
prev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction
```

## Flow Matching

## ä¸åŒè°ƒåº¦å™¨ç”Ÿæˆå¯¹æ¯”
> åªæ˜¯ç®€å•å¯¹æ¯”ä¸åŒè°ƒåº¦å™¨åœ¨ç”Ÿæˆæ•ˆæœä¸Šçš„é€Ÿåº¦å·®å¼‚ï¼ˆSDXLæ¨¡å‹ï¼‰

[ä¸åŒè°ƒåº¦å™¨ç”Ÿæˆå¯¹æ¯”](https://1drv.ms/f/c/667854cf645e8766/ElCNxPu93Q5Cp1Tqq8YbVUsBV-pVyGG6HG3FJ2AXAxDYDg?e=0H9btC)ï¼Œä»ä¸Šé¢ç®€å•æ¯”è¾ƒå‘ç°ä¸€èˆ¬æ¥è¯´éœ€è¦20-30æ­¥ï¼ˆå»ºç«‹åœ¨ä¸é€‚ç”¨LCMæ¨¡å‹åŸºç¡€ä¸Šï¼‰æ‰èƒ½ç”Ÿæˆä¸€ä¸ªæ•ˆæœè¾ƒå¥½çš„å›¾åƒï¼Œä»æµ‹è¯•è¿‡ç¨‹å‘ç°åŸºæœ¬ï¼ˆ20-30æ­¥ï¼‰ä¸€å¼ å›¾ç‰‡æ¶ˆè€—æ—¶é—´ä¸º0.2så·¦å³ï¼ˆA100-80Gä»¥åŠä½¿ç”¨`float16`ï¼‰ã€‚ä»ä¸Šé¢çš„æµ‹è¯•ç»“æœä¸Šæ¥çœ‹`UniPCMultistepScheduler`å’Œ `DPMSolverMultistepScheduler`æµ‹è¯•çš„æ•ˆæœæœ€å¥½ï¼ˆä»…ä»…åªä»è¿­ä»£æ­¥æ•°ä¸Šåˆ†æï¼‰ï¼Œå€Ÿç”¨ChatGPTå¯¹ä¸åŒç”Ÿæˆå™¨çš„åˆ†æå¦‚ä¸‹ï¼š
![image.png](https://s2.loli.net/2025/07/22/LbkEu5hO7y8PURj.webp)

ä¸è¿‡å¦‚æœå»ä»”ç»†çœ‹ç”Ÿæˆå›¾åƒçš„ç»†èŠ‚å†…å®¹çš„è¯ï¼ˆå•ç‹¬å¯¹æ¯”äº†Unipã€DPMã€DDIMä»10-50æ­¥ä½¿ç”¨çš„æ¨¡å‹æ˜¯SDXLå¹¶ä¸”ä½¿ç”¨`float16`ï¼‰å¾—åˆ°æµ‹è¯•[ç»“æœ](https://1drv.ms/f/c/667854cf645e8766/ElCNxPu93Q5Cp1Tqq8YbVUsBV-pVyGG6HG3FJ2AXAxDYDg?e=0H9btC)
> æ­¤è¿‡ç¨‹ä½¿ç”¨çš„promptï¼ˆç›´æ¥GPTç”Ÿæˆï¼‰ï¼š
```python
validation_prompt = [
    # 1. åŠ¨æ€å¤šä¸»ä½“ + å¤æ‚å…‰å½±
    "A fierce dog fighting a cat inside a Victorian living room, ultra realistic fur, dynamic cinematic lighting, motion blur, 8k hyper detail, dramatic shadows, volumetric fog",
    # 2. ç§‘å¹»åœºæ™¯ + å…‰å½±/åå°„
    "A futuristic cyberpunk city skyline at sunset with flying cars, glowing neon signs, reflective glass skyscrapers, cinematic wide-angle shot, ultra realistic 8k textures, complex lighting, atmospheric haze",
    # 3. å†™å®äººåƒ + æè´¨å¯¹æ¯”
    "A close-up portrait of an elderly woman with deep wrinkles, realistic skin texture, soft diffused lighting, cinematic depth of field, ultra detailed eyes, 8k hyper realism",
    # 4. è‡ªç„¶é£æ™¯ + å¾®è·ç»†èŠ‚
    "A crystal-clear mountain lake surrounded by pine trees, sunlight filtering through mist, hyper realistic reflections on water, ultra detailed rocks and moss, 8k cinematic composition",
    # 5. å¥‡å¹»åœºæ™¯ + å¤æ‚æè´¨
    "A medieval knight in silver armor standing in a glowing enchanted forest, bioluminescent plants, soft god rays, ultra detailed metallic reflections, cinematic epic fantasy lighting, 8k resolution",
    # 6. å®¤å†…ç‰©å“ + ç²¾ç»†çº¹ç†
    "A rustic wooden table with a vintage pocket watch, spilled coffee, handwritten letters, soft morning sunlight, ultra detailed textures, shallow depth of field, 8k macro photography style"
]
negative_prompt = "blurry, low quality, distorted, extra limbs, deformed, low contrast, unrealistic lighting, bad anatomy, oversaturated"
```

## å‚è€ƒ
[^1]:https://arxiv.org/abs/2010.02502
[^2]:https://arxiv.org/abs/2006.11239