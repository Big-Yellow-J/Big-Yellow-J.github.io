---
layout: mypost
title: 强化学习框架：OpenRLHF源码解读，模型训练
categories: OpenRLHF框架解读
address: changsha
extMath: true
show_footer_image: true
description: 强化学习框架：OpenRLHF源码解读，模型训练模块解读
---

前文已经介绍了：
* [**强化学习框架：OpenRLHF源码解读，模型处理模块解读**](https://www.big-yellow-j.top/posts/2025/04/22/OpenRLHF-1.html)

本文主要介绍 **强化学习框架：OpenRLHF源码解读，模型**。因为RL由DPO、GRPO、PPO等几种类别，因此本文住哟介绍PPO范式训练。在OpenRLHF训练框架中，主要还会应用到DeepSpeed以及vLLM，因此在介绍PPO训练之前需要回顾一下：1、DeepSpeed的配置；2、vLLM配置。
> 在之前Blog已经对DeepSpeed以及vLLM原理进行了解释，因此只需要介绍在OpenRLHF如何去对这两部分进行配置

参数参考脚本：https://github.com/OpenRLHF/OpenRLHF/blob/main/examples/scripts/train_ppo_llama_ray.sh 中的设置
* 1、vLLM配置

> From:https://github.com/OpenRLHF/OpenRLHF/blob/main/openrlhf/trainer/ray/vllm_engine.py

```python
def create_vllm_engines(
    num_engines: int, # 推理引擎数量
    tensor_parallel_size: int, # 张量并行大小
    pretrain: str,
    seed: int,
    full_determinism: bool,
    enable_prefix_caching: bool,
    enforce_eager: bool,
    max_model_len: int,
    num_total_actors: int,
    shared_pg=None,
    gpu_memory_utilization=None,
    vllm_enable_sleep=False,):
    ...
    # 1、资源调度配置。配置参数设置为：num_engines= tensor_parallel_size= 2
    use_hybrid_engine = shared_pg is not None
    num_gpus = int(tensor_parallel_size == 1)
    if use_hybrid_engine and tensor_parallel_size == 1:
        num_gpus = 0.2

    if not use_hybrid_engine:
        bundles = [{"GPU": 1, "CPU": 1} for _ in range(num_engines * tensor_parallel_size)]
        shared_pg = placement_group(bundles, strategy="PACK")
        ray.get(shared_pg.ready())
    ...
    # 2、构建每一个vLLM（=2）
    for i in range(num_engins):
        ...
        scheduling_strategy = PlacementGroupSchedulingStrategy(...) # 调度策略
        ...
        vllm_engines.append(
            LLMRayActor.options(
            num_cpus=num_gpus,
            num_gpus=num_gpus,
            scheduling_strategy=scheduling_strategy,
        ).remote(...)
        )
```

1、**资源调度配置**：第一种Hybrid模式（多个引擎共同占用GPU）；第二种标准模式（每个引擎都单独占用一个GPU和CPU）；
2、**构建vLLM**：

## 1、vLLM配置


## PPO训练范式

### train.sh

模型训练脚本：[🔗](https://github.com/OpenRLHF/OpenRLHF/blob/main/examples/scripts/train_ppo_llama_ray.sh) 脚本中主要涉及到参数：1、模型脚本：`openrlhf.cli.train_ppo_ray`；2、

### `train_ppo_ray.py`
> From: https://github.com/OpenRLHF/OpenRLHF/blob/main/openrlhf/cli/train_ppo_ray.py

因为要实现分布式训练

## 代码测试


## 总结
