---
layout: mypost
title: 深入浅出了解生成模型-2：VAE模型原理以及代码实战
categories: 生成模型
extMath: true
images: true
address: changsha
show_footer_image: true
tags: [生成模型, VAE]
description: 日常使用比较多的生成模型比如GPT/Qwen等这些大多都是“文生文”模型（当然GPT有自己的大一统模型可以“文生图”）但是网上流行很多AI生成图像，而这些生成图像模型大多都离不开下面三种模型：1、GAN；2、VAE；3、Diffusion Model。因此本文通过介绍这三个模型作为生成模型的入门。本文主要介绍GAN模型
---

前文已经介绍了GAN的基本原理以及代码操作，本文主要介绍VAE其基本原理以及代码实战

## VAE or AE
介绍VAE之前了解两个概念：AE（AutoEncoder，自编码器）和VAE（Variational Autoencoder，变自编码器）。**AE**：自编码器是一种无监督学习神经网络，旨在通过将输入数据压缩到一个低维表示（编码），然后从该表示重建输入数据（解码），来学习数据的特征表示。**VAE**：变分自编码器是自编码器的扩展，结合了概率模型和深度学习，通过引入变分推理使潜在空间具有概率分布特性，适合生成任务。
**AE**的数学描述对于输入 $x$通过编码器将输入映射到 **低纬空间** $z=f(x)$而后通过解码器得到输出：$\hat{x}=g(x)$
**VAE**的数学描述对于输入 $x$通过编码器将输入映射成 **概率分布** $q(z|x)$，假设为高斯分布，输出 𝜇和 𝜎，从 $q(z|x)$采样 $z$而后通过 $z=\mu+ \sigma+ \epsilon$ 其中 $\epsilon \in N(0,1)$，而后通过采样得到的$z$重新构建输入，生成$p(x|z)$
前者不适合对于图片进行生成而后者则是更加适合图像生成，这是因为AE将输入映射到一个低纬空间z这个低纬空间并没有明确的结构，进而就可能不适合去生成新的数据，而VAE之所以可以用于生成新的数据是，比如说对于图像数据（比如说：猫）如果知道其分布特征，就可以直接通过分布特征去构建一个新的图像

![](https://s2.loli.net/2025/05/13/Ji5sAMmGehLjdf9.png)

## VAE（Variational Autoencoder）
上面简单介绍了VAE数学描述这里重新再描述一下其数学描述（涉及到比较多贝叶斯统计相关内容）：
### 1.基本框架
VAE 是一种生成模型，**目标是学习数据的概率分布 p(x)，让模型能生成类似真实数据的新样本**，想象我们要制作各种蛋糕（数据 $x$），但不知道蛋糕的“秘方”（潜在变量 $z$）。假设所有蛋糕组成数据集 $X = {x_1, \dots, x_n}$，每种蛋糕（如巧克力蛋糕或水果蛋糕）背后有独特的秘方。VAE 通过学习秘方的分布和生成过程，制造出逼真的蛋糕。
**秘方**：VAE 假设秘方 $z$ 服从标准正态分布，即先验分布 $p(z) = \mathcal{N}(0, I)$。这意味着大多数秘方是“普通”的，围绕平均值分布。
**生成蛋糕（解码器）**：给定秘方 $z$，VAE 使用一个“蛋糕机”（解码器，参数 $\theta$）生成蛋糕 $x$。解码器建模条件分布 $p_\theta(x|z) = \mathcal{N}(x; \mu_\theta(z), \sigma_\theta^2(z))$，表示从 $z$ 生成 $x$ 的概率。
**猜测秘方（编码器）**：直接从蛋糕 $x$ 反推秘方（后验分布 $p_\theta(z|x)=\frac{p_\theta(x,z)}{p_\theta(x)}=\frac{p_\theta(x|z)p(z)}{p_\theta(x)}$）很困难（因为我的变量是一个高维的，换句说法就是我的蛋糕他有千奇百怪种组合）。既然如此就只需要将制造蛋糕的组合分解，分解成低维的变量 $z$（也就是上面提到的 **秘方**）然后我去计算下面一个联合分布：

$$
p_\theta(x) =\int p_\theta(x|z)p(z)dz
$$

不过就算上面积分会存在困难即使你将蛋糕分解成不同的 *潜在变量* 但是这些潜在变量种类也是很多的（蛋糕奶油、加不加巧克力等等）那么上面的联合分布就会变成：

$$
\int p_\theta(x|z)p(z)dz = \int_{z_1} ... \int_{z_d}p_\theta(x|z)p(z)d_{z_1}...d_{z_d}
$$

这种高维积分没有解析解，数值积分计算复杂度随维度指数增长，因此在VAE 引入一个“猜测机”（编码器，也就是一个神经网络，参数 $\phi$），用变分分布：

$$
q_\phi(z|x) = \mathcal{N}(z; \mu_\phi(x), \text{diag}(\sigma_\phi^2(x)))
$$ 

近似后验分布，估计可能的秘方也就是去估算我们的 $p_\theta(z|x)$
大致总结一下就是：VAE的主要的任务就是，最开始的数据集里面，我希望通过对这个数据记得潜在分布进行学习，如果我模型学会了各类数据的分布，那么就可以通过这些分布去进一步生成新的数据。

### 2.模型参数求解
了解模型基本框架之后就需要对整个模型的参数进行求解

## 3.代码操作
所有的代码：1、[VAE](./code/../../code/VAE.py.txt)；2、[PixelCNN](../code/PixcelCNN.py.txt)

### 实际生成效果
> VAE测试的主要是生成效果（MNIST数据集），而VA-VAE则是测试重构效果

**VAE**在MNIST数据集上表现

| 固定输入 | 重构图像 | 随机生成 |
|:--------:|:---------:|:--------:|
| ![](https://s2.loli.net/2025/05/14/ABJDCTjW46Odx3g.gif) | ![](https://s2.loli.net/2025/05/14/fQmMFOXRNovIubA.gif) | ![](https://s2.loli.net/2025/05/14/28Tln5qcap6HvPf.gif) |

不过值得注意的是 MNIST数据集很简单所以VAE可以很容易就生成需要的图片
**VQ-VAE**在CIFAR10数据集上重构图像的表现（**生成图像只是测试代码运行效果**，CIFAR10数据集自身也比较复杂！，在CIFAR10上都没能生成较好的图片）

| 重构图像 | PixelCNN生成图像 | PixelCNNPlusPlus 生成图像 | GatedPixelCNN 生成图像 |
|:------:|:----------------:|:-----------------------:|:--------------------:|
|![](https://s2.loli.net/2025/05/14/38zIQHaL9Vukret.gif)| ![](https://s2.loli.net/2025/05/15/DHvAXfZIRimwOen.gif) | ![](https://s2.loli.net/2025/05/15/mQqgLNF83uzoZiJ.gif) | ![](https://s2.loli.net/2025/05/15/gDcBlhsyS1or8Iu.gif)|

## 总结

## 参考
1、https://github.com/hkproj/vae-from-scratch-notes/blob/main/VAE.pdf
2、https://mbernste.github.io/posts/vae/
3、https://arxiv.org/pdf/1906.02691
