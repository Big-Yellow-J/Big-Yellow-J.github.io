---
layout: mypost
title: æ·±å…¥æµ…å‡ºäº†è§£ç”Ÿæˆæ¨¡å‹-6ï¼šå¸¸ç”¨åŸºç¡€æ¨¡å‹ä¸ Adaptersç­‰è§£æ
categories: ç”Ÿæˆæ¨¡å‹
extMath: true
images: true
address: é•¿æ²™ğŸŒ·
show_footer_image: true
tags:
- ç”Ÿæˆæ¨¡å‹
- diffusion model
- ControlNet
- T2I-Adapter
- SD
- SDVL
show: true
special_tag: æ›´æ–°ä¸­
description: æœ¬æ–‡ä»‹ç»åŸºåº§æ‰©æ•£æ¨¡å‹ï¼Œæ¶µç›–åŸºäºUnetçš„SD1.5ã€SDXLï¼ˆCLIPç¼–ç å™¨å·®å¼‚ã€1024x1024è¾“å‡ºï¼‰åŠDiTæ¡†æ¶çš„Hunyuan-DiTç­‰ï¼Œå¯¹æ¯”æ¨¡å‹ç»“æ„ä¸æŠ€æœ¯ç»†èŠ‚ï¼Œè¿˜åŒ…æ‹¬Imagenå¤šé˜¶æ®µç”ŸæˆåŠControlNetã€DreamBoothç­‰é€‚é…å™¨æŠ€æœ¯ï¼ŒåŠ©åŠ›å›¾åƒç”Ÿæˆä¸é£æ ¼æ§åˆ¶ã€‚
---

## åŸºåº§æ‰©æ•£æ¨¡å‹
ä¸»è¦ä»‹ç»åŸºäºUnetä»¥åŠåŸºäºDitæ¡†æ¶çš„åŸºåº§æ‰©æ•£æ¨¡å‹ï¼Œå…¶ä¸­SDè¿­ä»£ç‰ˆæœ¬æŒºå¤šçš„ï¼ˆä»1.2åˆ°3.5ï¼‰å› æ­¤æœ¬æ–‡ä¸»è¦é‡ç‚¹ä»‹ç»SD 1.5ä»¥åŠSDXLä¸¤ä¸ªåŸºåº§æ¨¡å‹ï¼Œä»¥åŠä¸¤è€…ä¹‹é—´çš„å¯¹æ¯”å·®å¼‚ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜æœ‰è®¸å¤šé—­æºçš„æ‰©æ•£æ¨¡å‹æ¯”å¦‚è¯´Imagenã€DALEç­‰ã€‚å¯¹äºDitåŸºåº§æ¨¡å‹ä¸»è¦ä»‹ç»ï¼šHunyuan-DiTã€FLUX.1ç­‰ã€‚å¯¹äºå„ç±»æ¨¡å‹è¯„åˆ†ç½‘ç«™ï¼ˆæ¨¡å‹è¯„åˆ†ä»è€…è§ä»æ™ºè€…è§æ™ºï¼Œç‰¹åˆ«æ˜¯æ­¤ç±»ç”Ÿæˆæ¨¡å‹è§†è§‰å›¾åƒç”Ÿæˆæ˜¯ä¸€ä¸ªå¾ˆä¸»è§‚çš„è¿‡ç¨‹ï¼ŒåŒä¸€å¼ å›¾ç‰‡ä¸åŒäººè§†è§‰æ„Ÿå®˜éƒ½æ˜¯ä¸åŒçš„ï¼‰ï¼š[https://lmarena.ai/leaderboard](https://lmarena.ai/leaderboard)

### SDv1.5 vs SDXL[^1]
> **SDv1.5**: https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5
> **SDXL**:https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0

ä¸¤è€…æ¨¡å‹è¯¦ç»†çš„æ¨¡å‹ç»“æ„ï¼š[SDv1.5--SDXLæ¨¡å‹ç»“æ„å›¾](https://1drv.ms/u/c/667854cf645e8766/ESgZEHNEn3RJsKY0t1KQAgABYKHDhQtutJztw6OhEt9DPg?e=5SqEro)ï¼Œå…¶ä¸­å…·ä½“æ¨¡å‹å‚æ•°çš„å¯¹æ¯”å¦‚ä¸‹ï¼š
**1ã€CLIPç¼–ç å™¨åŒºåˆ«**ï¼š
åœ¨SD1.5ä¸­é€‰æ‹©çš„æ˜¯**CLIP-ViT/L**ï¼ˆå¾—åˆ°çš„ç»´åº¦ä¸ºï¼š768ï¼‰è€Œåœ¨SDXLä¸­é€‰æ‹©çš„æ˜¯ä¸¤ä¸ªCLIPæ–‡æœ¬ç¼–ç å™¨ï¼š**OpenCLIP-ViT/G**ï¼ˆå¾—åˆ°çš„ç»´åº¦ä¸ºï¼š1280ï¼‰ä»¥åŠ**CLIP-ViT/L**ï¼ˆå¾—åˆ°ç»´åº¦ä¸ºï¼š768ï¼‰åœ¨ä»£ç ä¸­å¯¹äºä¸¤ä¸ªæ–‡æœ¬é€šè¿‡ç¼–ç å™¨å¤„ç†ä¹‹åSDXLç›´æ¥é€šè¿‡catæ–¹å¼æ‹¼æ¥ï¼š`prompt_embeds = torch.concat(prompt_embeds_list, dim=-1)` ä¹Ÿå°±æ˜¯è¯´æœ€åå¾—åˆ°çš„ç»´åº¦ä¸ºï¼š[..,..,1280+768]ã€‚æœ€åæ•ˆæœå¾ˆæ˜æ˜¾ï¼š**SDXLå¯¹äºæ–‡æœ¬çš„ç†è§£èƒ½åŠ›å¤§äºSD1.5**
**2ã€å›¾åƒè¾“å‡ºç»´åº¦åŒºåˆ«**ï¼š
å†SD1.5ä¸­çš„é»˜è®¤è¾“å‡ºæ˜¯ï¼š512x512è€Œå†SDXLä¸­çš„é»˜è®¤è¾“å‡ºæ˜¯ï¼š1024x1024ï¼Œå¦‚æœå¸Œæœ›å°†SD1.5ç”Ÿæˆçš„å›¾åƒå¤„ç†ä¸º1024x1024å¯ä»¥ç›´æ¥é€šè¿‡è¶…åˆ†ç®—æ³•æ¥è¿›è¡Œå¤„ç†ï¼Œé™¤æ­¤ä¹‹å¤–åœ¨SDXLä¸­è¿˜ä¼šä½¿ç”¨ä¸€ä¸ªrefineræ¨¡å‹ï¼ˆå’ŒUnetçš„ç»“æ„ç›¸ä¼¼ï¼‰æ¥å¼ºåŒ–baseæ¨¡å‹ï¼ˆUnetï¼‰ç”Ÿæˆçš„æ•ˆæœã€‚
**3ã€SDXLè®ºæ–‡ä¸­çš„æŠ€æœ¯ç»†èŠ‚**ï¼š
* 1ã€**å›¾åƒåˆ†è¾¨ç‡ä¼˜åŒ–ç­–ç•¥**ã€‚

æ•°æ®é›†ä¸­å›¾åƒçš„å°ºå¯¸å›¾åƒåˆ©ç”¨ç‡é—®é¢˜ï¼ˆé€‰æ‹©512x512èˆå¼ƒ256x256å°±ä¼šå¯¼è‡´å›¾åƒå¤§é‡è¢«èˆå¼ƒï¼‰å¦‚æœé€šè¿‡è¶…åˆ†è¾¨ç‡ç®—æ³•å°†å›¾åƒå°±è¡Œæ‰©å±•ä¼šæ”¾å¤§ä¼ªå½±ï¼Œè¿™äº›ä¼ªå½±å¯èƒ½ä¼šæ³„æ¼åˆ°æœ€ç»ˆçš„æ¨¡å‹è¾“å‡ºä¸­ï¼Œä¾‹å¦‚ï¼Œå¯¼è‡´æ ·æœ¬æ¨¡ç³Šã€‚ï¼ˆThe second method, on the other hand, usually introduces upscaling artifacts which may leak into the final model outputs, causing, for example, blurry samples.ï¼‰ä½œè€…åšæ³•æ˜¯ï¼š**è®­ç»ƒé˜¶æ®µ**ç›´æ¥å°†åŸå§‹å›¾åƒçš„åˆ†è¾¨ç‡ $c=(h_{org},w_{org})$ä½œä¸ºä¸€ä¸ªæ¡ä»¶ï¼Œé€šè¿‡å‚…é‡Œå¶ç‰¹å¾ç¼–ç è€ŒååŠ å…¥åˆ°time embeddingä¸­ï¼Œ**æ¨ç†é˜¶æ®µ**ç›´æ¥å°†åˆ†è¾¨ç‡ä½œä¸ºä¸€ä¸ªæ¡ä»¶å°±è¡ŒåµŒå…¥ï¼Œè¿›è€Œå®ç°ï¼š**å½“è¾“å…¥ä½åˆ†è¾¨ç‡æ¡ä»¶æ—¶ï¼Œç”Ÿæˆçš„å›¾åƒè¾ƒæ¨¡ç³Šï¼›åœ¨ä¸æ–­å¢å¤§åˆ†è¾¨ç‡æ¡ä»¶æ—¶ï¼Œç”Ÿæˆçš„å›¾åƒè´¨é‡ä¸æ–­æå‡ã€‚**
![image.png](https://s2.loli.net/2025/07/09/pMcLmdHThu2CnNx.webp)

* 2ã€**å›¾åƒè£å‰ªä¼˜åŒ–ç­–ç•¥**

ç›´æ¥ç»Ÿä¸€é‡‡æ ·è£å‰ªåæ ‡topå’Œcleftï¼ˆåˆ†åˆ«æŒ‡å®šä»å·¦ä¸Šè§’æ²¿é«˜åº¦å’Œå®½åº¦è½´è£å‰ªçš„åƒç´ æ•°é‡çš„æ•´æ•°ï¼‰ï¼Œå¹¶é€šè¿‡å‚…é‡Œå¶ç‰¹å¾åµŒå…¥å°†å®ƒä»¬ä½œä¸ºè°ƒèŠ‚å‚æ•°è¾“å…¥æ¨¡å‹ï¼Œç±»ä¼¼äºä¸Šé¢æè¿°çš„å°ºå¯¸è°ƒèŠ‚ã€‚ç¬¬1ï¼Œ2ç‚¹ä»£ç ä¸­çš„å¤„ç†æ–¹å¼ä¸ºï¼š
```python
def _get_add_time_ids(
        self, original_size, crops_coords_top_left, target_size, dtype, text_encoder_projection_dim=None
    ):
    add_time_ids = list(original_size + crops_coords_top_left + target_size)

    passed_add_embed_dim = (
        self.unet.config.addition_time_embed_dim * len(add_time_ids) + text_encoder_projection_dim
    )
    expected_add_embed_dim = self.unet.add_embedding.linear_1.in_features
    ...
    add_time_ids = torch.tensor([add_time_ids], dtype=dtype)
    return add_time_ids
```

> **æ¨èé˜…è¯»**ï¼š
> 1ã€[SDv1.5-SDXL-SD3ç”Ÿæˆæ•ˆæœå¯¹æ¯”](https://www.magicflow.ai/showcase/sd3-sdxl-sd1.5)

### Imagen
> https://imagen.research.google/
> https://deepmind.google/models/imagen/
> éå®˜æ–¹å®ç°ï¼šhttps://github.com/lucidrains/imagen-pytorch
> ç±»ä¼¼Githubï¼Œé€šè¿‡3é˜¶æ®µç”Ÿæˆï¼šhttps://github.com/deep-floyd/IF

Imagen[^6]è®ºæ–‡ä¸­ä¸»è¦æå‡ºï¼š1ã€çº¯æ–‡æœ¬è¯­æ–™åº“ä¸Šé¢„è®­ç»ƒçš„é€šç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚[T5](https://huggingface.co/collections/google/t5-release-65005e7c520f8d7b4d037918)ã€CLIPã€BERTç­‰ï¼‰åœ¨ç¼–ç å›¾åƒåˆæˆçš„æ–‡æœ¬æ–¹é¢éå¸¸æœ‰æ•ˆï¼šåœ¨Imagenä¸­å¢åŠ è¯­è¨€æ¨¡å‹çš„å¤§å°æ¯”å¢åŠ å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¤§å°æ›´èƒ½æé«˜æ ·æœ¬ä¿çœŸåº¦å’ŒImagetextå¯¹é½ã€‚
![](https://s2.loli.net/2025/07/12/lCFNWwDmgGnZueE.webp)

2ã€é€šè¿‡æé«˜classifier-free guidance weightï¼ˆ$\epsilon(z,c)=w\epsilon(z,c)+ (1-w)\epsilon(z)$ ä¹Ÿå°±æ˜¯å…¶ä¸­çš„å‚æ•° $w$ï¼‰å¯ä»¥æé«˜image-textä¹‹é—´çš„å¯¹é½ï¼Œä½†ä¼šæŸå®³å›¾åƒé€¼çœŸåº¦ï¼Œäº§ç”Ÿé«˜åº¦é¥±å’Œä¸è‡ªç„¶çš„å›¾åƒï¼ˆè®ºæ–‡é‡Œé¢ç»™å‡ºçš„åˆ†ææ˜¯ï¼šæ¯ä¸ªæ—¶é—´æ­¥ä¸­é¢„æµ‹å’Œæ­£å¼çš„xéƒ½ä¼šé™å®šåœ¨ $[-1,1]$è¿™ä¸ªèŒƒå›´ä½†æ˜¯è¾ƒå¤§çš„ $w$å¯èƒ½å¯¼è‡´è¶…å‡ºè¿™ä¸ªèŒƒå›´ï¼‰ï¼Œè®ºæ–‡é‡Œé¢åšæ³•å°±æ˜¯æå‡º **åŠ¨æ€è°ƒæ•´æ–¹æ³•**ï¼šåœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†sè®¾ç½®ä¸º $x_0^t$ä¸­çš„æŸä¸ªç™¾åˆ†ä½ç»å¯¹åƒç´ å€¼ï¼Œå¦‚æœs>1ï¼Œåˆ™æˆ‘ä»¬å°† $x_0^t$é˜ˆå€¼è®¾ç½®ä¸ºèŒƒå›´ $[-s,s]$ï¼Œç„¶åé™¤ä»¥sã€‚
![](https://s2.loli.net/2025/07/12/jAEBS7I1Ob6DPal.webp)

3ã€å’Œä¸Šé¢SDæ¨¡å‹å·®å¼‚æ¯”è¾ƒå¤§çš„ä¸€ç‚¹å°±æ˜¯ï¼Œåœ¨imagenä¸­ç›´æ¥ä½¿ç”¨å¤šé˜¶æ®µç”Ÿæˆç­–ç•¥ï¼Œæ¨¡å‹å…ˆç”Ÿæˆ64x64å›¾åƒå†å»é€šè¿‡è¶…åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹å»ç”Ÿæˆ256x256ä»¥åŠ1024x1024çš„å›¾åƒï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­ä½œè€…æåˆ°ä½¿ç”¨noise conditioning augmentationï¼ˆNCAï¼‰ç­–ç•¥ï¼ˆ**å¯¹è¾“å…¥çš„æ–‡æœ¬ç¼–ç åå†å»æ·»åŠ éšæœºå™ªå£°**ï¼‰
![](https://s2.loli.net/2025/07/12/HJm96oPr2AlXICs.webp)

### Dit
> https://github.com/facebookresearch/DiT

![](https://s2.loli.net/2025/07/15/CUisy5TPE24kKaH.webp)

Dit[^11]æ¨¡å‹ç»“æ„ä¸Šï¼Œ1ã€**æ¨¡å‹è¾“å…¥**ï¼Œå°†è¾“å…¥çš„image/latentåˆ‡åˆ†ä¸ºä¸åŒpatchè€Œåå»å¯¹ä¸åŒç¼–ç åçš„patchä¸Šå»æ·»åŠ ä½ç½®ç¼–ç ï¼ˆç›´æ¥ä½¿ç”¨çš„sin-cosä½ç½®ç¼–ç ï¼‰ï¼Œ2ã€**æ—¶é—´æ­¥ä»¥åŠæ¡ä»¶ç¼–ç **ï¼Œå¯¹äºæ—¶é—´æ­¥tä»¥åŠæ¡ä»¶cçš„ç¼–ç è€Œåå°†ä¸¤éƒ¨åˆ†ç¼–ç åçš„å†…å®¹è¿›è¡Œç›¸åŠ ï¼Œåœ¨`TimestepEmbedder`ä¸Šå¤„ç†æ–¹å¼æ˜¯ï¼šç›´æ¥é€šè¿‡**æ­£å¼¦æ—¶é—´æ­¥åµŒå…¥**æ–¹å¼è€Œåå°†ç¼–ç åçš„å†…å®¹é€šè¿‡ä¸¤å±‚linerå¤„ç†ï¼›åœ¨`LabelEmbedder`å¤„ç†æ–¹å¼ä¸Šå°±æ¯”è¾ƒç®€å•ç›´æ¥é€šè¿‡`nn.Embedding`è¿›è¡Œç¼–ç å¤„ç†ã€‚3ã€ä½¿ç”¨Adaptive layer normï¼ˆadaLNï¼‰blockä»¥åŠadaZero-Blockï¼ˆå¯¹æœ‰äº›å‚æ•°åˆå§‹åŒ–ä¸º0ï¼Œå°±å’Œloraä¸­ä¸€æ ·åˆå§‹åŒ–ABä¸º0ï¼Œä¸ºäº†ä¿è¯åç»­æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šï¼‰
> åœ¨[layernorm](https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)ä¸­ä¸€èˆ¬å½’ä¸€åŒ–å¤„ç†æ–¹å¼ä¸ºï¼š$\text{Norm}(x)=\gamma \frac{x-\mu}{\sqrt{\sigma^2+ \epsilon}}+\beta$ å…¶ä¸­æœ‰ä¸¤ä¸ªå‚æ•° $\gamma$ å’Œ $\beta$ æ˜¯å›ºå®šçš„å¯å­¦ä¹ å‚æ•°ï¼ˆæ¯”å¦‚è¯´ç›´æ¥é€šè¿‡ `nn.Parameter` è¿›è¡Œåˆ›å»ºï¼‰ï¼Œåœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶åˆ›å»ºï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ã€‚ä½†æ˜¯åœ¨ adaLNä¸­åˆ™æ˜¯ç›´æ¥é€šè¿‡ $\text{Norm}(x)=\gamma(c) \frac{x-\mu}{\sqrt{\sigma^2+ \epsilon}}+\beta(c)$ é€šè¿‡è¾“å…¥çš„æ¡ä»¶cè¿›è¡Œå­¦ä¹ çš„ï¼Œ

### Hunyuan-DiT
> https://huggingface.co/Tencent-Hunyuan/HunyuanDiT

è…¾è®¯çš„Hunyuan-DiT[^8]æ¨¡å‹æ•´ä½“ç»“æ„

![](https://s2.loli.net/2025/07/15/Hum9FCtPbV7do1B.webp)

æ•´ä½“æ¡†æ¶ä¸æ˜¯å¾ˆå¤æ‚ï¼Œ1ã€æ–‡æœ¬ç¼–ç ä¸Šç›´æ¥é€šè¿‡ç»“åˆä¸¤ä¸ªç¼–ç å™¨ï¼šCLIPã€T5ï¼›2ã€VAEåˆ™æ˜¯ç›´æ¥ä½¿ç”¨çš„SD1.5çš„ï¼›3ã€å¼•å…¥2ç»´çš„æ—‹è½¬ä½ç½®ç¼–ç ï¼›4ã€åœ¨Ditç»“æ„ä¸Šï¼ˆå›¾ç‰‡VAEå‹ç¼©è€Œåå»åˆ‡åˆ†æˆä¸åŒpatchï¼‰ï¼Œä½¿ç”¨çš„æ˜¯å †å çš„æ³¨æ„åŠ›æ¨¡å—ï¼ˆåœ¨SD1.5ä¸­ä¹Ÿæ˜¯è¿™ç§ç»“æ„ï¼‰self-attention+cross-attentionï¼ˆæ­¤éƒ¨åˆ†è¾“å…¥æ–‡æœ¬ï¼‰ã€‚è®ºæ–‡é‡Œé¢åšäº†æ”¹è¿›æªæ–½ï¼š1ã€å€Ÿé‰´ä¹‹å‰å¤„ç†ï¼Œè®¡ç®—attentionä¹‹å‰é¦–å…ˆè¿›è¡Œnormå¤„ç†ï¼ˆä¹Ÿå°±æ˜¯å°†normæ‹¿åˆ°attentionå‰é¢ï¼‰ã€‚

ç®€çŸ­äº†è§£ä¸€ä¸‹æ¨¡å‹æ˜¯å¦‚ä½•åšæ•°æ®çš„ï¼š
![](https://s2.loli.net/2025/07/15/dJZETbyHB6SQPKI.webp)


### PixArt
> https://pixart-alpha.github.io/

åä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤æå‡ºçš„ $\text{PixArt}-\alpha$æ¨¡å‹æ•´ä½“æ¡†æ¶å¦‚ä¸‹ï¼š
![](https://s2.loli.net/2025/07/15/cWTtLdONRPC9fnz.webp)

ç›¸æ¯”è¾ƒDitæ¨¡å‹è®ºæ–‡é‡Œé¢ä¸»è¦è¿›è¡Œçš„æ”¹è¿›å¦‚ä¸‹ï¼š
1ã€**Cross-Attention layer**ï¼Œåœ¨DiT blockä¸­åŠ å…¥äº†ä¸€ä¸ªå¤šå¤´äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œå®ƒä½äºè‡ªæ³¨æ„åŠ›å±‚ï¼ˆä¸Šå›¾ä¸­çš„Multi-Head Self
-Attentionï¼‰å’Œå‰é¦ˆå±‚ï¼ˆPointwise Feedforwardï¼‰ä¹‹é—´ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°å¼•å…¥æ–‡æœ¬åµŒå…¥æ¡ä»¶ã€‚æ­¤å¤–ï¼Œä¸ºäº†åˆ©ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œå°†äº¤å‰æ³¨æ„åŠ›å±‚ä¸­çš„è¾“å‡ºæŠ•å½±å±‚åˆå§‹åŒ–ä¸ºé›¶ï¼Œä½œä¸ºæ’ç­‰æ˜ å°„ï¼Œä¿ç•™äº†è¾“å…¥ä»¥ä¾›åç»­å±‚ä½¿ç”¨ã€‚
2ã€AdaLN-singleï¼Œåœ¨Ditä¸­çš„adaptive normalization layersï¼ˆadaLNï¼‰ä¸­éƒ¨åˆ†å‚æ•°ï¼ˆ27%ï¼‰æ²¡æœ‰èµ·ä½œç”¨ï¼ˆåœ¨æ–‡ç”Ÿå›¾ä»»åŠ¡ä¸­ï¼‰å°†å…¶æ›¿æ¢ä¸ºadaLN-single

## Adapters
> https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference

æ­¤ç±»æ–¹æ³•æ˜¯åœ¨å®Œå¤‡çš„ DF æƒé‡åŸºç¡€ä¸Šï¼Œé¢å¤–æ·»åŠ ä¸€ä¸ªâ€œæ’ä»¶â€ï¼Œä¿æŒåŸæœ‰æƒé‡ä¸å˜ã€‚æˆ‘åªéœ€ä¿®æ”¹è¿™ä¸ªæ’ä»¶ï¼Œå°±å¯ä»¥è®©æ¨¡å‹ç”Ÿæˆä¸åŒé£æ ¼çš„å›¾åƒã€‚å¯ä»¥ç†è§£ä¸ºåœ¨åŸå§‹æ¨¡å‹ä¹‹å¤–æ–°å¢ä¸€ä¸ªâ€œç”Ÿæˆæ¡ä»¶â€ï¼Œé€šè¿‡ä¿®æ”¹è¿™ä¸€æ¡ä»¶å³å¯çµæ´»æ§åˆ¶æ¨¡å‹ç”Ÿæˆå„ç§é£æ ¼æˆ–æ»¡è¶³ä¸åŒéœ€æ±‚çš„å›¾åƒã€‚

### ControlNet
> https://github.com/lllyasviel/ControlNet
> å»ºè®®ç›´æ¥é˜…è¯»ï¼š[https://github.com/lllyasviel/ControlNet/discussions/categories/announcements](https://github.com/lllyasviel/ControlNet/discussions/categories/announcements) æ¥äº†è§£æ›´åŠ å¤šç»†èŠ‚

![](https://s2.loli.net/2025/07/09/Tfji2LMv15tgr6d.webp)

ControlNet[^2]çš„å¤„ç†æ€è·¯å°±å¾ˆç®€å•ï¼Œå†å·¦å›¾ä¸­æ¨¡å‹çš„å¤„ç†è¿‡ç¨‹å°±æ˜¯ç›´æ¥é€šè¿‡ï¼š$y=f(x;\theta)$æ¥ç”Ÿæˆå›¾åƒï¼Œä½†æ˜¯åœ¨ControlNeté‡Œé¢ä¼šå°†æˆ‘ä»¬æœ€å¼€å§‹çš„ç½‘ç»œç»“æ„å¤åˆ¶ç„¶åé€šè¿‡åœ¨å…¶å‰åå¼•å…¥ä¸€ä¸ª**zero-convolution**å±‚æ¥â€œæŒ‡å¯¼â€ï¼ˆ$Z$ï¼‰æ¨¡å‹çš„è¾“å‡ºä¹Ÿå°±æ˜¯è¯´å°†ä¸Šé¢çš„ç”Ÿæˆè¿‡ç¨‹å˜ä¸ºï¼š$y=f(x;\theta)+Z(f(x+Z(c;\theta_{z_1});\theta);\theta_{Z_2})$ã€‚é€šè¿‡å†»ç»“æœ€åˆçš„æ¨¡å‹çš„æƒé‡ä¿æŒä¸å˜ï¼Œä¿ç•™äº†Stable Diffusionæ¨¡å‹åŸæœ¬çš„èƒ½åŠ›ï¼›ä¸æ­¤åŒæ—¶ï¼Œä½¿ç”¨é¢å¤–æ•°æ®å¯¹â€œå¯è®­ç»ƒâ€å‰¯æœ¬è¿›è¡Œå¾®è°ƒï¼Œå­¦ä¹ æˆ‘ä»¬æƒ³è¦æ·»åŠ çš„æ¡ä»¶ã€‚å› æ­¤åœ¨æœ€åæˆ‘ä»¬çš„SDæ¨¡å‹ä¸­å°±æ˜¯å¦‚ä¸‹ä¸€ä¸ªç»“æ„ï¼š

![](https://s2.loli.net/2025/07/09/uVNAEnleRMJ6p4v.webp)

åœ¨è®ºæ–‡é‡Œé¢ä½œè€…ç»™å‡ºä¸€ä¸ªå®é™…çš„æµ‹è¯•æ•ˆæœå¯ä»¥å¾ˆå®¹æ˜“ç†è§£é‡Œé¢æ¡ä»¶cï¼ˆæ¡ä»¶ ğ‘å°±æ˜¯æä¾›ç»™æ¨¡å‹çš„æ˜¾å¼ç»“æ„å¼•å¯¼ä¿¡æ¯ï¼Œ**ç”¨äºåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç²¾ç¡®æ§åˆ¶å›¾åƒçš„ç©ºé—´ç»“æ„æˆ–å¸ƒå±€**ï¼Œä¸€èˆ¬æ¥è¯´å¯ä»¥æ˜¯è‰å›¾ã€åˆ†å‰²å›¾ç­‰ï¼‰åˆ°åº•æ˜¯ä¸€ä¸ªä»€ä¹ˆä¸œè¥¿ï¼Œæ¯”å¦‚è¯´å°±æ˜¯ç›´æ¥ç»™å‡ºä¸€ä¸ªâ€œçº¿ç¨¿â€ç„¶åæ¨¡å‹æ¥è¾“å‡ºå›¾åƒã€‚

![](https://s2.loli.net/2025/07/09/rkWH3o1MOaNs6pg.webp)

> **è¡¥å……-1**ï¼šä¸ºä»€ä¹ˆä½¿ç”¨ä¸Šé¢è¿™ç§ç»“æ„
> åœ¨[github](https://github.com/lllyasviel/ControlNet/discussions/188)ä¸Šä½œè€…è®¨è®ºäº†ä¸ºä»€ä¹ˆè¦ä½¿ç”¨ä¸Šé¢è¿™ç§ç»“æ„è€Œéç›´æ¥ä½¿ç”¨mlpç­‰ï¼ˆä½œè€…ç»™å‡ºäº†å¾ˆå¤šæµ‹è¯•å›¾åƒï¼‰ï¼Œæœ€åæ€»ç»“å°±æ˜¯ï¼š**è¿™ç§ç»“æ„å¥½**
> **è¡¥å……-2**ï¼šä½¿ç”¨0å·ç§¯å±‚ä¼šä¸ä¼šå¯¼è‡´æ¨¡å‹æ— æ³•ä¼˜åŒ–é—®é¢˜ï¼Ÿ
> ä¸ä¼šï¼Œå› ä¸ºå¯¹äºç¥ç»ç½‘ç»œç»“æ„å¤§å¤šéƒ½æ˜¯ï¼š$y=wx+b$è®¡ç®—æ¢¯åº¦è¿‡ç¨‹ä¸­å³ä½¿ $w=0$ä½†æ˜¯é‡Œé¢çš„ $xâ‰ 0$æ¨¡å‹çš„å‚æ•°è¿˜æ˜¯å¯ä»¥è¢«ä¼˜åŒ–çš„


#### ControlNetä»£ç æ“ä½œ
> Code: [https://github.com/shangxiaaabb/ProjectCode/tree/main/code/Python/DFModelCode/training_controlnet](https://github.com/shangxiaaabb/ProjectCode/tree/main/code/Python/DFModelCode/training_controlnet)
> æ¨¡å‹æƒé‡ï¼š

**é¦–å…ˆ**ï¼Œç®€å•äº†è§£ä¸€ä¸ªControlNetæ•°æ®é›†æ ¼å¼ï¼Œä¸€èˆ¬æ¥è¯´ï¼ˆï¼‰æ•°æ®ä¸»è¦æ˜¯ä¸‰éƒ¨åˆ†ç»„æˆï¼š1ã€imageï¼ˆå¯ä»¥ç†è§£ä¸ºç”Ÿæˆçš„å›¾åƒï¼‰ï¼›2ã€condiction_imageï¼ˆå¯ä»¥ç†è§£ä¸ºè¾“å…¥ControlNeté‡Œé¢çš„æ¡ä»¶ $c$ï¼‰ï¼›3ã€textã€‚æ¯”å¦‚è¯´ä»¥[raulc0399/open_pose_controlnet](https://huggingface.co/datasets/raulc0399/open_pose_controlnet)ä¸ºä¾‹
![](https://s2.loli.net/2025/07/12/nphNm3OIebFGazr.webp)

**æ¨¡å‹åŠ è½½**ï¼Œä¸€èˆ¬æ¥è¯´æ‰©æ•£æ¨¡å‹å°±åªéœ€è¦åŠ è½½å¦‚ä¸‹å‡ ä¸ªï¼š`DDPMScheduler`ã€`AutoencoderKL`ï¼ˆvaeæ¨¡å‹ï¼‰ã€`UNet2DConditionModel`ï¼ˆä¸ä¸€å®šåŠ è½½æ¡ä»¶Unetæ¨¡å‹ï¼‰ï¼Œé™¤æ­¤ä¹‹å¤–åœ¨ControlNetä¸­è¿˜éœ€è¦åŠ è½½ä¸€ä¸ª`ControlNetModel`ã€‚å¯¹äº`ControlNetModel`ä¸­ä»£ç å¤§è‡´ç»“æ„ä¸ºï¼Œä»£ç ä¸­é€šè¿‡`self.controlnet_down_blocks`æ¥å­˜å‚¨ControlNetçš„ä¸‹é‡‡æ ·æ¨¡å—ï¼ˆ**åˆå§‹åŒ–ä¸º0çš„å·ç§¯å±‚**ï¼‰ã€‚`self.down_blocks`ç”¨æ¥å­˜å‚¨ControlNetä¸­å¤åˆ¶çš„Unetçš„ä¸‹é‡‡æ ·å±‚ã€‚åœ¨`forward`ä¸­å¯¹äºè¾“å…¥çš„æ ·æœ¬ï¼ˆ`sample`ï¼‰é¦–å…ˆé€šè¿‡ `self.down_blocks`é€å±‚å¤„ç†å åŠ åˆ° `down_block_res_samples`ä¸­ï¼Œè€Œåå°±æ˜¯ç›´æ¥å°†å¾—åˆ°ç»“æœå†å»é€šè¿‡ `self.controlnet_down_blocks`æ¯å±‚è¿›è¡Œå¤„ç†ï¼Œæœ€åè¿”å›ä¸‹é‡‡æ ·çš„æ¯å±‚ç»“æœä»¥åŠä¸­é—´å±‚å¤„ç†ç»“æœï¼š`down_block_res_samples`ï¼Œ`mid_block_res_sample`

```python
class ControlNetModel(ModelMixin, ConfigMixin, FromOriginalModelMixin):
    @register_to_config
    def __init__(...):
        ...
        self.down_blocks = nn.ModuleList([])
        self.controlnet_down_blocks = nn.ModuleList([])
        # å°è£…ä¸‹é‡‡æ ·è¿‡ç¨‹ï¼ˆå¯¹åº”ä¸Šé¢æ¨¡å‹å³ä¾§ç»“æ„ï¼‰
        controlnet_block = nn.Conv2d(output_channel, output_channel, kernel_size=1)
        controlnet_block = zero_module(controlnet_block)
        self.controlnet_down_blocks.append(controlnet_block)
        for i, down_block_type in enumerate(down_block_types):
            # down_block_typeså°±æ˜¯Uneté‡Œé¢ä¸‹é‡‡æ ·çš„æ¯ä¸€ä¸ªæ¨¡å—æ¯”å¦‚è¯´ï¼šCrossAttnDownBlock2D
            ...
            down_block = get_down_block(down_block_type) # é€šè¿‡ get_down_block è·å–uetä¸‹é‡‡æ ·çš„æ¨¡å—
            self.down_blocks.append(down_block)
            for _ in range(layers_per_block):
                controlnet_block = nn.Conv2d(output_channel, output_channel, kernel_size=1)
                controlnet_block = zero_module(controlnet_block)
                self.controlnet_down_blocks.append(controlnet_block)
    @classmethod
    def from_unet(cls, unet,...):
        ...
        # é€šè¿‡clså®ä¾‹åŒ–çš„ç±»æœ¬èº«ControlNetModel
        controlnet = cls(...)
        if load_weights_from_unet:
            # å°†å„ç±»æƒé‡åŠ è½½åˆ° controlnet ä¸­
            controlnet.conv_in.load_state_dict(unet.conv_in.state_dict())
            controlnet.time_proj.load_state_dict(unet.time_proj.state_dict())
            ...

        return controlnet
    def forward(...):
        ...
        # æ—¶é—´ç¼–ç 
        t_emb = self.time_proj(timesteps)
        emb = self.time_embedding(t_emb, timestep_cond)
        if self.class_embedding is not None:
            ...
            class_emb = self.class_embedding(class_labels).to(dtype=self.dtype)
            emb = emb + class_emb
        # å¯¹æ¡ä»¶è¿›è¡Œç¼–ç 
        if self.config.addition_embed_type is not None:
            if self.config.addition_embed_type == "text":
                aug_emb = self.add_embedding(encoder_hidden_states)
            elif self.config.addition_embed_type == "text_time":
                time_ids = added_cond_kwargs.get("time_ids")
                time_embeds = self.add_time_proj(time_ids.flatten())
                time_embeds = time_embeds.reshape((text_embeds.shape[0], -1))

                add_embeds = torch.concat([text_embeds, time_embeds], dim=-1)
                add_embeds = add_embeds.to(emb.dtype)
                aug_emb = self.add_embedding(add_embeds)
        emb = emb + aug_emb if aug_emb is not None else emb       

        sample = self.conv_in(sample)
        controlnet_cond = self.controlnet_cond_embedding(controlnet_cond)
        sample = sample + controlnet_cond

        # ä¸‹é‡‡æ ·å¤„ç†
        down_block_res_samples = (sample,)
        for downsample_block in self.down_blocks:
            if ...
                ...
            else:
                sample, res_samples = downsample_block(hidden_states=sample, temb=emb)
            down_block_res_samples += res_samples
        # ä¸­é—´å±‚å¤„ç†
        ...
        # å°†è¾“å‡ºåçš„å†…å®¹å»å’Œ0å·ç§¯è¿›è¡Œå åŠ 
        controlnet_down_block_res_samples = ()
        for down_block_res_sample, controlnet_block in zip(down_block_res_samples, self.controlnet_down_blocks):
            down_block_res_sample = controlnet_block(down_block_res_sample)
            controlnet_down_block_res_samples = controlnet_down_block_res_samples + (down_block_res_sample,)
        ...
        if not return_dict:
            return (down_block_res_samples, mid_block_res_sample)
        ...
```

**æ¨¡å‹è®­ç»ƒ**ï¼Œè®­ç»ƒè¿‡ç¨‹å’ŒDFè®­ç»ƒå·®å¼‚ä¸å¤§ã€‚å°†å›¾åƒé€šè¿‡VAEå¤„ç†ã€äº§ç”Ÿå™ªå£°ã€æ—¶é—´æ­¥ã€å°†å™ªå£°æ·»åŠ åˆ°ï¼ˆVAEå¤„ç†ä¹‹åçš„ï¼‰å›¾åƒä¸­ï¼Œè€Œåé€šè¿‡ `controlnet`å¾—åˆ°æ¯å±‚ä¸‹é‡‡æ ·çš„ç»“æœä»¥åŠä¸­é—´å±‚ç»“æœï¼š`down_block_res_samples, mid_block_res_sample = controlnet(...)`è€Œåå°†è¿™ä¸¤éƒ¨åˆ†ç»“æœå†å»é€šè¿‡unetå¤„ç†
```python
model_pred = unet(
    noisy_latents,
    timesteps,
    encoder_hidden_states=encoder_hidden_states,
    down_block_additional_residuals=[
        sample.to(dtype=weight_dtype) for sample in down_block_res_samples
    ],
    mid_block_additional_residual=mid_block_res_sample.to(dtype=weight_dtype),
    return_dict=False,
)[0]
```

åç»­å°±æ˜¯è®¡ç®—lossç­‰å¤„ç†

**æ¨¡å‹éªŒè¯**ï¼Œç›´æ¥å°±æ˜¯ä½¿ç”¨`StableDiffusionControlNetPipeline`æ¥å¤„ç†äº†ã€‚æœ€åéšæœºæµ‹è¯•çš„éƒ¨åˆ†ä¾‹å­ï¼ˆcontrolnetå¾®è°ƒæ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼‰ï¼š
![output.jpg](https://s2.loli.net/2025/07/22/SNfEiTVXpeZgOIP.webp)

### T2I-Adapter
> https://github.com/TencentARC/T2I-Adapter

![image.png](https://s2.loli.net/2025/07/09/gZLDtFSGr25kCwa.webp)

T2I[^3]çš„å¤„ç†æ€è·¯ä¹Ÿæ¯”è¾ƒç®€å•ï¼ˆT2I-Adap 4 ter Detailsé‡Œé¢å…¶å®å°±å†™çš„å¾ˆæ˜ç™½äº†ï¼‰ï¼Œå¯¹äºè¾“å…¥çš„æ¡ä»¶å›¾ç‰‡ï¼ˆæ¯”å¦‚è¯´è¾¹ç¼˜å›¾åƒï¼‰:512x512ï¼Œé¦–å…ˆé€šè¿‡ pixel unshuffleè¿›è¡Œä¸‹é‡‡æ ·å°†å›¾åƒåˆ†è¾¨ç‡æ”¹ä¸ºï¼š64x64è€Œåé€šè¿‡ä¸€å±‚å·ç§¯+ä¸¤å±‚æ®‹å·®è¿æ¥ï¼Œè¾“å‡ºå¾—åˆ°ç‰¹å¾ $F_c$ä¹‹åå°†å…¶ä¸å¯¹åº”çš„encoderç»“æ„è¿›è¡Œç›¸åŠ ï¼š$F_{enc}+ F_c$ï¼Œå½“ç„¶T2Iä¹Ÿæ”¯æŒå¤šä¸ªæ¡ä»¶ï¼ˆç›´æ¥é€šè¿‡åŠ æƒç»„åˆå°±è¡Œï¼‰

### DreamBooth
> https://huggingface.co/docs/diffusers/v0.34.0/using-diffusers/dreambooth

è®ºæ–‡[^4]é‡Œé¢ä¸»è¦å‡ºå‘ç‚¹å°±æ˜¯ï¼š1ã€è§£å†³**language drif**ï¼ˆè¯­è¨€åç¦»é—®é¢˜ï¼‰ï¼šæŒ‡çš„æ˜¯æ¨¡å‹é€šè¿‡åè®­ç»ƒï¼ˆå¾®è°ƒç­‰å¤„ç†ä¹‹åï¼‰æ¨¡å‹ä¸§å¤±äº†å¯¹æŸäº›è¯­ä¹‰ç‰¹å¾çš„æ„ŸçŸ¥ï¼Œå°±æ¯”å¦‚è¯´æ‰©æ•£æ¨¡å‹é‡Œé¢ï¼Œæ¨¡å‹é€šè¿‡ä¸æ–­å¾®è°ƒå¯èƒ½å°±ä¸çŸ¥é“â€œç‹—â€æ˜¯ä»€ä¹ˆä»è€Œå¯¼è‡´æ¨¡å‹ç”Ÿæˆé”™è¯¯ã€‚2ã€é«˜æ•ˆçš„ç”Ÿæˆéœ€è¦çš„å¯¹è±¡ï¼Œä¸ä¼šäº§ç”Ÿï¼šç”Ÿæˆé”™è¯¯ã€ç»†èŠ‚ä¸¢å¤±é—®é¢˜ï¼Œæ¯”å¦‚è¯´ä¸‹é¢å›¾åƒä¸­çš„é—®é¢˜ï¼š
![](https://s2.loli.net/2025/07/12/mRaHPOtC23li9Fn.webp)

ä¸ºäº†å®ç°å›¾åƒçš„â€œé«˜æ•ˆè¿ç§»â€ï¼Œä½œè€…ç›´æ¥å°†å›¾åƒï¼ˆæ¯”å¦‚è¯´æˆ‘ä»¬éœ€è¦é£æ ¼åŒ–çš„å›¾ç‰‡ï¼‰ä½œä¸ºä¸€ä¸ªç‰¹æ®Šçš„æ ‡è®°ï¼Œä¹Ÿå°±æ˜¯è®ºæ–‡é‡Œé¢æåˆ°çš„ `a [identifier] [class noun]`ï¼ˆå…¶ä¸­class nounä¸ºç±»åˆ«æ¯”å¦‚æ‰€ç‹—ï¼Œidentifierå°±æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„æ ‡è®°ï¼‰ï¼Œåœ¨promptä¸­åŠ å…¥ç±»åˆ«ï¼Œé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ä¸­å…³äºè¯¥ç±»åˆ«ç‰©å“çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶å°†å…ˆéªŒçŸ¥è¯†ä¸ç‰¹æ®Šæ ‡è®°ç¬¦ç›¸å…³ä¿¡æ¯è¿›è¡Œèåˆï¼Œè¿™æ ·å°±å¯ä»¥åœ¨ä¸åŒåœºæ™¯ä¸‹ç”Ÿæˆä¸åŒå§¿åŠ¿çš„ç›®æ ‡ç‰©ä½“ã€‚å°±æ¯”å¦‚ä¸‹é¢çš„ `fine-tuning`è¿‡ç¨‹é€šè¿‡å‡ å¼ å›¾ç‰‡è®©æ¨¡å‹å­¦ä¹ åˆ° *ç‰¹æ®Šçš„ç‹—*ï¼Œç„¶åå†æ¨ç†é˜¶æ®µæ¨¡å‹å¯ä»¥åˆ©ç”¨è¿™ä¸ª *ç‰¹æ®Šçš„ç‹—*å»ç”Ÿæˆæ–°çš„åŠ¨ä½œã€‚

![](https://s2.loli.net/2025/07/12/hYM1VdykDxALrGo.webp)

å†è®ºæ–‡é‡Œé¢ä½œè€…è®¾è®¡å¦‚ä¸‹çš„Class-specific Prior Preservation Lossï¼ˆå‚è€ƒstackexchangeï¼‰[^5]ï¼š

$$\begin{aligned}
 & \mathbb{E}_{x,c,\epsilon,t}\left[\|\epsilon-\varepsilon_{\theta}(z_{t},t,c)\|_{2}^{2}+\lambda\|\epsilon^{\prime}-\epsilon_{pr}(z_{t^{\prime}}^{\prime},t^{\prime},c_{pr})\|_{2}^{2}\right]
\end{aligned}$$

ä¸Šé¢æŸå¤±å‡½æ•°ä¸­åé¢ä¸€éƒ¨åˆ†å°±æ˜¯æˆ‘ä»¬çš„å…ˆéªŒæŸå¤±ï¼Œæ¯”å¦‚è¯´$c+{pr}$å°±æ˜¯å¯¹ "a dog"è¿›è¡Œç¼–ç ç„¶åè®¡ç®—ç”ŸæˆæŸå¤±ã€‚åœ¨ä»£ç ä¸­ï¼š

```python
if args.with_prior_preservation:
    model_pred, model_pred_prior = torch.chunk(model_pred, 2, dim=0)
    target, target_prior = torch.chunk(target, 2, dim=0)
    # Compute instance loss
    loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
    # Compute prior loss
    prior_loss = F.mse_loss(model_pred_prior.float(), target_prior.float(), reduction="mean")
    # Add the prior loss to the instance loss.
    loss = loss + args.prior_loss_weight * prior_loss
else:
    loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
```

#### DreamBoothä»£ç æ“ä½œ
> ä»£ç ï¼š[https://github.com/shangxiaaabb/ProjectCode/tree/main/code/Python/DFModelCode/training_dreambooth_lora/](https://github.com/shangxiaaabb/ProjectCode/tree/main/code/Python/DFModelCode/training_dreambooth_lora/)
> æƒé‡ï¼š[https://www.modelscope.cn/models/bigyellowjie/SDXL-DreamBooth-LOL/files](https://www.modelscope.cn/models/bigyellowjie/SDXL-DreamBooth-LOL/files)

åœ¨ä»‹ç»DreamBoothä»£ç ä¹‹å‰ï¼Œç®€å•å›é¡¾DreamBoothåŸç†ï¼Œæˆ‘å¸Œæœ›æˆ‘çš„æ¨¡å‹å»å­¦ä¹ ä¸€ç§ç”»é£é‚£ä¹ˆæˆ‘å°±éœ€è¦å‡†å¤‡**æ ·æœ¬å›¾ç‰‡**ï¼ˆå¦‚3-5ï¼‰è¿™å‡ å¼ å›¾ç‰‡å°±æ˜¯ä¸“é—¨çš„æ¨¡å‹éœ€è¦å­¦ä¹ çš„ï¼Œä½†æ˜¯ä¸ºäº†é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼ˆæ¨¡å‹åªå­¦ä¹ äº†æˆ‘çš„å›¾ç‰‡å†…å®¹ï¼Œä½†æ˜¯å¯¹ä¸€äº›ç»†èŠ‚ä¸¢æ‰äº†ï¼Œæ¯”å¦‚è¯´æˆ‘æä¾›çš„5å¼ æ²¹ç”»ï¼Œæ¨¡å‹å°±å­¦ä¼šäº†æˆ‘çš„æ²¹ç”»ç”»é£ä½†æ˜¯ä¸ºäº†é˜²æ­¢æ¨¡å‹å¯¹æ›´åŠ å¤šçš„æ²¹ç”»ç»†èŠ‚å¿˜è®°äº†ï¼Œé‚£ä¹ˆæˆ‘å°±å‡†å¤‡`num_epochs * num_samples` å¼ æ²¹ç”»ç±»å‹å›¾ç‰‡ç„¶åé€šè¿‡è®¡ç®— `Class-specific Prior Preservation Loss`ï¼‰éœ€è¦å‡†å¤‡ **ç±»å‹å›¾ç‰‡**æ¥è®¡ç®—Class-specific Prior Preservation Lossã€‚ä»£ç å¤„ç†ï¼ˆSDXL+Loraï¼‰ï¼š
**é¦–å…ˆæ˜¯loraå¤„ç†æ¨¡å‹**ï¼šåœ¨åŸºäºtransformeré‡Œé¢çš„æ¨¡å‹å¾ˆå®¹æ˜“ä½¿ç”¨loraï¼Œæ¯”å¦‚è¯´ä¸‹é¢ä»£ç ä½¿ç”¨loraåŒ…è£¹æ¨¡å‹å¹¶ä¸”å¯¹æ¨¡å‹æƒé‡è¿›è¡Œä¿å­˜ï¼š
```python
from peft import LoraConfig
def get_lora_config(rank, dropout, use_dora, target_modules):
    '''lora config'''
    base_config = {
        "r": rank,
        "lora_alpha": rank,
        "lora_dropout": dropout,
        "init_lora_weights": "gaussian",
        "target_modules": target_modules,
    }
    return LoraConfig(**base_config)
# åŒ…è£¹loraæ¨¡å‹æƒé‡
unet_target_modules = ["to_k", "to_q", "to_v", "to_out.0"]
unet_lora_config = get_lora_config(
    rank= config.rank,
    dropout= config.lora_dropout,
    use_dora= config.use_dora,
    target_modules= unet_target_modules,
)
unet.add_adapter(unet_lora_config)
```

ä¸€èˆ¬çš„è¯è€ƒè™‘SDæ¨¡å‹æƒé‡éƒ½æ¯”è¾ƒå¤§ï¼Œè€Œä¸”æˆ‘ä»¬ä½¿ç”¨loraå¾®è°ƒæ¨¡å‹æ²¡å¿…è¦å¯¹æ‰€æœ‰çš„æ¨¡å‹æƒé‡è¿›è¡Œå­˜å‚¨ï¼Œé‚£ä¹ˆä¸€èˆ¬éƒ½ä¼šå®šä¹‰ä¸€ä¸ª`hook`æ¥å‘Šè¯‰æ¨¡å‹é‚£äº›å‚æ•°éœ€è¦ä¿å­˜ã€åŠ è½½æ¯”å¦‚ï¼š
```python
def save_model_hook(models, weights, output_dir):
    if accelerator.is_main_process:
        unet_lora_layers_to_save = None
        
        for model in models:
            if isinstance(model, type(unwrap_model(unet))):
                unet_lora_layers_to_save = convert_state_dict_to_diffusers(get_peft_model_state_dict(model))
            ...
            weights.pop() # å»æ‰ä¸éœ€è¦ä¿å­˜çš„å‚æ•°

        StableDiffusionXLPipeline.save_lora_weights(
            output_dir,
            unet_lora_layers= unet_lora_layers_to_save,
            ...
        )
def load_model_hook(models, input_dir):
    unet_ = None

    while len(models) > 0:
        model = models.pop()

        if isinstance(model, type(unwrap_model(unet))):
            unet_ = model

    lora_state_dict, network_alphas = StableDiffusionLoraLoaderMixin.lora_state_dict(input_dir)

    unet_state_dict = {f"{k.replace('unet.', '')}": v for k, v in lora_state_dict.items() if k.startswith("unet.")}
    unet_state_dict = convert_unet_state_dict_to_peft(unet_state_dict)
    incompatible_keys = set_peft_model_state_dict(unet_, unet_state_dict, adapter_name="default")
    ...
accelerator.register_save_state_pre_hook(save_model_hook)
accelerator.register_load_state_pre_hook(load_model_hook)
```

è¿™æ ·ä¸€æ¥ä½¿ç”¨ `accelerator.save_state(save_path)` å°±ä¼šå…ˆå»ä½¿ç”¨ `hook`å¤„ç†å‚æ•°ç„¶åè¿›è¡Œä¿å­˜ã€‚
**å…¶æ¬¡æ¨¡å‹è®­ç»ƒ**ï¼šå°±æ˜¯å¸¸è§„çš„æ¨¡å‹è®­ç»ƒï¼ˆç›´æ¥åœ¨æ ·æœ¬å›¾ç‰‡ï¼š`instance_data_dir`ä»¥åŠæ ·æœ¬çš„promptï¼š`instance_prompt`ä¸Šè¿›è¡Œå¾®è°ƒï¼‰ç„¶åè®¡ç®—losså³å¯ï¼Œå¦‚æœæ¶‰åŠåˆ°`Class-specific Prior Preservation Loss`ï¼ˆé™¤äº†ä¸Šé¢ä¸¤ä¸ªç»„åˆè¿˜éœ€è¦ï¼š`class_data_dir`ä»¥åŠ `class_prompt`ï¼‰é‚£ä¹ˆå¤„ç†è¿‡ç¨‹ä¸ºï¼ˆä»¥SDXLä¸ºä¾‹ï¼‰ï¼Œä¸è¿‡éœ€è¦äº‹å…ˆäº†è§£çš„æ˜¯åœ¨è®¡ç®—è¿™ä¸ªlossä¹‹å‰ä¼šå°†ä¸¤ä¸ªæ•°æ®é›†ä»¥åŠpromptéƒ½**ç»„åˆåˆ°ä¸€èµ·æˆä¸ºä¸€ä¸ªæ•°æ®é›†**ï¼ˆ`instance-image-prompt` ä»¥åŠ `class-image-prompt`ä¹‹é—´æ˜¯åŒ¹é…çš„ï¼‰ï¼š
```python
# æ ·æœ¬å†…å®¹ç¼–ç 
instance_prompt_hidden_states, instance_pooled_prompt_embeds = compute_text_embeddings(config.instance_prompt, text_encoders, tokenizers)
# ç±»å‹å›¾ç‰‡å†…å®¹ç¼–ç 
if config.with_prior_preservation:
    class_prompt_hidden_states, class_pooled_prompt_embeds = compute_text_embeddings(config.class_prompt, text_encoders, tokenizers)
...
prompt_embeds = instance_prompt_hidden_states
unet_add_text_embeds = instance_pooled_prompt_embeds
if not config.with_prior_preservation:
    prompt_embeds = torch.cat([prompt_embeds, class_prompt_hidden_states], dim=0)
    unet_add_text_embeds = torch.cat([unet_add_text_embeds, class_pooled_prompt_embeds], dim=0)
...
model_pred = unet(...)
if config.with_prior_preservation:
    model_pred, model_pred_prior = torch.chunk(model_pred, 2, dim=0)
    target, target_prior = torch.chunk(target, 2, dim=0)
    ...
    prior_loss = F.mse_loss(model_pred_prior.float(), target_prior.float(), reduction="mean")
...
loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
...
loss = loss + config.prior_loss_weight * prior_loss
accelerator.backward(loss)
```

åœ¨è¿™ä¸ªé‡Œé¢ä¹‹æ‰€ä»¥ç”¨ `chunk`æ˜¯å› ä¸ºåœ¨æ•°æ®é›†æ„ä»¶ä¸­ï¼š
```python
pixel_values = [example["instance_images"] for example in examples]
...    
if with_prior_preservation:
    pixel_values += [example["class_images"] for example in examples]
pixel_values = torch.stack(pixel_values)
...
```
é‚£ä¹ˆè¿™æ ·ä¸€æ¥æ•°æ®ä¸­ä¸€åŠæ¥è‡ªæ ·æœ¬å›¾ç‰‡ä¸€éƒ¨åˆ†æ¥è‡ªç±»å‹å›¾ç‰‡ï¼Œåœ¨æ¨¡å‹å¤„ç†ä¹‹ååœ¨`model_pred`å°±æœ‰ä¸€éƒ¨åˆ†æ˜¯æ ·æœ¬å›¾ç‰‡çš„é¢„æµ‹ï¼Œå¦å¤–ä¸€éƒ¨åˆ†ä¸ºç±»å‹å›¾ç‰‡é¢„æµ‹ã€‚æœ€åæµ‹è¯•çš„ç»“æœä¸ºï¼ˆ`prompt: "A photo of Rengar the Pridestalker in a bucket"`ï¼Œæ¨¡å‹[ä»£ç ](https://github.com/shangxiaaabb/ProjectCode/tree/main/code/Python/DFModelCode/training_dreambooth_lora/)ä»¥åŠ[æƒé‡ä¸‹è½½](https://www.modelscope.cn/models/bigyellowjie/SDXL-DreamBooth-LOL/files)ï¼‰ï¼š

![image.png](https://s2.loli.net/2025/07/15/7xIPMW6SJ1degZj.webp)

## è¡¥å……å†…å®¹


## æ€»ç»“
å¯¹äºä¸åŒçš„æ‰©æ•£ï¼ˆåŸºåº§ï¼‰æ¨¡å‹ï¼ˆSD1.5ã€SDXLã€Imagenï¼‰ç­‰å¤§éƒ¨åˆ†éƒ½æ˜¯é‡‡ç”¨Unetç»“æ„ï¼Œå½“ç„¶ä¹Ÿæœ‰é‡‡ç”¨Ditçš„ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹ï¼ˆSD1.5ã€SDXLï¼‰ä¹‹é—´çš„å·®å¼‚ä¸»è¦åœ¨äºåè€…ä¼šå¤šä¸€ä¸ªclipç¼–ç å™¨å†æ–‡æœ¬è¯­ä¹‰ä¸Šæ¯”å‰è€…æ›´åŠ æœ‰ä¼˜åŠ¿ã€‚å¯¹äºadapterè€Œè¨€ï¼Œå¯ä»¥ç›´æ¥ç†è§£ä¸ºå†SDçš„åŸºç¡€ä¸Šå»ä½¿ç”¨â€œé£æ ¼æ’ä»¶â€ï¼Œè¿™ä¸ªæ’ä»¶ä¸å»å¯¹SDæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼ˆä»è€Œå®ç°å¯¹å‚æ•°çš„å‡å°ï¼‰ï¼Œå¯¹äºControNetå°±æ˜¯ç›´æ¥å¯¹Unetçš„ä¸‹é‡‡æ ·æ‰€æœ‰çš„æ¨¡å—ï¼ˆå‰åï¼‰éƒ½åŠ ä¸€ä¸ªzero-convè€Œåå°†ç»“æœå†å»åµŒå…¥åˆ°ä¸‹é‡‡ç”¨ä¸­ï¼Œè€ŒT2I-Adapteråˆ™æ˜¯å»å¯¹æ¡ä»¶è¿›è¡Œç¼–ç è€ŒååµŒå…¥åˆ°SDæ¨¡å‹ï¼ˆä¸Šé‡‡ç”¨æ¨¡å—ï¼‰ä¸­ã€‚å¯¹äºderambothå°±æ˜¯ç›´æ¥é€šè¿‡ç»™å®šçš„æ ·æœ¬å›¾ç‰‡å»ç”Ÿâ€œå¾®è°ƒâ€æ¨¡å‹ï¼Œè€Œåé€šè¿‡è®¾è®¡çš„Class-specific Prior Preservation Lossæ¥ç¡®ä¿æ‰€ç”Ÿæˆçš„æ ·æœ¬ç‰¹é‡Œä¸ä¼šå‘ç”Ÿè¿‡æ‹Ÿåˆã€‚

## å‚è€ƒ
[^1]:[https://arxiv.org/pdf/2307.01952](https://arxiv.org/pdf/2307.01952)
[^2]:[https://arxiv.org/pdf/2302.05543](https://arxiv.org/pdf/2302.05543)
[^3]:[https://arxiv.org/pdf/2302.08453](https://arxiv.org/pdf/2302.08453)
[^4]:[https://arxiv.org/pdf/2208.12242](https://arxiv.org/pdf/2208.12242)
[^5]:https://stats.stackexchange.com/questions/601782/how-to-rewrite-dreambooth-loss-in-terms-of-epsilon-prediction
[^6]:[https://arxiv.org/pdf/2205.11487](https://arxiv.org/pdf/2205.11487)
[^8]:[https://arxiv.org/pdf/2405.08748](https://arxiv.org/pdf/2405.08748)
[^9]:[https://arxiv.org/pdf/2506.15742](https://arxiv.org/pdf/2506.15742)
[^10]:[https://arxiv.org/pdf/2310.00426](https://arxiv.org/pdf/2310.00426)
[^11]:[Scalable Diffusion Models with Transformers](https://openaccess.thecvf.com/content/ICCV2023/papers/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.pdf)