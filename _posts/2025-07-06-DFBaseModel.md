---
layout: mypost
title: æ·±å…¥æµ…å‡ºäº†è§£ç”Ÿæˆæ¨¡å‹-6ï¼šå¸¸ç”¨åŸºç¡€æ¨¡å‹ä¸ Adaptersç­‰è§£æ
categories: ç”Ÿæˆæ¨¡å‹
extMath: true
images: true
address: é•¿æ²™ğŸŒ·
show_footer_image: true
tags:
- ç”Ÿæˆæ¨¡å‹
- diffusion model
- ControlNet
- T2I-Adapter
- SD
- SDVL
show: true
description: å¯¹æ¯”Stable Diffusion SD 1.5ä¸SDXLæ¨¡å‹å·®å¼‚ï¼ŒSDXLé‡‡ç”¨åŒCLIPç¼–ç å™¨ï¼ˆOpenCLIP-ViT/G+CLIP-ViT/Lï¼‰æå‡æ–‡æœ¬ç†è§£ï¼Œé»˜è®¤1024x1024åˆ†è¾¨ç‡å¹¶ä¼˜åŒ–å¤„ç†ï¼›ä»‹ç»ControlNetï¼ˆç©ºé—´ç»“æ„æ§åˆ¶ï¼‰ã€T2I-Adapterã€DreamBoothï¼ˆè§£å†³è¯­è¨€åç¦»ï¼‰ç­‰Adaptersï¼Œå®ç°é£æ ¼è¿ç§»ä¸é«˜æ•ˆç”Ÿæˆã€‚
---

## åŸºåº§æ‰©æ•£æ¨¡å‹
ä¸»è¦ä»‹ç»SDä»¥åŠSDXLä¸¤ç±»æ¨¡å‹ï¼Œä½†æ˜¯SDè¿­ä»£ç‰ˆæœ¬æŒºå¤šçš„ï¼ˆä»1.2åˆ°3.5ï¼‰å› æ­¤æœ¬æ–‡ä¸»è¦é‡ç‚¹ä»‹ç»SD 1.5ä»¥åŠSDXLä¸¤ä¸ªåŸºåº§æ¨¡å‹ï¼Œä»¥åŠä¸¤è€…ä¹‹é—´çš„å¯¹æ¯”å·®å¼‚ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜æœ‰è®¸å¤šé—­æºçš„æ‰©æ•£æ¨¡å‹æ¯”å¦‚è¯´Imagenã€DALEç­‰ã€‚

### SDv1.5 vs SDXL[^1]
> **SDv1.5**: https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5
> **SDXL**:https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0

ä¸¤è€…æ¨¡å‹è¯¦ç»†çš„æ¨¡å‹ç»“æ„ï¼š[SDv1.5--SDXLæ¨¡å‹ç»“æ„å›¾](https://1drv.ms/u/c/667854cf645e8766/ESgZEHNEn3RJsKY0t1KQAgABYKHDhQtutJztw6OhEt9DPg?e=5SqEro)ï¼Œå…¶ä¸­å…·ä½“æ¨¡å‹å‚æ•°çš„å¯¹æ¯”å¦‚ä¸‹ï¼š
**1ã€CLIPç¼–ç å™¨åŒºåˆ«**ï¼š
åœ¨SD1.5ä¸­é€‰æ‹©çš„æ˜¯**CLIP-ViT/L**ï¼ˆå¾—åˆ°çš„ç»´åº¦ä¸ºï¼š768ï¼‰è€Œåœ¨SDXLä¸­é€‰æ‹©çš„æ˜¯ä¸¤ä¸ªCLIPæ–‡æœ¬ç¼–ç å™¨ï¼š**OpenCLIP-ViT/G**ï¼ˆå¾—åˆ°çš„ç»´åº¦ä¸ºï¼š1280ï¼‰ä»¥åŠ**CLIP-ViT/L**ï¼ˆå¾—åˆ°ç»´åº¦ä¸ºï¼š768ï¼‰åœ¨ä»£ç ä¸­å¯¹äºä¸¤ä¸ªæ–‡æœ¬é€šè¿‡ç¼–ç å™¨å¤„ç†ä¹‹åSDXLç›´æ¥é€šè¿‡catæ–¹å¼æ‹¼æ¥ï¼š`prompt_embeds = torch.concat(prompt_embeds_list, dim=-1)` ä¹Ÿå°±æ˜¯è¯´æœ€åå¾—åˆ°çš„ç»´åº¦ä¸ºï¼š[..,..,1280+768]ã€‚æœ€åæ•ˆæœå¾ˆæ˜æ˜¾ï¼š**SDXLå¯¹äºæ–‡æœ¬çš„ç†è§£èƒ½åŠ›å¤§äºSD1.5**
**2ã€å›¾åƒè¾“å‡ºç»´åº¦åŒºåˆ«**ï¼š
å†SD1.5ä¸­çš„é»˜è®¤è¾“å‡ºæ˜¯ï¼š512x512è€Œå†SDXLä¸­çš„é»˜è®¤è¾“å‡ºæ˜¯ï¼š1024x1024ï¼Œå¦‚æœå¸Œæœ›å°†SD1.5ç”Ÿæˆçš„å›¾åƒå¤„ç†ä¸º1024x1024å¯ä»¥ç›´æ¥é€šè¿‡è¶…åˆ†ç®—æ³•æ¥è¿›è¡Œå¤„ç†ï¼Œé™¤æ­¤ä¹‹å¤–åœ¨SDXLä¸­è¿˜ä¼šä½¿ç”¨ä¸€ä¸ªrefineræ¨¡å‹ï¼ˆå’ŒUnetçš„ç»“æ„ç›¸ä¼¼ï¼‰æ¥å¼ºåŒ–baseæ¨¡å‹ï¼ˆUnetï¼‰ç”Ÿæˆçš„æ•ˆæœã€‚
**3ã€SDXLè®ºæ–‡ä¸­çš„æŠ€æœ¯ç»†èŠ‚**ï¼š
* 1ã€**å›¾åƒåˆ†è¾¨ç‡ä¼˜åŒ–ç­–ç•¥**ã€‚

æ•°æ®é›†ä¸­å›¾åƒçš„å°ºå¯¸å›¾åƒåˆ©ç”¨ç‡é—®é¢˜ï¼ˆé€‰æ‹©512x512èˆå¼ƒ256x256å°±ä¼šå¯¼è‡´å›¾åƒå¤§é‡è¢«èˆå¼ƒï¼‰å¦‚æœé€šè¿‡è¶…åˆ†è¾¨ç‡ç®—æ³•å°†å›¾åƒå°±è¡Œæ‰©å±•ä¼šæ”¾å¤§ä¼ªå½±ï¼Œè¿™äº›ä¼ªå½±å¯èƒ½ä¼šæ³„æ¼åˆ°æœ€ç»ˆçš„æ¨¡å‹è¾“å‡ºä¸­ï¼Œä¾‹å¦‚ï¼Œå¯¼è‡´æ ·æœ¬æ¨¡ç³Šã€‚ï¼ˆThe second method, on the other hand, usually introduces upscaling artifacts which may leak into the final model outputs, causing, for example, blurry samples.ï¼‰ä½œè€…åšæ³•æ˜¯ï¼š**è®­ç»ƒé˜¶æ®µ**ç›´æ¥å°†åŸå§‹å›¾åƒçš„åˆ†è¾¨ç‡ $c=(h_{org},w_{org})$ä½œä¸ºä¸€ä¸ªæ¡ä»¶ï¼Œé€šè¿‡å‚…é‡Œå¶ç‰¹å¾ç¼–ç è€ŒååŠ å…¥åˆ°time embeddingä¸­ï¼Œ**æ¨ç†é˜¶æ®µ**ç›´æ¥å°†åˆ†è¾¨ç‡ä½œä¸ºä¸€ä¸ªæ¡ä»¶å°±è¡ŒåµŒå…¥ï¼Œè¿›è€Œå®ç°ï¼š**å½“è¾“å…¥ä½åˆ†è¾¨ç‡æ¡ä»¶æ—¶ï¼Œç”Ÿæˆçš„å›¾åƒè¾ƒæ¨¡ç³Šï¼›åœ¨ä¸æ–­å¢å¤§åˆ†è¾¨ç‡æ¡ä»¶æ—¶ï¼Œç”Ÿæˆçš„å›¾åƒè´¨é‡ä¸æ–­æå‡ã€‚**
![image.png](https://s2.loli.net/2025/07/09/pMcLmdHThu2CnNx.webp)

* 2ã€**å›¾åƒè£å‰ªä¼˜åŒ–ç­–ç•¥**

ç›´æ¥ç»Ÿä¸€é‡‡æ ·è£å‰ªåæ ‡topå’Œcleftï¼ˆåˆ†åˆ«æŒ‡å®šä»å·¦ä¸Šè§’æ²¿é«˜åº¦å’Œå®½åº¦è½´è£å‰ªçš„åƒç´ æ•°é‡çš„æ•´æ•°ï¼‰ï¼Œå¹¶é€šè¿‡å‚…é‡Œå¶ç‰¹å¾åµŒå…¥å°†å®ƒä»¬ä½œä¸ºè°ƒèŠ‚å‚æ•°è¾“å…¥æ¨¡å‹ï¼Œç±»ä¼¼äºä¸Šé¢æè¿°çš„å°ºå¯¸è°ƒèŠ‚
ç¬¬1ï¼Œ2ç‚¹ä»£ç ä¸­çš„å¤„ç†æ–¹å¼ä¸ºï¼š
```python
def _get_add_time_ids(
        self, original_size, crops_coords_top_left, target_size, dtype, text_encoder_projection_dim=None
    ):
    add_time_ids = list(original_size + crops_coords_top_left + target_size)

    passed_add_embed_dim = (
        self.unet.config.addition_time_embed_dim * len(add_time_ids) + text_encoder_projection_dim
    )
    expected_add_embed_dim = self.unet.add_embedding.linear_1.in_features
    ...
    add_time_ids = torch.tensor([add_time_ids], dtype=dtype)
    return add_time_ids
```

> **æ¨èé˜…è¯»**ï¼š
> 1ã€[SDv1.5-SDXL-SD3ç”Ÿæˆæ•ˆæœå¯¹æ¯”](https://www.magicflow.ai/showcase/sd3-sdxl-sd1.5)

### Imagenç³»åˆ—
> https://imagen.research.google/
> https://deepmind.google/models/imagen/
> éå®˜æ–¹å®ç°ï¼šhttps://github.com/lucidrains/imagen-pytorch
> ç±»ä¼¼Githubï¼Œé€šè¿‡3é˜¶æ®µç”Ÿæˆï¼šhttps://github.com/deep-floyd/IF

Imagen[^6]è®ºæ–‡ä¸­ä¸»è¦æå‡ºï¼š1ã€çº¯æ–‡æœ¬è¯­æ–™åº“ä¸Šé¢„è®­ç»ƒçš„é€šç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚[T5](https://huggingface.co/collections/google/t5-release-65005e7c520f8d7b4d037918)ã€CLIPã€BERTç­‰ï¼‰åœ¨ç¼–ç å›¾åƒåˆæˆçš„æ–‡æœ¬æ–¹é¢éå¸¸æœ‰æ•ˆï¼šåœ¨Imagenä¸­å¢åŠ è¯­è¨€æ¨¡å‹çš„å¤§å°æ¯”å¢åŠ å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¤§å°æ›´èƒ½æé«˜æ ·æœ¬ä¿çœŸåº¦å’ŒImagetextå¯¹é½ã€‚
![](https://s2.loli.net/2025/07/12/lCFNWwDmgGnZueE.webp)

2ã€é€šè¿‡æé«˜classifier-free guidance weightï¼ˆ$\epsilon(z,c)=w\epsilon(z,c)+ (1-w)\epsilon(z)$ ä¹Ÿå°±æ˜¯å…¶ä¸­çš„å‚æ•° $w$ï¼‰å¯ä»¥æé«˜image-textä¹‹é—´çš„å¯¹é½ï¼Œä½†ä¼šæŸå®³å›¾åƒé€¼çœŸåº¦ï¼Œäº§ç”Ÿé«˜åº¦é¥±å’Œä¸è‡ªç„¶çš„å›¾åƒï¼ˆè®ºæ–‡é‡Œé¢ç»™å‡ºçš„åˆ†ææ˜¯ï¼šæ¯ä¸ªæ—¶é—´æ­¥ä¸­é¢„æµ‹å’Œæ­£å¼çš„xéƒ½ä¼šé™å®šåœ¨ $[-1,1]$è¿™ä¸ªèŒƒå›´ä½†æ˜¯è¾ƒå¤§çš„ $w$å¯èƒ½å¯¼è‡´è¶…å‡ºè¿™ä¸ªèŒƒå›´ï¼‰ï¼Œè®ºæ–‡é‡Œé¢åšæ³•å°±æ˜¯æå‡º **åŠ¨æ€è°ƒæ•´æ–¹æ³•**ï¼šåœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†sè®¾ç½®ä¸º $x_0^t$ä¸­çš„æŸä¸ªç™¾åˆ†ä½ç»å¯¹åƒç´ å€¼ï¼Œå¦‚æœs>1ï¼Œåˆ™æˆ‘ä»¬å°† $x_0^t$é˜ˆå€¼è®¾ç½®ä¸ºèŒƒå›´ $[-s,s]$ï¼Œç„¶åé™¤ä»¥sã€‚
![](https://s2.loli.net/2025/07/12/jAEBS7I1Ob6DPal.webp)

3ã€å’Œä¸Šé¢SDæ¨¡å‹å·®å¼‚æ¯”è¾ƒå¤§çš„ä¸€ç‚¹å°±æ˜¯ï¼Œåœ¨imagenä¸­ç›´æ¥ä½¿ç”¨å¤šé˜¶æ®µç”Ÿæˆç­–ç•¥ï¼Œæ¨¡å‹å…ˆç”Ÿæˆ64x64å›¾åƒå†å»é€šè¿‡è¶…åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹å»ç”Ÿæˆ256x256ä»¥åŠ1024x1024çš„å›¾åƒï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­ä½œè€…æåˆ°ä½¿ç”¨noise conditioning augmentationï¼ˆNCAï¼‰ç­–ç•¥ï¼ˆå¯¹è¾“å…¥çš„æ–‡æœ¬ç¼–ç åå†å»æ·»åŠ éšæœºå™ªå£°ï¼‰
![](https://s2.loli.net/2025/07/12/HJm96oPr2AlXICs.webp)


## Adapters
> https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference

æ­¤ç±»æ–¹æ³•æ˜¯åœ¨å®Œå¤‡çš„ DF æƒé‡åŸºç¡€ä¸Šï¼Œé¢å¤–æ·»åŠ ä¸€ä¸ªâ€œæ’ä»¶â€ï¼Œä¿æŒåŸæœ‰æƒé‡ä¸å˜ã€‚æˆ‘åªéœ€ä¿®æ”¹è¿™ä¸ªæ’ä»¶ï¼Œå°±å¯ä»¥è®©æ¨¡å‹ç”Ÿæˆä¸åŒé£æ ¼çš„å›¾åƒã€‚å¯ä»¥ç†è§£ä¸ºåœ¨åŸå§‹æ¨¡å‹ä¹‹å¤–æ–°å¢ä¸€ä¸ªâ€œç”Ÿæˆæ¡ä»¶â€ï¼Œé€šè¿‡ä¿®æ”¹è¿™ä¸€æ¡ä»¶å³å¯çµæ´»æ§åˆ¶æ¨¡å‹ç”Ÿæˆå„ç§é£æ ¼æˆ–æ»¡è¶³ä¸åŒéœ€æ±‚çš„å›¾åƒã€‚

### ControlNet
> https://github.com/lllyasviel/ControlNet
> å»ºè®®ç›´æ¥é˜…è¯»ï¼š[https://github.com/lllyasviel/ControlNet/discussions/categories/announcements](https://github.com/lllyasviel/ControlNet/discussions/categories/announcements) æ¥äº†è§£æ›´åŠ å¤šç»†èŠ‚

![](https://s2.loli.net/2025/07/09/Tfji2LMv15tgr6d.webp)

ControlNet[^2]çš„å¤„ç†æ€è·¯å°±å¾ˆç®€å•ï¼Œå†å·¦å›¾ä¸­æ¨¡å‹çš„å¤„ç†è¿‡ç¨‹å°±æ˜¯ç›´æ¥é€šè¿‡ï¼š$y=f(x;\theta)$æ¥ç”Ÿæˆå›¾åƒï¼Œä½†æ˜¯åœ¨ControlNeté‡Œé¢ä¼šå°†æˆ‘ä»¬æœ€å¼€å§‹çš„ç½‘ç»œç»“æ„å¤åˆ¶ç„¶åé€šè¿‡åœ¨å…¶å‰åå¼•å…¥ä¸€ä¸ª**zero-convolution**å±‚æ¥â€œæŒ‡å¯¼â€ï¼ˆ$Z$ï¼‰æ¨¡å‹çš„è¾“å‡ºä¹Ÿå°±æ˜¯è¯´å°†ä¸Šé¢çš„ç”Ÿæˆè¿‡ç¨‹å˜ä¸ºï¼š$y=f(x;\theta)+Z(f(x+Z(c;\theta_{z_1});\theta);\theta_{Z_2})$ã€‚é€šè¿‡å†»ç»“æœ€åˆçš„æ¨¡å‹çš„æƒé‡ä¿æŒä¸å˜ï¼Œä¿ç•™äº†Stable Diffusionæ¨¡å‹åŸæœ¬çš„èƒ½åŠ›ï¼›ä¸æ­¤åŒæ—¶ï¼Œä½¿ç”¨é¢å¤–æ•°æ®å¯¹â€œå¯è®­ç»ƒâ€å‰¯æœ¬è¿›è¡Œå¾®è°ƒï¼Œå­¦ä¹ æˆ‘ä»¬æƒ³è¦æ·»åŠ çš„æ¡ä»¶ã€‚å› æ­¤åœ¨æœ€åæˆ‘ä»¬çš„SDæ¨¡å‹ä¸­å°±æ˜¯å¦‚ä¸‹ä¸€ä¸ªç»“æ„ï¼š

![](https://s2.loli.net/2025/07/09/uVNAEnleRMJ6p4v.webp)

åœ¨è®ºæ–‡é‡Œé¢ä½œè€…ç»™å‡ºä¸€ä¸ªå®é™…çš„æµ‹è¯•æ•ˆæœå¯ä»¥å¾ˆå®¹æ˜“ç†è§£é‡Œé¢æ¡ä»¶cï¼ˆæ¡ä»¶ ğ‘å°±æ˜¯æä¾›ç»™æ¨¡å‹çš„æ˜¾å¼ç»“æ„å¼•å¯¼ä¿¡æ¯ï¼Œ**ç”¨äºåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç²¾ç¡®æ§åˆ¶å›¾åƒçš„ç©ºé—´ç»“æ„æˆ–å¸ƒå±€**ï¼Œä¸€èˆ¬æ¥è¯´å¯ä»¥æ˜¯è‰å›¾ã€åˆ†å‰²å›¾ç­‰ï¼‰åˆ°åº•æ˜¯ä¸€ä¸ªä»€ä¹ˆä¸œè¥¿ï¼Œæ¯”å¦‚è¯´å°±æ˜¯ç›´æ¥ç»™å‡ºä¸€ä¸ªâ€œçº¿ç¨¿â€ç„¶åæ¨¡å‹æ¥è¾“å‡ºå›¾åƒã€‚

![](https://s2.loli.net/2025/07/09/rkWH3o1MOaNs6pg.webp)

> **è¡¥å……-1**ï¼šä¸ºä»€ä¹ˆä½¿ç”¨ä¸Šé¢è¿™ç§ç»“æ„
> åœ¨[github](https://github.com/lllyasviel/ControlNet/discussions/188)ä¸Šä½œè€…è®¨è®ºäº†ä¸ºä»€ä¹ˆè¦ä½¿ç”¨ä¸Šé¢è¿™ç§ç»“æ„è€Œéç›´æ¥ä½¿ç”¨mlpç­‰ï¼ˆä½œè€…ç»™å‡ºäº†å¾ˆå¤šæµ‹è¯•å›¾åƒï¼‰ï¼Œæœ€åæ€»ç»“å°±æ˜¯ï¼š**è¿™ç§ç»“æ„å¥½**
> **è¡¥å……-2**ï¼šä½¿ç”¨0å·ç§¯å±‚ä¼šä¸ä¼šå¯¼è‡´æ¨¡å‹æ— æ³•ä¼˜åŒ–é—®é¢˜ï¼Ÿ
> ä¸ä¼šï¼Œå› ä¸ºå¯¹äºç¥ç»ç½‘ç»œç»“æ„å¤§å¤šéƒ½æ˜¯ï¼š$y=wx+b$è®¡ç®—æ¢¯åº¦è¿‡ç¨‹ä¸­å³ä½¿ $w=0$ä½†æ˜¯é‡Œé¢çš„ $xâ‰ 0$æ¨¡å‹çš„å‚æ•°è¿˜æ˜¯å¯ä»¥è¢«ä¼˜åŒ–çš„


#### ControlNetçš„ä»£ç æ“ä½œ
> Code: [https://github.com/shangxiaaabb/ProjectCode/tree/main/code/Python/DFModelCode/training_controlnet](https://github.com/shangxiaaabb/ProjectCode/tree/main/code/Python/DFModelCode/training_controlnet)

**é¦–å…ˆ**ï¼Œç®€å•äº†è§£ä¸€ä¸ªControlNetæ•°æ®é›†æ ¼å¼ï¼Œä¸€èˆ¬æ¥è¯´ï¼ˆï¼‰æ•°æ®ä¸»è¦æ˜¯ä¸‰éƒ¨åˆ†ç»„æˆï¼š1ã€imageï¼ˆå¯ä»¥ç†è§£ä¸ºç”Ÿæˆçš„å›¾åƒï¼‰ï¼›2ã€condiction_imageï¼ˆå¯ä»¥ç†è§£ä¸ºè¾“å…¥ControlNeté‡Œé¢çš„æ¡ä»¶ $c$ï¼‰ï¼›3ã€textã€‚æ¯”å¦‚è¯´ä»¥[raulc0399/open_pose_controlnet](https://huggingface.co/datasets/raulc0399/open_pose_controlnet)ä¸ºä¾‹
![](https://s2.loli.net/2025/07/12/nphNm3OIebFGazr.webp)

**æ¨¡å‹åŠ è½½**ï¼Œä¸€èˆ¬æ¥è¯´æ‰©æ•£æ¨¡å‹å°±åªéœ€è¦åŠ è½½å¦‚ä¸‹å‡ ä¸ªï¼š`DDPMScheduler`ã€`AutoencoderKL`ï¼ˆvaeæ¨¡å‹ï¼‰ã€`UNet2DConditionModel`ï¼ˆä¸ä¸€å®šåŠ è½½æ¡ä»¶Unetæ¨¡å‹ï¼‰ï¼Œé™¤æ­¤ä¹‹å¤–åœ¨ControlNetä¸­è¿˜éœ€è¦åŠ è½½ä¸€ä¸ª`ControlNetModel`ã€‚å¯¹äº`ControlNetModel`ä¸­ä»£ç å¤§è‡´ç»“æ„ä¸ºï¼Œä»£ç ä¸­é€šè¿‡`self.controlnet_down_blocks`æ¥å­˜å‚¨ControlNetçš„ä¸‹é‡‡æ ·æ¨¡å—ï¼ˆ**åˆå§‹åŒ–ä¸º0çš„å·ç§¯å±‚**ï¼‰ã€‚`self.down_blocks`ç”¨æ¥å­˜å‚¨ControlNetä¸­å¤åˆ¶çš„Unetçš„ä¸‹é‡‡æ ·å±‚ã€‚åœ¨`forward`ä¸­å¯¹äºè¾“å…¥çš„æ ·æœ¬ï¼ˆ`sample`ï¼‰é¦–å…ˆé€šè¿‡ `self.down_blocks`é€å±‚å¤„ç†å åŠ åˆ° `down_block_res_samples`ä¸­ï¼Œè€Œåå°±æ˜¯ç›´æ¥å°†å¾—åˆ°ç»“æœå†å»é€šè¿‡ `self.controlnet_down_blocks`æ¯å±‚è¿›è¡Œå¤„ç†ï¼Œæœ€åè¿”å›ä¸‹é‡‡æ ·çš„æ¯å±‚ç»“æœä»¥åŠä¸­é—´å±‚å¤„ç†ç»“æœï¼š`down_block_res_samples`ï¼Œ`mid_block_res_sample`

```python
class ControlNetModel(ModelMixin, ConfigMixin, FromOriginalModelMixin):
    @register_to_config
    def __init__(...):
        ...
        self.down_blocks = nn.ModuleList([])
        self.controlnet_down_blocks = nn.ModuleList([])
        # å°è£…ä¸‹é‡‡æ ·è¿‡ç¨‹ï¼ˆå¯¹åº”ä¸Šé¢æ¨¡å‹å³ä¾§ç»“æ„ï¼‰
        controlnet_block = nn.Conv2d(output_channel, output_channel, kernel_size=1)
        controlnet_block = zero_module(controlnet_block)
        self.controlnet_down_blocks.append(controlnet_block)
        for i, down_block_type in enumerate(down_block_types):
            # down_block_typeså°±æ˜¯Uneté‡Œé¢ä¸‹é‡‡æ ·çš„æ¯ä¸€ä¸ªæ¨¡å—æ¯”å¦‚è¯´ï¼šCrossAttnDownBlock2D
            ...
            down_block = get_down_block(down_block_type) # é€šè¿‡ get_down_block è·å–uetä¸‹é‡‡æ ·çš„æ¨¡å—
            self.down_blocks.append(down_block)
            for _ in range(layers_per_block):
                controlnet_block = nn.Conv2d(output_channel, output_channel, kernel_size=1)
                controlnet_block = zero_module(controlnet_block)
                self.controlnet_down_blocks.append(controlnet_block)
    @classmethod
    def from_unet(cls, unet,...):
        ...
        # é€šè¿‡clså®ä¾‹åŒ–çš„ç±»æœ¬èº«ControlNetModel
        controlnet = cls(...)
        if load_weights_from_unet:
            # å°†å„ç±»æƒé‡åŠ è½½åˆ° controlnet ä¸­
            controlnet.conv_in.load_state_dict(unet.conv_in.state_dict())
            controlnet.time_proj.load_state_dict(unet.time_proj.state_dict())
            ...

        return controlnet
    def forward(...):
        ...
        # æ—¶é—´ç¼–ç 
        t_emb = self.time_proj(timesteps)
        emb = self.time_embedding(t_emb, timestep_cond)
        if self.class_embedding is not None:
            ...
            class_emb = self.class_embedding(class_labels).to(dtype=self.dtype)
            emb = emb + class_emb
        # å¯¹æ¡ä»¶è¿›è¡Œç¼–ç 
        if self.config.addition_embed_type is not None:
            if self.config.addition_embed_type == "text":
                aug_emb = self.add_embedding(encoder_hidden_states)
            elif self.config.addition_embed_type == "text_time":
                time_ids = added_cond_kwargs.get("time_ids")
                time_embeds = self.add_time_proj(time_ids.flatten())
                time_embeds = time_embeds.reshape((text_embeds.shape[0], -1))

                add_embeds = torch.concat([text_embeds, time_embeds], dim=-1)
                add_embeds = add_embeds.to(emb.dtype)
                aug_emb = self.add_embedding(add_embeds)
        emb = emb + aug_emb if aug_emb is not None else emb       

        sample = self.conv_in(sample)
        controlnet_cond = self.controlnet_cond_embedding(controlnet_cond)
        sample = sample + controlnet_cond

        # ä¸‹é‡‡æ ·å¤„ç†
        down_block_res_samples = (sample,)
        for downsample_block in self.down_blocks:
            if ...
                ...
            else:
                sample, res_samples = downsample_block(hidden_states=sample, temb=emb)
            down_block_res_samples += res_samples
        # ä¸­é—´å±‚å¤„ç†
        ...
        # å°†è¾“å‡ºåçš„å†…å®¹å»å’Œ0å·ç§¯è¿›è¡Œå åŠ 
        controlnet_down_block_res_samples = ()
        for down_block_res_sample, controlnet_block in zip(down_block_res_samples, self.controlnet_down_blocks):
            down_block_res_sample = controlnet_block(down_block_res_sample)
            controlnet_down_block_res_samples = controlnet_down_block_res_samples + (down_block_res_sample,)
        ...
        if not return_dict:
            return (down_block_res_samples, mid_block_res_sample)
        ...
```

**æ¨¡å‹è®­ç»ƒ**ï¼Œè®­ç»ƒè¿‡ç¨‹å’ŒDFè®­ç»ƒå·®å¼‚ä¸å¤§ã€‚å°†å›¾åƒé€šè¿‡VAEå¤„ç†ã€äº§ç”Ÿå™ªå£°ã€æ—¶é—´æ­¥ã€å°†å™ªå£°æ·»åŠ åˆ°ï¼ˆVAEå¤„ç†ä¹‹åçš„ï¼‰å›¾åƒä¸­ï¼Œè€Œåé€šè¿‡ `controlnet`å¾—åˆ°æ¯å±‚ä¸‹é‡‡æ ·çš„ç»“æœä»¥åŠä¸­é—´å±‚ç»“æœï¼š`down_block_res_samples, mid_block_res_sample = controlnet(...)`è€Œåå°†è¿™ä¸¤éƒ¨åˆ†ç»“æœå†å»é€šè¿‡unetå¤„ç†
```python
model_pred = unet(
    noisy_latents,
    timesteps,
    encoder_hidden_states=encoder_hidden_states,
    down_block_additional_residuals=[
        sample.to(dtype=weight_dtype) for sample in down_block_res_samples
    ],
    mid_block_additional_residual=mid_block_res_sample.to(dtype=weight_dtype),
    return_dict=False,
)[0]
```

åç»­å°±æ˜¯è®¡ç®—lossç­‰å¤„ç†

**æ¨¡å‹éªŒè¯**ï¼Œç›´æ¥å°±æ˜¯ä½¿ç”¨`StableDiffusionControlNetPipeline`æ¥å¤„ç†äº†


### T2I-Adapter
> https://github.com/TencentARC/T2I-Adapter

![image.png](https://s2.loli.net/2025/07/09/gZLDtFSGr25kCwa.webp)

T2I[^3]çš„å¤„ç†æ€è·¯ä¹Ÿæ¯”è¾ƒç®€å•ï¼ˆT2I-Adap 4 ter Detailsé‡Œé¢å…¶å®å°±å†™çš„å¾ˆæ˜ç™½äº†ï¼‰ï¼Œå¯¹äºè¾“å…¥çš„æ¡ä»¶å›¾ç‰‡ï¼ˆæ¯”å¦‚è¯´è¾¹ç¼˜å›¾åƒï¼‰:512x512ï¼Œé¦–å…ˆé€šè¿‡ pixel unshuffleè¿›è¡Œä¸‹é‡‡æ ·å°†å›¾åƒåˆ†è¾¨ç‡æ”¹ä¸ºï¼š64x64è€Œåé€šè¿‡ä¸€å±‚å·ç§¯+ä¸¤å±‚æ®‹å·®è¿æ¥ï¼Œè¾“å‡ºå¾—åˆ°ç‰¹å¾ $F_c$ä¹‹åå°†å…¶ä¸å¯¹åº”çš„encoderç»“æ„è¿›è¡Œç›¸åŠ ï¼š$F_{enc}+ F_c$ï¼Œå½“ç„¶T2Iä¹Ÿæ”¯æŒå¤šä¸ªæ¡ä»¶ï¼ˆç›´æ¥é€šè¿‡åŠ æƒç»„åˆå°±è¡Œï¼‰

### DreamBooth
> https://huggingface.co/docs/diffusers/v0.34.0/using-diffusers/dreambooth

è®ºæ–‡[^4]é‡Œé¢ä¸»è¦å‡ºå‘ç‚¹å°±æ˜¯ï¼š1ã€è§£å†³**language drif**ï¼ˆè¯­è¨€åç¦»é—®é¢˜ï¼‰ï¼šæŒ‡çš„æ˜¯æ¨¡å‹é€šè¿‡åè®­ç»ƒï¼ˆå¾®è°ƒç­‰å¤„ç†ä¹‹åï¼‰æ¨¡å‹ä¸§å¤±äº†å¯¹æŸäº›è¯­ä¹‰ç‰¹å¾çš„æ„ŸçŸ¥ï¼Œå°±æ¯”å¦‚è¯´æ‰©æ•£æ¨¡å‹é‡Œé¢ï¼Œæ¨¡å‹é€šè¿‡ä¸æ–­å¾®è°ƒå¯èƒ½å°±ä¸çŸ¥é“â€œç‹—â€æ˜¯ä»€ä¹ˆä»è€Œå¯¼è‡´æ¨¡å‹ç”Ÿæˆé”™è¯¯ã€‚2ã€é«˜æ•ˆçš„ç”Ÿæˆéœ€è¦çš„å¯¹è±¡ï¼Œä¸ä¼šäº§ç”Ÿï¼šç”Ÿæˆé”™è¯¯ã€ç»†èŠ‚ä¸¢å¤±é—®é¢˜ï¼Œæ¯”å¦‚è¯´ä¸‹é¢å›¾åƒä¸­çš„é—®é¢˜ï¼š
![](https://s2.loli.net/2025/07/12/mRaHPOtC23li9Fn.webp)

ä¸ºäº†å®ç°å›¾åƒçš„â€œé«˜æ•ˆè¿ç§»â€ï¼Œä½œè€…ç›´æ¥å°†å›¾åƒï¼ˆæ¯”å¦‚è¯´æˆ‘ä»¬éœ€è¦é£æ ¼åŒ–çš„å›¾ç‰‡ï¼‰ä½œä¸ºä¸€ä¸ªç‰¹æ®Šçš„æ ‡è®°ï¼Œä¹Ÿå°±æ˜¯è®ºæ–‡é‡Œé¢æåˆ°çš„ `a [identifier] [class noun]`ï¼ˆå…¶ä¸­class nounä¸ºç±»åˆ«æ¯”å¦‚æ‰€ç‹—ï¼Œidentifierå°±æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„æ ‡è®°ï¼‰ï¼Œåœ¨promptä¸­åŠ å…¥ç±»åˆ«ï¼Œé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ä¸­å…³äºè¯¥ç±»åˆ«ç‰©å“çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶å°†å…ˆéªŒçŸ¥è¯†ä¸ç‰¹æ®Šæ ‡è®°ç¬¦ç›¸å…³ä¿¡æ¯è¿›è¡Œèåˆï¼Œè¿™æ ·å°±å¯ä»¥åœ¨ä¸åŒåœºæ™¯ä¸‹ç”Ÿæˆä¸åŒå§¿åŠ¿çš„ç›®æ ‡ç‰©ä½“ã€‚å°±æ¯”å¦‚ä¸‹é¢çš„ `fine-tuning`è¿‡ç¨‹é€šè¿‡å‡ å¼ å›¾ç‰‡è®©æ¨¡å‹å­¦ä¹ åˆ° *ç‰¹æ®Šçš„ç‹—*ï¼Œç„¶åå†æ¨ç†é˜¶æ®µæ¨¡å‹å¯ä»¥åˆ©ç”¨è¿™ä¸ª *ç‰¹æ®Šçš„ç‹—*å»ç”Ÿæˆæ–°çš„åŠ¨ä½œã€‚

![](https://s2.loli.net/2025/07/12/hYM1VdykDxALrGo.webp)

å†è®ºæ–‡é‡Œé¢ä½œè€…è®¾è®¡å¦‚ä¸‹çš„Class-specific Prior Preservation Lossï¼ˆå‚è€ƒstackexchangeï¼‰[^5]ï¼š

$$\begin{aligned}
 & \mathbb{E}_{x,c,\epsilon,t}\left[\|\epsilon-\varepsilon_{\theta}(z_{t},t,c)\|_{2}^{2}+\lambda\|\epsilon^{\prime}-\epsilon_{pr}(z_{t^{\prime}}^{\prime},t^{\prime},c_{pr})\|_{2}^{2}\right]
\end{aligned}$$

ä¸Šé¢æŸå¤±å‡½æ•°ä¸­åé¢ä¸€éƒ¨åˆ†å°±æ˜¯æˆ‘ä»¬çš„å…ˆéªŒæŸå¤±ï¼Œæ¯”å¦‚è¯´$c+{pr}$å°±æ˜¯å¯¹ "a dog"è¿›è¡Œç¼–ç ç„¶åè®¡ç®—ç”ŸæˆæŸå¤±ã€‚åœ¨ä»£ç ä¸­ï¼š

```python
if args.with_prior_preservation:
    model_pred, model_pred_prior = torch.chunk(model_pred, 2, dim=0)
    target, target_prior = torch.chunk(target, 2, dim=0)
    # Compute instance loss
    loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
    # Compute prior loss
    prior_loss = F.mse_loss(model_pred_prior.float(), target_prior.float(), reduction="mean")
    # Add the prior loss to the instance loss.
    loss = loss + args.prior_loss_weight * prior_loss
else:
    loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
```

## æ€»ç»“
å¯¹äºä¸åŒçš„æ‰©æ•£ï¼ˆåŸºåº§ï¼‰æ¨¡å‹ï¼ˆSD1.5ã€SDXLï¼‰ç­‰å¤§éƒ¨åˆ†éƒ½æ˜¯é‡‡ç”¨Unetç»“æ„ï¼Œå½“ç„¶ä¹Ÿæœ‰é‡‡ç”¨Ditçš„ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹ä¹‹é—´çš„å·®å¼‚ä¸»è¦åœ¨äºåè€…ä¼šå¤šä¸€ä¸ªclipç¼–ç å™¨å†æ–‡æœ¬è¯­ä¹‰ä¸Šæ¯”å‰è€…æ›´åŠ æœ‰ä¼˜åŠ¿ã€‚å¯¹äºadapterè€Œè¨€ï¼Œå¯ä»¥ç›´æ¥ç†è§£ä¸ºå†SDçš„åŸºç¡€ä¸Šå»ä½¿ç”¨â€œé£æ ¼æ’ä»¶â€ï¼Œè¿™ä¸ªæ’ä»¶ä¸å»å¯¹SDæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼ˆä»è€Œå®ç°å¯¹å‚æ•°çš„å‡å°ï¼‰ï¼Œå¯¹äºControNetå°±æ˜¯ç›´æ¥å¯¹Unetçš„ä¸‹é‡‡æ ·æ‰€æœ‰çš„æ¨¡å—ï¼ˆå‰åï¼‰éƒ½åŠ ä¸€ä¸ªzero-convè€Œåå°†ç»“æœå†å»åµŒå…¥åˆ°ä¸‹é‡‡ç”¨ä¸­ï¼Œè€ŒT2I-Adapteråˆ™æ˜¯å»å¯¹æ¡ä»¶è¿›è¡Œç¼–ç è€ŒååµŒå…¥åˆ°SDæ¨¡å‹ï¼ˆä¸Šé‡‡ç”¨æ¨¡å—ï¼‰ä¸­ã€‚å¯¹äºderambothå°±æ˜¯ç›´æ¥é€šè¿‡è®¾è®¡çš„Class-specific Prior Preservation Lossæ¥å®ç°ç”Ÿæˆç‰¹ä¾‹çš„é£æ ¼åŒ–è¿ç§»

## å‚è€ƒ
[^1]:[https://arxiv.org/pdf/2307.01952](https://arxiv.org/pdf/2307.01952)
[^2]:[https://arxiv.org/pdf/2302.05543](https://arxiv.org/pdf/2302.05543)
[^3]:[https://arxiv.org/pdf/2302.08453](https://arxiv.org/pdf/2302.08453)
[^4]:[https://arxiv.org/pdf/2208.12242](https://arxiv.org/pdf/2208.12242)
[^5]:https://stats.stackexchange.com/questions/601782/how-to-rewrite-dreambooth-loss-in-terms-of-epsilon-prediction
[^6]: [https://arxiv.org/pdf/2205.11487](https://arxiv.org/pdf/2205.11487)